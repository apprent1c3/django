import datetime
import itertools
import unittest
from copy import copy
from decimal import Decimal
from unittest import mock

from django.core.exceptions import FieldError
from django.core.management.color import no_style
from django.core.serializers.json import DjangoJSONEncoder
from django.db import (
    DatabaseError,
    DataError,
    IntegrityError,
    OperationalError,
    connection,
)
from django.db.backends.utils import truncate_name
from django.db.models import (
    CASCADE,
    PROTECT,
    AutoField,
    BigAutoField,
    BigIntegerField,
    BinaryField,
    BooleanField,
    CharField,
    CheckConstraint,
    DateField,
    DateTimeField,
    DecimalField,
    DurationField,
    F,
    FloatField,
    ForeignKey,
    ForeignObject,
    GeneratedField,
    Index,
    IntegerField,
    JSONField,
    ManyToManyField,
    Model,
    OneToOneField,
    OrderBy,
    PositiveIntegerField,
    Q,
    SlugField,
    SmallAutoField,
    SmallIntegerField,
    TextField,
    TimeField,
    UniqueConstraint,
    UUIDField,
    Value,
)
from django.db.models.fields.json import KT, KeyTextTransform
from django.db.models.functions import (
    Abs,
    Cast,
    Collate,
    Concat,
    Lower,
    Random,
    Round,
    Upper,
)
from django.db.models.indexes import IndexExpression
from django.db.transaction import TransactionManagementError, atomic
from django.test import TransactionTestCase, skipIfDBFeature, skipUnlessDBFeature
from django.test.utils import CaptureQueriesContext, isolate_apps, register_lookup

from .fields import CustomManyToManyField, InheritedManyToManyField, MediumBlobField
from .models import (
    Author,
    AuthorCharFieldWithIndex,
    AuthorTextFieldWithIndex,
    AuthorWithDefaultHeight,
    AuthorWithEvenLongerName,
    AuthorWithIndexedName,
    AuthorWithUniqueName,
    AuthorWithUniqueNameAndBirthday,
    Book,
    BookForeignObj,
    BookWeak,
    BookWithLongName,
    BookWithO2O,
    BookWithoutAuthor,
    BookWithSlug,
    IntegerPK,
    Node,
    Note,
    NoteRename,
    Tag,
    TagM2MTest,
    TagUniqueRename,
    Thing,
    UniqueTest,
    new_apps,
)


class SchemaTests(TransactionTestCase):
    """
    Tests for the schema-alteration code.

    Be aware that these tests are more liable than most to false results,
    as sometimes the code to check if a test has worked is almost as complex
    as the code it is testing.
    """

    available_apps = []

    models = [
        Author,
        AuthorCharFieldWithIndex,
        AuthorTextFieldWithIndex,
        AuthorWithDefaultHeight,
        AuthorWithEvenLongerName,
        Book,
        BookWeak,
        BookWithLongName,
        BookWithO2O,
        BookWithSlug,
        IntegerPK,
        Node,
        Note,
        Tag,
        TagM2MTest,
        TagUniqueRename,
        Thing,
        UniqueTest,
    ]

    # Utility functions

    def setUp(self):
        # local_models should contain test dependent model classes that will be
        # automatically removed from the app cache on test tear down.
        """

        Sets up the environment for testing by initializing two empty lists: 
        :ivar local_models: to store local models, and 
        :ivar isolated_local_models: to store isolated local models, preparing the context for further testing operations.

        """
        self.local_models = []
        # isolated_local_models contains models that are in test methods
        # decorated with @isolate_apps.
        self.isolated_local_models = []

    def tearDown(self):
        # Delete any tables made for our models
        """
        Teardown method used to clean up resources after a test case has finished executing.

        This method performs the following steps to ensure a clean state:
        - Deletes any created tables.
        - Clears the application registry cache.
        - Expires the model cache for all models.
        - If a schema is present, removes many-to-many through tables and local models from the application registry.
        - If local models are isolated, deletes them from the database schema.

        This method is typically used in the context of testing to prevent test cases from interfering with each other.
        """
        self.delete_tables()
        new_apps.clear_cache()
        for model in new_apps.get_models():
            model._meta._expire_cache()
        if "schema" in new_apps.all_models:
            for model in self.local_models:
                for many_to_many in model._meta.many_to_many:
                    through = many_to_many.remote_field.through
                    if through and through._meta.auto_created:
                        del new_apps.all_models["schema"][through._meta.model_name]
                del new_apps.all_models["schema"][model._meta.model_name]
        if self.isolated_local_models:
            with connection.schema_editor() as editor:
                for model in self.isolated_local_models:
                    editor.delete_model(model)

    def delete_tables(self):
        "Deletes all model tables for our models for a clean test environment"
        converter = connection.introspection.identifier_converter
        with connection.schema_editor() as editor:
            connection.disable_constraint_checking()
            table_names = connection.introspection.table_names()
            if connection.features.ignores_table_name_case:
                table_names = [table_name.lower() for table_name in table_names]
            for model in itertools.chain(SchemaTests.models, self.local_models):
                tbl = converter(model._meta.db_table)
                if connection.features.ignores_table_name_case:
                    tbl = tbl.lower()
                if tbl in table_names:
                    editor.delete_model(model)
                    table_names.remove(tbl)
            connection.enable_constraint_checking()

    def column_classes(self, model):
        """
        Returns a dictionary mapping column names to their respective field types in the given database model.

        The dictionary keys are the column names, and the values are tuples where the first element is the field type and the second element contains additional column information. This function is useful for introspecting the database schema of a model and determining the data types of its columns.
        """
        with connection.cursor() as cursor:
            columns = {
                d[0]: (connection.introspection.get_field_type(d[1], d), d)
                for d in connection.introspection.get_table_description(
                    cursor,
                    model._meta.db_table,
                )
            }
        # SQLite has a different format for field_type
        for name, (type, desc) in columns.items():
            if isinstance(type, tuple):
                columns[name] = (type[0], desc)
        return columns

    def get_primary_key(self, table):
        with connection.cursor() as cursor:
            return connection.introspection.get_primary_key_column(cursor, table)

    def get_indexes(self, table):
        """
        Get the indexes on the table using a new cursor.
        """
        with connection.cursor() as cursor:
            return [
                c["columns"][0]
                for c in connection.introspection.get_constraints(
                    cursor, table
                ).values()
                if c["index"] and len(c["columns"]) == 1
            ]

    def get_uniques(self, table):
        """

        Retrieves a list of unique column names from the specified database table.

        This function returns a list of column names that have unique constraints 
        applied to them and are not composite keys (i.e., they are the only column 
        in the unique constraint). The result can be used to identify columns 
        that must contain distinct values in the table.

        :param table: The name of the database table to retrieve unique columns from
        :return: A list of unique column names

        """
        with connection.cursor() as cursor:
            return [
                c["columns"][0]
                for c in connection.introspection.get_constraints(
                    cursor, table
                ).values()
                if c["unique"] and len(c["columns"]) == 1
            ]

    def get_constraints(self, table):
        """
        Get the constraints on a table using a new cursor.
        """
        with connection.cursor() as cursor:
            return connection.introspection.get_constraints(cursor, table)

    def get_constraints_for_column(self, model, column_name):
        """

        Get a list of constraints that apply to a specific column in a model.

        This function retrieves all constraints for the given model's database table and
        then filters them to include only those that apply to the specified column.
        The result is a sorted list of constraint names.

        :param model: The model to retrieve constraints for.
        :param column_name: The name of the column to filter constraints by.
        :return: A sorted list of constraint names that apply to the specified column.

        """
        constraints = self.get_constraints(model._meta.db_table)
        constraints_for_column = []
        for name, details in constraints.items():
            if details["columns"] == [column_name]:
                constraints_for_column.append(name)
        return sorted(constraints_for_column)

    def get_constraint_opclasses(self, constraint_name):
        """

        Get operation classes associated with a given constraint.

        Retrieves the operation class names (opcname) from the PostgreSQL catalog tables
        for the specified constraint. These operation classes define the behavior of the
        constraint's underlying index.

        :param constraint_name: The name of the constraint to retrieve operation classes for.
        :rtype: list
        :return: A list of operation class names associated with the given constraint.

        """
        with connection.cursor() as cursor:
            sql = """
                SELECT opcname
                FROM pg_opclass AS oc
                JOIN pg_index as i on oc.oid = ANY(i.indclass)
                JOIN pg_class as c on c.oid = i.indexrelid
                WHERE c.relname = %s
            """
            cursor.execute(sql, [constraint_name])
            return [row[0] for row in cursor.fetchall()]

    def check_added_field_default(
        self,
        schema_editor,
        model,
        field,
        field_name,
        expected_default,
        cast_function=None,
    ):
        """

        Checks that the default value of an added field matches the expected value.

        This method adds a field to a model, retrieves the default value from the database,
        and asserts that it matches the provided expected default.

        It also supports type casting of the database default value if necessary,
        using the provided cast function.

        :param schema_editor: The schema editor instance to use for adding the field.
        :param model: The model to which the field is being added.
        :param field: The field instance being added.
        :param field_name: The name of the field in the database.
        :param expected_default: The expected default value of the field.
        :param cast_function: An optional function to cast the database default value to the expected type.

        """
        with connection.cursor() as cursor:
            schema_editor.add_field(model, field)
            cursor.execute(
                "SELECT {} FROM {};".format(field_name, model._meta.db_table)
            )
            database_default = cursor.fetchall()[0][0]
            if cast_function and type(database_default) is not type(expected_default):
                database_default = cast_function(database_default)
            self.assertEqual(database_default, expected_default)

    def get_constraints_count(self, table, column, fk_to):
        """
        Return a dict with keys 'fks', 'uniques, and 'indexes' indicating the
        number of foreign keys, unique constraints, and indexes on
        `table`.`column`. The `fk_to` argument is a 2-tuple specifying the
        expected foreign key relationship's (table, column).
        """
        with connection.cursor() as cursor:
            constraints = connection.introspection.get_constraints(cursor, table)
        counts = {"fks": 0, "uniques": 0, "indexes": 0}
        for c in constraints.values():
            if c["columns"] == [column]:
                if c["foreign_key"] == fk_to:
                    counts["fks"] += 1
                if c["unique"]:
                    counts["uniques"] += 1
                elif c["index"]:
                    counts["indexes"] += 1
        return counts

    def get_column_collation(self, table, column):
        """
        Return the collation of a specific column in a database table.

        :param table: The name of the database table to query.
        :param column: The name of the column for which to retrieve the collation.
        :return: The collation of the specified column, or None if the column is not found.
        :raises StopIteration: If the column is not found in the table description.

        This function provides a convenient way to determine the collation of a specific column, 
        which can be useful for tasks such as data import/export, query optimization, or schema validation.
        """
        with connection.cursor() as cursor:
            return next(
                f.collation
                for f in connection.introspection.get_table_description(cursor, table)
                if f.name == column
            )

    def get_column_comment(self, table, column):
        """

        Get a comment associated with a specific column of a table.

        Args:
            table (str): Name of the table to retrieve the column comment from.
            column (str): Name of the column to retrieve the comment for.

        Returns:
            str: The comment associated with the specified column, or None if no comment exists.

        Note:
            The function uses database introspection to retrieve the comment.

        """
        with connection.cursor() as cursor:
            return next(
                f.comment
                for f in connection.introspection.get_table_description(cursor, table)
                if f.name == column
            )

    def get_table_comment(self, table):
        with connection.cursor() as cursor:
            return next(
                t.comment
                for t in connection.introspection.get_table_list(cursor)
                if t.name == table
            )

    def assert_column_comment_not_exists(self, table, column):
        with connection.cursor() as cursor:
            columns = connection.introspection.get_table_description(cursor, table)
        self.assertFalse(any([c.name == column and c.comment for c in columns]))

    def assertIndexOrder(self, table, index, order):
        """

        Asserts that the order of an index in a given table matches the expected order.

        :param table: The name of the table to check.
        :param index: The name of the index to verify.
        :param order: The expected order of the index.

        This function retrieves the constraints of the specified table, checks if the given index exists, 
        and then verifies that the actual order of the index matches the provided order. 
        It raises an assertion error if the index does not exist or if the orders do not match.

        """
        constraints = self.get_constraints(table)
        self.assertIn(index, constraints)
        index_orders = constraints[index]["orders"]
        self.assertTrue(
            all(val == expected for val, expected in zip(index_orders, order))
        )

    def assertForeignKeyExists(self, model, column, expected_fk_table, field="id"):
        """
        Fail if the FK constraint on `model.Meta.db_table`.`column` to
        `expected_fk_table`.id doesn't exist.
        """
        if not connection.features.can_introspect_foreign_keys:
            return
        constraints = self.get_constraints(model._meta.db_table)
        constraint_fk = None
        for details in constraints.values():
            if details["columns"] == [column] and details["foreign_key"]:
                constraint_fk = details["foreign_key"]
                break
        self.assertEqual(constraint_fk, (expected_fk_table, field))

    def assertForeignKeyNotExists(self, model, column, expected_fk_table):
        """
        Asserts that a foreign key does not exist between a specified model and column, 
        and an expected foreign key table.

        This test checks the relationship between a model and a column, and verifies that 
        it does not have a foreign key referencing the specified table. 

        :param model: The model to check for foreign key constraints
        :param column: The column to check for foreign key constraints
        :param expected_fk_table: The table that should not be referenced by a foreign key
        """
        if not connection.features.can_introspect_foreign_keys:
            return
        with self.assertRaises(AssertionError):
            self.assertForeignKeyExists(model, column, expected_fk_table)

    # Tests
    def test_creation_deletion(self):
        """
        Tries creating a model's table, and then deleting it.
        """
        with connection.schema_editor() as editor:
            # Create the table
            editor.create_model(Author)
            # The table is there
            list(Author.objects.all())
            # Clean up that table
            editor.delete_model(Author)
            # No deferred SQL should be left over.
            self.assertEqual(editor.deferred_sql, [])
        # The table is gone
        with self.assertRaises(DatabaseError):
            list(Author.objects.all())

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_fk(self):
        "Creating tables out of FK order, then repointing, works"
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Book)
            editor.create_model(Author)
            editor.create_model(Tag)
        # Initial tables are there
        list(Author.objects.all())
        list(Book.objects.all())
        # Make sure the FK constraint is present
        with self.assertRaises(IntegrityError):
            Book.objects.create(
                author_id=1,
                title="Much Ado About Foreign Keys",
                pub_date=datetime.datetime.now(),
            )
        # Repoint the FK constraint
        old_field = Book._meta.get_field("author")
        new_field = ForeignKey(Tag, CASCADE)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(Book, old_field, new_field, strict=True)
        self.assertForeignKeyExists(Book, "author_id", "schema_tag")

    @skipUnlessDBFeature("can_create_inline_fk")
    def test_inline_fk(self):
        # Create some tables.
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
            editor.create_model(Note)
        self.assertForeignKeyNotExists(Note, "book_id", "schema_book")
        # Add a foreign key from one to the other.
        with connection.schema_editor() as editor:
            new_field = ForeignKey(Book, CASCADE)
            new_field.set_attributes_from_name("book")
            editor.add_field(Note, new_field)
        self.assertForeignKeyExists(Note, "book_id", "schema_book")
        # Creating a FK field with a constraint uses a single statement without
        # a deferred ALTER TABLE.
        self.assertFalse(
            [
                sql
                for sql in (str(statement) for statement in editor.deferred_sql)
                if sql.startswith("ALTER TABLE") and "ADD CONSTRAINT" in sql
            ]
        )

    @skipUnlessDBFeature("can_create_inline_fk")
    def test_add_inline_fk_update_data(self):
        with connection.schema_editor() as editor:
            editor.create_model(Node)
        # Add an inline foreign key and update data in the same transaction.
        new_field = ForeignKey(Node, CASCADE, related_name="new_fk", null=True)
        new_field.set_attributes_from_name("new_parent_fk")
        parent = Node.objects.create()
        with connection.schema_editor() as editor:
            editor.add_field(Node, new_field)
            editor.execute("UPDATE schema_node SET new_parent_fk_id = %s;", [parent.pk])
        assertIndex = (
            self.assertIn
            if connection.features.indexes_foreign_keys
            else self.assertNotIn
        )
        assertIndex("new_parent_fk_id", self.get_indexes(Node._meta.db_table))

    @skipUnlessDBFeature(
        "can_create_inline_fk",
        "allows_multiple_constraints_on_same_fields",
    )
    @isolate_apps("schema")
    def test_add_inline_fk_index_update_data(self):
        """

        Tests the addition of an inline foreign key index with an update of the data.

        This test case verifies that a foreign key can be added to a model with an
        inline index, and that the data in the table is updated correctly. It creates
        a new model, adds a foreign key field to it, and then updates the data in the
        table to reference an existing parent object. Finally, it checks that the index
        has been successfully created on the foreign key field.

        This test is only run on databases that support creating inline foreign keys
        and allow multiple constraints on the same fields.

        """
        class Node(Model):
            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Node)
        # Add an inline foreign key, update data, and an index in the same
        # transaction.
        new_field = ForeignKey(Node, CASCADE, related_name="new_fk", null=True)
        new_field.set_attributes_from_name("new_parent_fk")
        parent = Node.objects.create()
        with connection.schema_editor() as editor:
            editor.add_field(Node, new_field)
            Node._meta.add_field(new_field)
            editor.execute("UPDATE schema_node SET new_parent_fk_id = %s;", [parent.pk])
            editor.add_index(
                Node, Index(fields=["new_parent_fk"], name="new_parent_inline_fk_idx")
            )
        self.assertIn("new_parent_fk_id", self.get_indexes(Node._meta.db_table))

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_char_field_with_db_index_to_fk(self):
        # Create the table
        """

        Tests the addition of a foreign key constraint to a char field with a database index.

        This test case verifies that a char field with a database index can be successfully
        altered to become a foreign key field referencing another model, specifically the Author model.
        The test creates the necessary models, alters the field, and then asserts that the foreign key exists
        in the database schema as expected.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(AuthorCharFieldWithIndex)
        # Change CharField to FK
        old_field = AuthorCharFieldWithIndex._meta.get_field("char_field")
        new_field = ForeignKey(Author, CASCADE, blank=True)
        new_field.set_attributes_from_name("char_field")
        with connection.schema_editor() as editor:
            editor.alter_field(
                AuthorCharFieldWithIndex, old_field, new_field, strict=True
            )
        self.assertForeignKeyExists(
            AuthorCharFieldWithIndex, "char_field_id", "schema_author"
        )

    @skipUnlessDBFeature("supports_foreign_keys")
    @skipUnlessDBFeature("supports_index_on_text_field")
    def test_text_field_with_db_index_to_fk(self):
        # Create the table
        """

        Tests creating a text field with a database index and then changing it to a foreign key field.

        Checks the database's support for foreign keys and indexes on text fields before performing the test.
        The test creates two models, Author and AuthorTextFieldWithIndex, then alters the 'text_field' in 
        AuthorTextFieldWithIndex to a foreign key referencing the Author model. It verifies the foreign key 
        constraint is created correctly in the database.

        This test ensures the database schema is updated correctly when changing a text field to a foreign key 
        field, which is an important aspect of maintaining data consistency and relationships in the database.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(AuthorTextFieldWithIndex)
        # Change TextField to FK
        old_field = AuthorTextFieldWithIndex._meta.get_field("text_field")
        new_field = ForeignKey(Author, CASCADE, blank=True)
        new_field.set_attributes_from_name("text_field")
        with connection.schema_editor() as editor:
            editor.alter_field(
                AuthorTextFieldWithIndex, old_field, new_field, strict=True
            )
        self.assertForeignKeyExists(
            AuthorTextFieldWithIndex, "text_field_id", "schema_author"
        )

    @isolate_apps("schema")
    def test_char_field_pk_to_auto_field(self):
        """

        Tests the migration of a character field primary key to an auto field.

        This test case covers the scenario where a model's primary key is initially defined
        as a character field and is then altered to be an auto field. It verifies that the
        migration is successful and that the model's primary key is correctly updated.

        The test creates a sample model 'Foo' with a character field primary key, creates the
        model in the database, and then alters the primary key field to be an auto field.
        The test ensures that the alteration is done correctly and that the model's metadata
        is updated accordingly.

        """
        class Foo(Model):
            id = CharField(max_length=255, primary_key=True)

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Foo)
        self.isolated_local_models = [Foo]
        old_field = Foo._meta.get_field("id")
        new_field = AutoField(primary_key=True)
        new_field.set_attributes_from_name("id")
        new_field.model = Foo
        with connection.schema_editor() as editor:
            editor.alter_field(Foo, old_field, new_field, strict=True)

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_fk_to_proxy(self):
        "Creating a FK to a proxy model creates database constraints."

        class AuthorProxy(Author):
            class Meta:
                app_label = "schema"
                apps = new_apps
                proxy = True

        class AuthorRef(Model):
            author = ForeignKey(AuthorProxy, on_delete=CASCADE)

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [AuthorProxy, AuthorRef]

        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(AuthorRef)
        self.assertForeignKeyExists(AuthorRef, "author_id", "schema_author")

    @skipUnlessDBFeature("supports_foreign_keys", "can_introspect_foreign_keys")
    def test_fk_db_constraint(self):
        "The db_constraint parameter is respected"
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
            editor.create_model(Author)
            editor.create_model(BookWeak)
        # Initial tables are there
        list(Author.objects.all())
        list(Tag.objects.all())
        list(BookWeak.objects.all())
        self.assertForeignKeyNotExists(BookWeak, "author_id", "schema_author")
        # Make a db_constraint=False FK
        new_field = ForeignKey(Tag, CASCADE, db_constraint=False)
        new_field.set_attributes_from_name("tag")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        self.assertForeignKeyNotExists(Author, "tag_id", "schema_tag")
        # Alter to one with a constraint
        new_field2 = ForeignKey(Tag, CASCADE)
        new_field2.set_attributes_from_name("tag")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, new_field2, strict=True)
        self.assertForeignKeyExists(Author, "tag_id", "schema_tag")
        # Alter to one without a constraint again
        new_field2 = ForeignKey(Tag, CASCADE)
        new_field2.set_attributes_from_name("tag")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field2, new_field, strict=True)
        self.assertForeignKeyNotExists(Author, "tag_id", "schema_tag")

    @isolate_apps("schema")
    def test_no_db_constraint_added_during_primary_key_change(self):
        """
        When a primary key that's pointed to by a ForeignKey with
        db_constraint=False is altered, a foreign key constraint isn't added.
        """

        class Author(Model):
            class Meta:
                app_label = "schema"

        class BookWeak(Model):
            author = ForeignKey(Author, CASCADE, db_constraint=False)

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWeak)
        self.assertForeignKeyNotExists(BookWeak, "author_id", "schema_author")
        old_field = Author._meta.get_field("id")
        new_field = BigAutoField(primary_key=True)
        new_field.model = Author
        new_field.set_attributes_from_name("id")
        # @isolate_apps() and inner models are needed to have the model
        # relations populated, otherwise this doesn't act as a regression test.
        self.assertEqual(len(new_field.model._meta.related_objects), 1)
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertForeignKeyNotExists(BookWeak, "author_id", "schema_author")

    def _test_m2m_db_constraint(self, M2MFieldClass):
        class LocalAuthorWithM2M(Model):
            name = CharField(max_length=255)

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [LocalAuthorWithM2M]

        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
            editor.create_model(LocalAuthorWithM2M)
        # Initial tables are there
        list(LocalAuthorWithM2M.objects.all())
        list(Tag.objects.all())
        # Make a db_constraint=False FK
        new_field = M2MFieldClass(Tag, related_name="authors", db_constraint=False)
        new_field.contribute_to_class(LocalAuthorWithM2M, "tags")
        # Add the field
        with connection.schema_editor() as editor:
            editor.add_field(LocalAuthorWithM2M, new_field)
        self.assertForeignKeyNotExists(
            new_field.remote_field.through, "tag_id", "schema_tag"
        )

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_m2m_db_constraint(self):
        self._test_m2m_db_constraint(ManyToManyField)

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_m2m_db_constraint_custom(self):
        self._test_m2m_db_constraint(CustomManyToManyField)

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_m2m_db_constraint_inherited(self):
        self._test_m2m_db_constraint(InheritedManyToManyField)

    def test_add_field(self):
        """
        Tests adding fields to models
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure there's no age field
        columns = self.column_classes(Author)
        self.assertNotIn("age", columns)
        # Add the new field
        new_field = IntegerField(null=True)
        new_field.set_attributes_from_name("age")
        with (
            CaptureQueriesContext(connection) as ctx,
            connection.schema_editor() as editor,
        ):
            editor.add_field(Author, new_field)
        drop_default_sql = editor.sql_alter_column_no_default % {
            "column": editor.quote_name(new_field.name),
        }
        self.assertFalse(
            any(drop_default_sql in query["sql"] for query in ctx.captured_queries)
        )
        # Table is not rebuilt.
        self.assertIs(
            any("CREATE TABLE" in query["sql"] for query in ctx.captured_queries), False
        )
        self.assertIs(
            any("DROP TABLE" in query["sql"] for query in ctx.captured_queries), False
        )
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["age"][0],
            connection.features.introspected_field_types["IntegerField"],
        )
        self.assertTrue(columns["age"][1][6])

    def test_add_field_remove_field(self):
        """
        Adding a field and removing it removes all deferred sql referring to it.
        """
        with connection.schema_editor() as editor:
            # Create a table with a unique constraint on the slug field.
            editor.create_model(Tag)
            # Remove the slug column.
            editor.remove_field(Tag, Tag._meta.get_field("slug"))
        self.assertEqual(editor.deferred_sql, [])

    def test_add_field_temp_default(self):
        """
        Tests adding fields to models with a temporary default
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure there's no age field
        columns = self.column_classes(Author)
        self.assertNotIn("age", columns)
        # Add some rows of data
        Author.objects.create(name="Andrew", height=30)
        Author.objects.create(name="Andrea")
        # Add a not-null field
        new_field = CharField(max_length=30, default="Godwin")
        new_field.set_attributes_from_name("surname")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["surname"][0],
            connection.features.introspected_field_types["CharField"],
        )
        self.assertEqual(
            columns["surname"][1][6],
            connection.features.interprets_empty_strings_as_nulls,
        )

    def test_add_field_temp_default_boolean(self):
        """
        Tests adding fields to models with a temporary default where
        the default is False. (#21783)
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure there's no age field
        columns = self.column_classes(Author)
        self.assertNotIn("age", columns)
        # Add some rows of data
        Author.objects.create(name="Andrew", height=30)
        Author.objects.create(name="Andrea")
        # Add a not-null field
        new_field = BooleanField(default=False)
        new_field.set_attributes_from_name("awesome")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        columns = self.column_classes(Author)
        # BooleanField are stored as TINYINT(1) on MySQL.
        field_type = columns["awesome"][0]
        self.assertEqual(
            field_type, connection.features.introspected_field_types["BooleanField"]
        )

    def test_add_field_default_transform(self):
        """
        Tests adding fields to models with a default that is not directly
        valid in the database (#22581)
        """

        class TestTransformField(IntegerField):
            # Weird field that saves the count of items in its value
            def get_default(self):
                return self.default

            def get_prep_value(self, value):
                """

                Returns the prepared value for use in a database query.

                The prepared value is calculated as the length of the input value if it is not None.
                If the input value is None, the prepared value is 0.

                """
                if value is None:
                    return 0
                return len(value)

        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Add some rows of data
        Author.objects.create(name="Andrew", height=30)
        Author.objects.create(name="Andrea")
        # Add the field with a default it needs to cast (to string in this case)
        new_field = TestTransformField(default={1: 2})
        new_field.set_attributes_from_name("thing")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        # Ensure the field is there
        columns = self.column_classes(Author)
        field_type, field_info = columns["thing"]
        self.assertEqual(
            field_type, connection.features.introspected_field_types["IntegerField"]
        )
        # Make sure the values were transformed correctly
        self.assertEqual(Author.objects.extra(where=["thing = 1"]).count(), 2)

    def test_add_field_o2o_nullable(self):
        """
        Tests the addition of a nullable one-to-one field to a model.

        This test case creates two models, Author and Note, and then adds a new one-to-one field
        to the Author model that references the Note model. The field is defined as nullable,
        meaning it can accept null values. The test verifies that the field is successfully added
        to the Author model and that the resulting database column allows null values.

        The test covers the following scenarios:

        * Creation of models using a schema editor
        * Addition of a nullable one-to-one field to a model
        * Verification of the added field's properties, including its nullability
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Note)
        new_field = OneToOneField(Note, CASCADE, null=True)
        new_field.set_attributes_from_name("note")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        columns = self.column_classes(Author)
        self.assertIn("note_id", columns)
        self.assertTrue(columns["note_id"][1][6])

    def test_add_field_binary(self):
        """
        Tests binary fields get a sane default (#22851)
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Add the new field
        new_field = BinaryField(blank=True)
        new_field.set_attributes_from_name("bits")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        columns = self.column_classes(Author)
        # MySQL annoyingly uses the same backend, so it'll come back as one of
        # these two types.
        self.assertIn(columns["bits"][0], ("BinaryField", "TextField"))

    def test_add_field_durationfield_with_default(self):
        """
        Tests adding a DurationField with a default value to an existing model.

        This test case verifies that a DurationField can be successfully added to a model
        with a default duration of 10 minutes. The test creates a new model, adds the
        DurationField to it, and then checks that the field type is correctly
        introspected from the database.

        The purpose of this test is to ensure that the database schema is updated
        correctly when adding a new field with a default value to an existing model.‚Äù
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        new_field = DurationField(default=datetime.timedelta(minutes=10))
        new_field.set_attributes_from_name("duration")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["duration"][0],
            connection.features.introspected_field_types["DurationField"],
        )

    @unittest.skipUnless(connection.vendor == "mysql", "MySQL specific")
    def test_add_binaryfield_mediumblob(self):
        """
        Test adding a custom-sized binary field on MySQL (#24846).
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Add the new field with default
        new_field = MediumBlobField(blank=True, default=b"123")
        new_field.set_attributes_from_name("bits")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        columns = self.column_classes(Author)
        # Introspection treats BLOBs as TextFields
        self.assertEqual(columns["bits"][0], "TextField")

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_json_field", "supports_stored_generated_columns")
    def test_add_generated_field_with_kt_model(self):
        """
        Tests the addition of a generated field to a model using KeyTransformer (KT) expressions.

        Verifies that creating a model with a generated field using a KT expression does not result in
        SQL queries containing 'None' values. The test coverage includes the creation of a sample model
        with a JSON field and a generated field based on the JSON field, ensuring database support for
        JSON fields and stored generated columns.

        The test case uses the `supports_json_field` and `supports_stored_generated_columns` database
        features to guarantee compatibility and isolate the test to the 'schema' app for accurate results.
        """
        class GeneratedFieldKTModel(Model):
            data = JSONField()
            status = GeneratedField(
                expression=KT("data__status"),
                output_field=TextField(),
                db_persist=True,
            )

            class Meta:
                app_label = "schema"

        with CaptureQueriesContext(connection) as ctx:
            with connection.schema_editor() as editor:
                editor.create_model(GeneratedFieldKTModel)
        self.assertIs(
            any("None" in query["sql"] for query in ctx.captured_queries),
            False,
        )

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_virtual_generated_columns")
    def test_add_generated_boolean_field(self):
        class GeneratedBooleanFieldModel(Model):
            value = IntegerField(null=True)
            has_value = GeneratedField(
                expression=Q(value__isnull=False),
                output_field=BooleanField(),
                db_persist=False,
            )

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(GeneratedBooleanFieldModel)
        obj = GeneratedBooleanFieldModel.objects.create()
        self.assertIs(obj.has_value, False)
        obj = GeneratedBooleanFieldModel.objects.create(value=1)
        self.assertIs(obj.has_value, True)

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_stored_generated_columns")
    def test_add_generated_field(self):
        """

        Tests the addition of a generated field to a model.

        This test case creates a temporary model with a generated field that calculates the VAT price based on the original price.
        It then creates the model in the database using a schema editor, verifying that the generated field is correctly defined and persisted.

        The test requires a database that supports stored generated columns and is isolated to the 'schema' app.

        """
        class GeneratedFieldOutputFieldModel(Model):
            price = DecimalField(max_digits=7, decimal_places=2)
            vat_price = GeneratedField(
                expression=Round(F("price") * Value(Decimal("1.22")), 2),
                db_persist=True,
                output_field=DecimalField(max_digits=8, decimal_places=2),
            )

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(GeneratedFieldOutputFieldModel)

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_stored_generated_columns")
    def test_add_generated_field_contains(self):
        """

        Test adding a generated field that contains a given value.

        This test case exercises the functionality of adding a generated field to a model,
        specifically when the field is defined with a \"contains\" type of check.
        It creates a temporary model, adds a generated field to it, and then verifies that
        the generated field is correctly computed based on the specified expression.

        The generated field in this test uses a database-level \"contains\" operation to
        determine whether a given text field contains a specific value.
        The test ensures that this generated field is properly added to the model and
        that its value is correctly calculated.

        """
        class GeneratedFieldContainsModel(Model):
            text = TextField(default="foo")
            generated = GeneratedField(
                expression=Concat("text", Value("%")),
                db_persist=True,
                output_field=TextField(),
            )

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(GeneratedFieldContainsModel)

        field = GeneratedField(
            expression=Q(text__contains="foo"),
            db_persist=True,
            output_field=BooleanField(),
        )
        field.contribute_to_class(GeneratedFieldContainsModel, "contains_foo")

        with connection.schema_editor() as editor:
            editor.add_field(GeneratedFieldContainsModel, field)

        obj = GeneratedFieldContainsModel.objects.create()
        obj.refresh_from_db()
        self.assertEqual(obj.text, "foo")
        self.assertEqual(obj.generated, "foo%")
        self.assertIs(obj.contains_foo, True)

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_stored_generated_columns")
    def test_alter_generated_field(self):
        """

        Tests altering a generated field to add a database index.

        Verifies that the 'supports_stored_generated_columns' database feature is available
        and then creates a model with a generated field. The generated field is initially 
        created without a database index. The test then alters the field to include a 
        database index and checks that the index was successfully created.

        """
        class GeneratedFieldIndexedModel(Model):
            number = IntegerField(default=1)
            generated = GeneratedField(
                expression=F("number"),
                db_persist=True,
                output_field=IntegerField(),
            )

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(GeneratedFieldIndexedModel)

        old_field = GeneratedFieldIndexedModel._meta.get_field("generated")
        new_field = GeneratedField(
            expression=F("number"),
            db_persist=True,
            db_index=True,
            output_field=IntegerField(),
        )
        new_field.contribute_to_class(GeneratedFieldIndexedModel, "generated")

        with connection.schema_editor() as editor:
            editor.alter_field(GeneratedFieldIndexedModel, old_field, new_field)

        self.assertIn(
            "generated", self.get_indexes(GeneratedFieldIndexedModel._meta.db_table)
        )

    @isolate_apps("schema")
    def test_add_auto_field(self):
        """
        Tests the addition of an auto field to a model.

        This test case creates a new model with a character field as the primary key,
        then alters the field to remove the primary key attribute, and finally
        adds a new auto field to the model. The test ensures that the model can
        still be used to create new instances after the field additions and alterations.

        The process includes creating a model, modifying its field, adding a new field,
        and verifying that the model remains functional after these changes.
        """
        class AddAutoFieldModel(Model):
            name = CharField(max_length=255, primary_key=True)

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(AddAutoFieldModel)
        self.isolated_local_models = [AddAutoFieldModel]
        old_field = AddAutoFieldModel._meta.get_field("name")
        new_field = CharField(max_length=255)
        new_field.set_attributes_from_name("name")
        new_field.model = AddAutoFieldModel
        with connection.schema_editor() as editor:
            editor.alter_field(AddAutoFieldModel, old_field, new_field)
        new_auto_field = AutoField(primary_key=True)
        new_auto_field.set_attributes_from_name("id")
        new_auto_field.model = AddAutoFieldModel()
        with connection.schema_editor() as editor:
            editor.add_field(AddAutoFieldModel, new_auto_field)
        # Crashes on PostgreSQL when the GENERATED BY suffix is missing.
        AddAutoFieldModel.objects.create(name="test")

    def test_remove_field(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            with CaptureQueriesContext(connection) as ctx:
                editor.remove_field(Author, Author._meta.get_field("name"))
        columns = self.column_classes(Author)
        self.assertNotIn("name", columns)
        if getattr(connection.features, "can_alter_table_drop_column", True):
            # Table is not rebuilt.
            self.assertIs(
                any("CREATE TABLE" in query["sql"] for query in ctx.captured_queries),
                False,
            )
            self.assertIs(
                any("DROP TABLE" in query["sql"] for query in ctx.captured_queries),
                False,
            )

    def test_remove_indexed_field(self):
        """
        Tests the removal of an indexed field from a model.

        Verifies that after removing a field with an index, the field and its index are correctly deleted from the database schema.

        Checks that the removed field is no longer present in the model's column classes after removal.

        Ensures that the removal process is executed within the scope of a schema editor to maintain database integrity.
        """
        with connection.schema_editor() as editor:
            editor.create_model(AuthorCharFieldWithIndex)
        with connection.schema_editor() as editor:
            editor.remove_field(
                AuthorCharFieldWithIndex,
                AuthorCharFieldWithIndex._meta.get_field("char_field"),
            )
        columns = self.column_classes(AuthorCharFieldWithIndex)
        self.assertNotIn("char_field", columns)

    def test_alter(self):
        """
        Tests simple altering of fields
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the field is right to begin with
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["name"][0],
            connection.features.introspected_field_types["CharField"],
        )
        self.assertEqual(
            bool(columns["name"][1][6]),
            bool(connection.features.interprets_empty_strings_as_nulls),
        )
        # Alter the name field to a TextField
        old_field = Author._meta.get_field("name")
        new_field = TextField(null=True)
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        columns = self.column_classes(Author)
        self.assertEqual(columns["name"][0], "TextField")
        self.assertTrue(columns["name"][1][6])
        # Change nullability again
        new_field2 = TextField(null=False)
        new_field2.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, new_field2, strict=True)
        columns = self.column_classes(Author)
        self.assertEqual(columns["name"][0], "TextField")
        self.assertEqual(
            bool(columns["name"][1][6]),
            bool(connection.features.interprets_empty_strings_as_nulls),
        )

    def test_alter_auto_field_to_integer_field(self):
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Change AutoField to IntegerField
        old_field = Author._meta.get_field("id")
        new_field = IntegerField(primary_key=True)
        new_field.set_attributes_from_name("id")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        # Now that ID is an IntegerField, the database raises an error if it
        # isn't provided.
        if not connection.features.supports_unspecified_pk:
            with self.assertRaises(DatabaseError):
                Author.objects.create()

    def test_alter_auto_field_to_char_field(self):
        # Create the table
        """

        Tests the alteration of an auto field to a character field in a model.

        This test case checks the feasibility of changing an auto-incrementing primary key
        field to a character field, which can be useful when migrating a model to use a
        different type of identifier.

        The test creates a model instance, retrieves its original primary key field, 
        defines a new character field with primary key characteristics, and then 
        performs the field alteration via a schema editor.

        The test is performed with strict mode enabled, ensuring that any errors 
        encountered during the alteration process are immediately propagated.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Change AutoField to CharField
        old_field = Author._meta.get_field("id")
        new_field = CharField(primary_key=True, max_length=50)
        new_field.set_attributes_from_name("id")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)

    @isolate_apps("schema")
    def test_alter_auto_field_quoted_db_column(self):
        """

        Tests the alteration of an auto field to a big auto field when the database column name is quoted.

        This test case checks the process of changing an AutoField to a BigAutoField while preserving the quoted database column name.
        It verifies that the field alteration is successful and does not disrupt the model's functionality.

        The test involves creating a model with a quoted database column name, altering the field, and then verifying the successful creation of a new instance of the model.

        """
        class Foo(Model):
            id = AutoField(primary_key=True, db_column='"quoted_id"')

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Foo)
        self.isolated_local_models = [Foo]
        old_field = Foo._meta.get_field("id")
        new_field = BigAutoField(primary_key=True)
        new_field.model = Foo
        new_field.db_column = '"quoted_id"'
        new_field.set_attributes_from_name("id")
        with connection.schema_editor() as editor:
            editor.alter_field(Foo, old_field, new_field, strict=True)
        Foo.objects.create()

    def test_alter_not_unique_field_to_primary_key(self):
        # Create the table.
        """

        Tests that altering a non-unique field to a primary key field removes any existing unique constraints.

        This test case ensures that when a field is altered to become the primary key, 
        any existing unique constraints on that field are removed, 
        leaving at most one unique constraint, which is the primary key constraint.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Change UUIDField to primary key.
        old_field = Author._meta.get_field("uuid")
        new_field = UUIDField(primary_key=True)
        new_field.set_attributes_from_name("uuid")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.remove_field(Author, Author._meta.get_field("id"))
            editor.alter_field(Author, old_field, new_field, strict=True)
        # Redundant unique constraint is not added.
        count = self.get_constraints_count(
            Author._meta.db_table,
            Author._meta.get_field("uuid").column,
            None,
        )
        self.assertLessEqual(count["uniques"], 1)

    @isolate_apps("schema")
    def test_alter_primary_key_quoted_db_table(self):
        """

        Tests the alteration of a primary key field for a quoted database table.

        This test case creates a model instance with a quoted db_table name, 
        adds it to the database, and then alters its primary key field from an 
        auto field to a big auto field. The purpose is to verify that the 
        database schema can be successfully modified when the table name 
        is enclosed in quotes.

        The test covers the creation of a model, the initial setup of its 
        primary key field, and the subsequent alteration of this field 
        using the database schema editor. The test verifies that these 
        operations can be performed without errors, ensuring the correct 
        functionality of the database schema modification APIs.

        """
        class Foo(Model):
            class Meta:
                app_label = "schema"
                db_table = '"foo"'

        with connection.schema_editor() as editor:
            editor.create_model(Foo)
        self.isolated_local_models = [Foo]
        old_field = Foo._meta.get_field("id")
        new_field = BigAutoField(primary_key=True)
        new_field.model = Foo
        new_field.set_attributes_from_name("id")
        with connection.schema_editor() as editor:
            editor.alter_field(Foo, old_field, new_field, strict=True)
        Foo.objects.create()

    def test_alter_text_field(self):
        # Regression for "BLOB/TEXT column 'info' can't have a default value")
        # on MySQL.
        # Create the table
        """

        Alters the 'info' field in the Note model to a TextField with blank=True.

        This test case verifies the alteration of an existing field in a Django model.
        It first creates the Note model, then it retrieves the existing 'info' field and creates a new TextField with the same name.
        The alteration is then applied using a schema editor, which modifies the database schema accordingly.

        The test ensures that the field alteration is successful and the new field attributes are applied correctly.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        old_field = Note._meta.get_field("info")
        new_field = TextField(blank=True)
        new_field.set_attributes_from_name("info")
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)

    def test_alter_text_field_to_not_null_with_default_value(self):
        """

        Tests altering a text field to not null with a default value.

        Verifies that when a text field is altered to disallow null values and a default value is provided,
        existing null values are updated to the default value. This ensures data consistency after the schema change.

        The test creates a model instance with a null value in the text field, alters the field to not null with a default value,
        and then checks that the existing null value has been replaced with the default value.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        note = Note.objects.create(address=None)
        old_field = Note._meta.get_field("address")
        new_field = TextField(blank=True, default="", null=False)
        new_field.set_attributes_from_name("address")
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)
        note.refresh_from_db()
        self.assertEqual(note.address, "")

    @skipUnlessDBFeature("can_defer_constraint_checks", "can_rollback_ddl")
    def test_alter_fk_checks_deferred_constraints(self):
        """
        #25492 - Altering a foreign key's structure and data in the same
        transaction.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Node)
        old_field = Node._meta.get_field("parent")
        new_field = ForeignKey(Node, CASCADE)
        new_field.set_attributes_from_name("parent")
        parent = Node.objects.create()
        with connection.schema_editor() as editor:
            # Update the parent FK to create a deferred constraint check.
            Node.objects.update(parent=parent)
            editor.alter_field(Node, old_field, new_field, strict=True)

    @isolate_apps("schema")
    def test_alter_null_with_default_value_deferred_constraints(self):
        """

        Tests the alteration of null fields with default values to non-null fields 
        with default values while deferred constraints are applied.

        This function first creates models for Publisher and Article. 
        It then creates instances of these models and alters the fields 'title' and 'description' 
        in the Article model from nullable to non-nullable with a default value, 
        ensuring that the changes are applied correctly with deferred constraint checking.

        """
        class Publisher(Model):
            class Meta:
                app_label = "schema"

        class Article(Model):
            publisher = ForeignKey(Publisher, CASCADE)
            title = CharField(max_length=50, null=True)
            description = CharField(max_length=100, null=True)

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Publisher)
            editor.create_model(Article)
        self.isolated_local_models = [Article, Publisher]

        publisher = Publisher.objects.create()
        Article.objects.create(publisher=publisher)

        old_title = Article._meta.get_field("title")
        new_title = CharField(max_length=50, null=False, default="")
        new_title.set_attributes_from_name("title")
        old_description = Article._meta.get_field("description")
        new_description = CharField(max_length=100, null=False, default="")
        new_description.set_attributes_from_name("description")
        with connection.schema_editor() as editor:
            editor.alter_field(Article, old_title, new_title, strict=True)
            editor.alter_field(Article, old_description, new_description, strict=True)

    def test_alter_text_field_to_date_field(self):
        """
        #25002 - Test conversion of text field to date field.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        Note.objects.create(info="1988-05-05")
        old_field = Note._meta.get_field("info")
        new_field = DateField(blank=True)
        new_field.set_attributes_from_name("info")
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)
        # Make sure the field isn't nullable
        columns = self.column_classes(Note)
        self.assertFalse(columns["info"][1][6])

    def test_alter_text_field_to_datetime_field(self):
        """
        #25002 - Test conversion of text field to datetime field.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        Note.objects.create(info="1988-05-05 3:16:17.4567")
        old_field = Note._meta.get_field("info")
        new_field = DateTimeField(blank=True)
        new_field.set_attributes_from_name("info")
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)
        # Make sure the field isn't nullable
        columns = self.column_classes(Note)
        self.assertFalse(columns["info"][1][6])

    def test_alter_text_field_to_time_field(self):
        """
        #25002 - Test conversion of text field to time field.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        Note.objects.create(info="3:16:17.4567")
        old_field = Note._meta.get_field("info")
        new_field = TimeField(blank=True)
        new_field.set_attributes_from_name("info")
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)
        # Make sure the field isn't nullable
        columns = self.column_classes(Note)
        self.assertFalse(columns["info"][1][6])

    @skipIfDBFeature("interprets_empty_strings_as_nulls")
    def test_alter_textual_field_keep_null_status(self):
        """
        Changing a field type shouldn't affect the not null status.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        with self.assertRaises(IntegrityError):
            Note.objects.create(info=None)
        old_field = Note._meta.get_field("info")
        new_field = CharField(max_length=50)
        new_field.set_attributes_from_name("info")
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)
        with self.assertRaises(IntegrityError):
            Note.objects.create(info=None)

    @skipUnlessDBFeature("interprets_empty_strings_as_nulls")
    def test_alter_textual_field_not_null_to_null(self):
        """
        Nullability for textual fields is preserved on databases that
        interpret empty strings as NULLs.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        columns = self.column_classes(Author)
        # Field is nullable.
        self.assertTrue(columns["uuid"][1][6])
        # Change to NOT NULL.
        old_field = Author._meta.get_field("uuid")
        new_field = SlugField(null=False, blank=True)
        new_field.set_attributes_from_name("uuid")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        columns = self.column_classes(Author)
        # Nullability is preserved.
        self.assertTrue(columns["uuid"][1][6])

    def test_alter_numeric_field_keep_null_status(self):
        """
        Changing a field type shouldn't affect the not null status.
        """
        with connection.schema_editor() as editor:
            editor.create_model(UniqueTest)
        with self.assertRaises(IntegrityError):
            UniqueTest.objects.create(year=None, slug="aaa")
        old_field = UniqueTest._meta.get_field("year")
        new_field = BigIntegerField()
        new_field.set_attributes_from_name("year")
        with connection.schema_editor() as editor:
            editor.alter_field(UniqueTest, old_field, new_field, strict=True)
        with self.assertRaises(IntegrityError):
            UniqueTest.objects.create(year=None, slug="bbb")

    def test_alter_null_to_not_null(self):
        """
        #23609 - Tests handling of default values when altering from NULL to NOT NULL.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the field is right to begin with
        columns = self.column_classes(Author)
        self.assertTrue(columns["height"][1][6])
        # Create some test data
        Author.objects.create(name="Not null author", height=12)
        Author.objects.create(name="Null author")
        # Verify null value
        self.assertEqual(Author.objects.get(name="Not null author").height, 12)
        self.assertIsNone(Author.objects.get(name="Null author").height)
        # Alter the height field to NOT NULL with default
        old_field = Author._meta.get_field("height")
        new_field = PositiveIntegerField(default=42)
        new_field.set_attributes_from_name("height")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        columns = self.column_classes(Author)
        self.assertFalse(columns["height"][1][6])
        # Verify default value
        self.assertEqual(Author.objects.get(name="Not null author").height, 12)
        self.assertEqual(Author.objects.get(name="Null author").height, 42)

    def test_alter_charfield_to_null(self):
        """
        #24307 - Should skip an alter statement on databases with
        interprets_empty_strings_as_nulls when changing a CharField to null.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Change the CharField to null
        old_field = Author._meta.get_field("name")
        new_field = copy(old_field)
        new_field.null = True
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_char_field_decrease_length(self):
        # Create the table.
        """

        Tests the alteration of a character field when decreasing its length.

        This test case simulates the scenario where a character field's length is decreased.
        It verifies that attempting to alter the field with a new, shorter length will fail
        if the existing data exceeds the new length.

        The test focuses on PostgreSQL-specific behavior, checking that a DataError is raised
        when the alteration would result in data truncation.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        Author.objects.create(name="x" * 255)
        # Change max_length of CharField.
        old_field = Author._meta.get_field("name")
        new_field = CharField(max_length=254)
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            msg = "value too long for type character varying(254)"
            with self.assertRaisesMessage(DataError, msg):
                editor.alter_field(Author, old_field, new_field, strict=True)

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_field_with_custom_db_type(self):
        """

        Tests the alteration of a model field with a custom database type, 
        specifically the PostgreSQL ArrayField, to ensure it is handled correctly.

        This test case creates a temporary model with an ArrayField, 
        then attempts to alter the field to a new instance with a changed max_length, 
        verifying that the schema editor correctly applies the changes to the database.

        """
        from django.contrib.postgres.fields import ArrayField

        class Foo(Model):
            field = ArrayField(CharField(max_length=255))

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Foo)
        self.isolated_local_models = [Foo]
        old_field = Foo._meta.get_field("field")
        new_field = ArrayField(CharField(max_length=16))
        new_field.set_attributes_from_name("field")
        new_field.model = Foo
        with connection.schema_editor() as editor:
            editor.alter_field(Foo, old_field, new_field, strict=True)

    @isolate_apps("schema")
    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_array_field_decrease_base_field_length(self):
        """

        Test decreasing the base field length of an array field in PostgreSQL.

        This test case verifies that attempting to decrease the base field length of an
        array field results in a DataError when the new length is less than the length
        of existing data. The test creates a model with an array field, populates the
        field with data, and then attempts to alter the field to have a shorter base
        field length.

        The expected behavior is that a DataError is raised when the alter operation
        is executed, indicating that the new length is too short to accommodate the
        existing data.

        """
        from django.contrib.postgres.fields import ArrayField

        class ArrayModel(Model):
            field = ArrayField(CharField(max_length=16))

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(ArrayModel)
        self.isolated_local_models = [ArrayModel]
        ArrayModel.objects.create(field=["x" * 16])
        old_field = ArrayModel._meta.get_field("field")
        new_field = ArrayField(CharField(max_length=15))
        new_field.set_attributes_from_name("field")
        new_field.model = ArrayModel
        with connection.schema_editor() as editor:
            msg = "value too long for type character varying(15)"
            with self.assertRaisesMessage(DataError, msg):
                editor.alter_field(ArrayModel, old_field, new_field, strict=True)

    @isolate_apps("schema")
    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_array_field_decrease_nested_base_field_length(self):
        """

        Tests altering a PostgreSQL array field by decreasing the length of its nested base field.

        This test case creates a model with a nested array field, populates it with data, and then attempts to alter the field by decreasing the length of its base field.
        The test verifies that a DataError is raised when the altered field is too restrictive for the existing data.

        The test is specific to PostgreSQL and requires a PostgreSQL database connection to run.

        """
        from django.contrib.postgres.fields import ArrayField

        class ArrayModel(Model):
            field = ArrayField(ArrayField(CharField(max_length=16)))

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(ArrayModel)
        self.isolated_local_models = [ArrayModel]
        ArrayModel.objects.create(field=[["x" * 16]])
        old_field = ArrayModel._meta.get_field("field")
        new_field = ArrayField(ArrayField(CharField(max_length=15)))
        new_field.set_attributes_from_name("field")
        new_field.model = ArrayModel
        with connection.schema_editor() as editor:
            msg = "value too long for type character varying(15)"
            with self.assertRaisesMessage(DataError, msg):
                editor.alter_field(ArrayModel, old_field, new_field, strict=True)

    def _add_ci_collation(self):
        ci_collation = "case_insensitive"

        def drop_collation():
            with connection.cursor() as cursor:
                cursor.execute(f"DROP COLLATION IF EXISTS {ci_collation}")

        with connection.cursor() as cursor:
            cursor.execute(
                f"CREATE COLLATION IF NOT EXISTS {ci_collation} (provider=icu, "
                f"locale='und-u-ks-level2', deterministic=false)"
            )
        self.addCleanup(drop_collation)
        return ci_collation

    @isolate_apps("schema")
    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    @skipUnlessDBFeature(
        "supports_collation_on_charfield",
        "supports_non_deterministic_collations",
    )
    def test_db_collation_arrayfield(self):
        """

        Tests the PostgreSQL collation support for ArrayField in the database.

        This test creates a model with an ArrayField that uses a case-insensitive collation,
        verifies that the correct collation is used, alters the field's collation to case-sensitive,
        and then verifies that the new collation is used.

        The test requires a PostgreSQL database and the 'supports_collation_on_charfield'
        and 'supports_non_deterministic_collations' database features to be supported.

        """
        from django.contrib.postgres.fields import ArrayField

        ci_collation = self._add_ci_collation()
        cs_collation = "en-x-icu"

        class ArrayModel(Model):
            field = ArrayField(CharField(max_length=16, db_collation=ci_collation))

            class Meta:
                app_label = "schema"

        # Create the table.
        with connection.schema_editor() as editor:
            editor.create_model(ArrayModel)
        self.isolated_local_models = [ArrayModel]
        self.assertEqual(
            self.get_column_collation(ArrayModel._meta.db_table, "field"),
            ci_collation,
        )
        # Alter collation.
        old_field = ArrayModel._meta.get_field("field")
        new_field_cs = ArrayField(CharField(max_length=16, db_collation=cs_collation))
        new_field_cs.set_attributes_from_name("field")
        new_field_cs.model = ArrayField
        with connection.schema_editor() as editor:
            editor.alter_field(ArrayModel, old_field, new_field_cs, strict=True)
        self.assertEqual(
            self.get_column_collation(ArrayModel._meta.db_table, "field"),
            cs_collation,
        )

    @isolate_apps("schema")
    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    @skipUnlessDBFeature(
        "supports_collation_on_charfield",
        "supports_non_deterministic_collations",
    )
    def test_unique_with_collation_charfield(self):
        ci_collation = self._add_ci_collation()

        class CiCharModel(Model):
            field = CharField(max_length=16, db_collation=ci_collation, unique=True)

            class Meta:
                app_label = "schema"

        # Create the table.
        with connection.schema_editor() as editor:
            editor.create_model(CiCharModel)
        self.isolated_local_models = [CiCharModel]
        self.assertEqual(
            self.get_column_collation(CiCharModel._meta.db_table, "field"),
            ci_collation,
        )
        self.assertIn("field", self.get_uniques(CiCharModel._meta.db_table))

    @isolate_apps("schema")
    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    @skipUnlessDBFeature("supports_collation_on_charfield")
    def test_unique_with_deterministic_collation_charfield(self):
        """

        Tests that unique CharField instances on PostgreSQL with deterministic collation are correctly created.

        This test case verifies that when a CharField is defined with a unique constraint and a deterministic collation,
        the database correctly applies the collation and ensures uniqueness of the field's values.

        It checks that the created constraint uses the `varchar_pattern_ops` operator class and the specified deterministic collation.
        The test also confirms that the column's collation is correctly set to the deterministic collation and that the field is included in the table's unique constraints.

        The test is skipped if the database backend does not support deterministic collations or if the connection vendor is not PostgreSQL.

        """
        deterministic_collation = connection.features.test_collations.get(
            "deterministic"
        )
        if not deterministic_collation:
            self.skipTest("This backend does not support deterministic collations.")

        class CharModel(Model):
            field = CharField(db_collation=deterministic_collation, unique=True)

            class Meta:
                app_label = "schema"

        # Create the table.
        with connection.schema_editor() as editor:
            editor.create_model(CharModel)
        self.isolated_local_models = [CharModel]
        constraints = self.get_constraints_for_column(
            CharModel, CharModel._meta.get_field("field").column
        )
        self.assertIn("schema_charmodel_field_8b338dea_like", constraints)
        self.assertIn(
            "varchar_pattern_ops",
            self.get_constraint_opclasses("schema_charmodel_field_8b338dea_like"),
        )
        self.assertEqual(
            self.get_column_collation(CharModel._meta.db_table, "field"),
            deterministic_collation,
        )
        self.assertIn("field", self.get_uniques(CharModel._meta.db_table))

    @isolate_apps("schema")
    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    @skipUnlessDBFeature(
        "supports_collation_on_charfield",
        "supports_non_deterministic_collations",
    )
    def test_relation_to_collation_charfield(self):
        """

        Tests that a OneToOneField referencing a CharField with a case-insensitive collation 
        inherently sets the same collation on the referencing field in the database.

        This test case ensures that when a model has a OneToOneField that references a 
        CharField with a specific collation, the column for the OneToOneField in the 
        database is created with the same collation as the referenced CharField. It also 
        verifies that the uniqueness constraint is applied correctly to the referencing 
        field.

        The test is specific to PostgreSQL databases and requires support for 
        non-deterministic collations and collations on CharFields.

        """
        ci_collation = self._add_ci_collation()

        class CiCharModel(Model):
            field = CharField(max_length=16, db_collation=ci_collation, unique=True)

            class Meta:
                app_label = "schema"

        class RelationModel(Model):
            field = OneToOneField(CiCharModel, CASCADE, to_field="field")

            class Meta:
                app_label = "schema"

        # Create the table.
        with connection.schema_editor() as editor:
            editor.create_model(CiCharModel)
            editor.create_model(RelationModel)
        self.isolated_local_models = [CiCharModel, RelationModel]
        self.assertEqual(
            self.get_column_collation(RelationModel._meta.db_table, "field_id"),
            ci_collation,
        )
        self.assertEqual(
            self.get_column_collation(CiCharModel._meta.db_table, "field"),
            ci_collation,
        )
        self.assertIn("field_id", self.get_uniques(RelationModel._meta.db_table))

    @isolate_apps("schema")
    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    @skipUnlessDBFeature("supports_collation_on_charfield")
    def test_relation_to_deterministic_collation_charfield(self):
        """
        Tests the behavior of a One-To-One relation to a CharField with deterministic collation.

        This test is PostgreSQL specific and requires the support of collation on CharField.
        It checks that the deterministic collation is correctly applied to the CharField and
        its related One-To-One field in the RelationModel, verifying the creation of
        like constraints and opclasses, as well as the column collation and uniqueness.
        The test ensures that the database correctly handles the relation to a CharField
        with deterministic collation.
        """
        deterministic_collation = connection.features.test_collations.get(
            "deterministic"
        )
        if not deterministic_collation:
            self.skipTest("This backend does not support deterministic collations.")

        class CharModel(Model):
            field = CharField(db_collation=deterministic_collation, unique=True)

            class Meta:
                app_label = "schema"

        class RelationModel(Model):
            field = OneToOneField(CharModel, CASCADE, to_field="field")

            class Meta:
                app_label = "schema"

        # Create the table.
        with connection.schema_editor() as editor:
            editor.create_model(CharModel)
            editor.create_model(RelationModel)
        self.isolated_local_models = [CharModel, RelationModel]
        constraints = self.get_constraints_for_column(
            CharModel, CharModel._meta.get_field("field").column
        )
        self.assertIn("schema_charmodel_field_8b338dea_like", constraints)
        self.assertIn(
            "varchar_pattern_ops",
            self.get_constraint_opclasses("schema_charmodel_field_8b338dea_like"),
        )
        rel_constraints = self.get_constraints_for_column(
            RelationModel, RelationModel._meta.get_field("field").column
        )
        self.assertIn("schema_relationmodel_field_id_395fbb08_like", rel_constraints)
        self.assertIn(
            "varchar_pattern_ops",
            self.get_constraint_opclasses(
                "schema_relationmodel_field_id_395fbb08_like"
            ),
        )
        self.assertEqual(
            self.get_column_collation(RelationModel._meta.db_table, "field_id"),
            deterministic_collation,
        )
        self.assertEqual(
            self.get_column_collation(CharModel._meta.db_table, "field"),
            deterministic_collation,
        )
        self.assertIn("field_id", self.get_uniques(RelationModel._meta.db_table))

    def test_alter_textfield_to_null(self):
        """
        #24307 - Should skip an alter statement on databases with
        interprets_empty_strings_as_nulls when changing a TextField to null.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        # Change the TextField to null
        old_field = Note._meta.get_field("info")
        new_field = copy(old_field)
        new_field.null = True
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)

    def test_alter_null_to_not_null_keeping_default(self):
        """
        #23738 - Can change a nullable field with default to non-nullable
        with the same default.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithDefaultHeight)
        # Ensure the field is right to begin with
        columns = self.column_classes(AuthorWithDefaultHeight)
        self.assertTrue(columns["height"][1][6])
        # Alter the height field to NOT NULL keeping the previous default
        old_field = AuthorWithDefaultHeight._meta.get_field("height")
        new_field = PositiveIntegerField(default=42)
        new_field.set_attributes_from_name("height")
        with connection.schema_editor() as editor:
            editor.alter_field(
                AuthorWithDefaultHeight, old_field, new_field, strict=True
            )
        columns = self.column_classes(AuthorWithDefaultHeight)
        self.assertFalse(columns["height"][1][6])

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_alter_fk(self):
        """
        Tests altering of FKs
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        # Ensure the field is right to begin with
        columns = self.column_classes(Book)
        self.assertEqual(
            columns["author_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )
        self.assertForeignKeyExists(Book, "author_id", "schema_author")
        # Alter the FK
        old_field = Book._meta.get_field("author")
        new_field = ForeignKey(Author, CASCADE, editable=False)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(Book, old_field, new_field, strict=True)
        columns = self.column_classes(Book)
        self.assertEqual(
            columns["author_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )
        self.assertForeignKeyExists(Book, "author_id", "schema_author")

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_alter_to_fk(self):
        """
        #24447 - Tests adding a FK constraint for an existing column
        """

        class LocalBook(Model):
            author = IntegerField()
            title = CharField(max_length=100, db_index=True)
            pub_date = DateTimeField()

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [LocalBook]

        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(LocalBook)
        # Ensure no FK constraint exists
        constraints = self.get_constraints(LocalBook._meta.db_table)
        for details in constraints.values():
            if details["foreign_key"]:
                self.fail(
                    "Found an unexpected FK constraint to %s" % details["columns"]
                )
        old_field = LocalBook._meta.get_field("author")
        new_field = ForeignKey(Author, CASCADE)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(LocalBook, old_field, new_field, strict=True)
        self.assertForeignKeyExists(LocalBook, "author_id", "schema_author")

    @skipUnlessDBFeature("supports_foreign_keys", "can_introspect_foreign_keys")
    def test_alter_o2o_to_fk(self):
        """
        #24163 - Tests altering of OneToOneField to ForeignKey
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithO2O)
        # Ensure the field is right to begin with
        columns = self.column_classes(BookWithO2O)
        self.assertEqual(
            columns["author_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )
        # Ensure the field is unique
        author = Author.objects.create(name="Joe")
        BookWithO2O.objects.create(
            author=author, title="Django 1", pub_date=datetime.datetime.now()
        )
        with self.assertRaises(IntegrityError):
            BookWithO2O.objects.create(
                author=author, title="Django 2", pub_date=datetime.datetime.now()
            )
        BookWithO2O.objects.all().delete()
        self.assertForeignKeyExists(BookWithO2O, "author_id", "schema_author")
        # Alter the OneToOneField to ForeignKey
        old_field = BookWithO2O._meta.get_field("author")
        new_field = ForeignKey(Author, CASCADE)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithO2O, old_field, new_field, strict=True)
        columns = self.column_classes(Book)
        self.assertEqual(
            columns["author_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )
        # Ensure the field is not unique anymore
        Book.objects.create(
            author=author, title="Django 1", pub_date=datetime.datetime.now()
        )
        Book.objects.create(
            author=author, title="Django 2", pub_date=datetime.datetime.now()
        )
        self.assertForeignKeyExists(Book, "author_id", "schema_author")

    @skipUnlessDBFeature("supports_foreign_keys", "can_introspect_foreign_keys")
    def test_alter_fk_to_o2o(self):
        """
        #24163 - Tests altering of ForeignKey to OneToOneField
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        # Ensure the field is right to begin with
        columns = self.column_classes(Book)
        self.assertEqual(
            columns["author_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )
        # Ensure the field is not unique
        author = Author.objects.create(name="Joe")
        Book.objects.create(
            author=author, title="Django 1", pub_date=datetime.datetime.now()
        )
        Book.objects.create(
            author=author, title="Django 2", pub_date=datetime.datetime.now()
        )
        Book.objects.all().delete()
        self.assertForeignKeyExists(Book, "author_id", "schema_author")
        # Alter the ForeignKey to OneToOneField
        old_field = Book._meta.get_field("author")
        new_field = OneToOneField(Author, CASCADE)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(Book, old_field, new_field, strict=True)
        columns = self.column_classes(BookWithO2O)
        self.assertEqual(
            columns["author_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )
        # Ensure the field is unique now
        BookWithO2O.objects.create(
            author=author, title="Django 1", pub_date=datetime.datetime.now()
        )
        with self.assertRaises(IntegrityError):
            BookWithO2O.objects.create(
                author=author, title="Django 2", pub_date=datetime.datetime.now()
            )
        self.assertForeignKeyExists(BookWithO2O, "author_id", "schema_author")

    def test_alter_field_fk_to_o2o(self):
        """
        Alter a foreign key field to a one-to-one field in the database schema.

        This test case checks the creation and modification of database fields when altering a foreign key field to a one-to-one field.
        It first creates the Author and Book models, then tests the initial state of the foreign key constraints and indexes.
        After altering the 'author' field in the Book model from a foreign key to a one-to-one field, it re-checks the constraints and indexes to ensure they have been updated correctly.
        The test verifies that the one-to-one field has the expected unique constraint and no index, as per the database features and configuration.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        expected_fks = (
            1
            if connection.features.supports_foreign_keys
            and connection.features.can_introspect_foreign_keys
            else 0
        )
        expected_indexes = 1 if connection.features.indexes_foreign_keys else 0

        # Check the index is right to begin with.
        counts = self.get_constraints_count(
            Book._meta.db_table,
            Book._meta.get_field("author").column,
            (Author._meta.db_table, Author._meta.pk.column),
        )
        self.assertEqual(
            counts,
            {"fks": expected_fks, "uniques": 0, "indexes": expected_indexes},
        )

        old_field = Book._meta.get_field("author")
        new_field = OneToOneField(Author, CASCADE)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(Book, old_field, new_field)

        counts = self.get_constraints_count(
            Book._meta.db_table,
            Book._meta.get_field("author").column,
            (Author._meta.db_table, Author._meta.pk.column),
        )
        # The index on ForeignKey is replaced with a unique constraint for
        # OneToOneField.
        self.assertEqual(counts, {"fks": expected_fks, "uniques": 1, "indexes": 0})

    def test_autofield_to_o2o(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Note)

        # Rename the field.
        old_field = Author._meta.get_field("id")
        new_field = AutoField(primary_key=True)
        new_field.set_attributes_from_name("note_ptr")
        new_field.model = Author

        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        # Alter AutoField to OneToOneField.
        new_field_o2o = OneToOneField(Note, CASCADE)
        new_field_o2o.set_attributes_from_name("note_ptr")
        new_field_o2o.model = Author

        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, new_field_o2o, strict=True)
        columns = self.column_classes(Author)
        field_type, _ = columns["note_ptr_id"]
        self.assertEqual(
            field_type, connection.features.introspected_field_types["IntegerField"]
        )

    def test_alter_field_fk_keeps_index(self):
        """

        Tests that altering a foreign key field preserves the index on the field.

        Checks that the index is kept after changing the field's properties, specifically 
        when using the `alter_field` method of a schema editor. The test covers 
        scenarios where foreign key support and index creation are enabled or disabled, 
        depending on the database backend being used.

        The test ensures that the number of foreign keys, unique constraints, and indexes 
        on the field remains unchanged after the alteration, as expected.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        expected_fks = (
            1
            if connection.features.supports_foreign_keys
            and connection.features.can_introspect_foreign_keys
            else 0
        )
        expected_indexes = 1 if connection.features.indexes_foreign_keys else 0

        # Check the index is right to begin with.
        counts = self.get_constraints_count(
            Book._meta.db_table,
            Book._meta.get_field("author").column,
            (Author._meta.db_table, Author._meta.pk.column),
        )
        self.assertEqual(
            counts,
            {"fks": expected_fks, "uniques": 0, "indexes": expected_indexes},
        )

        old_field = Book._meta.get_field("author")
        # on_delete changed from CASCADE.
        new_field = ForeignKey(Author, PROTECT)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(Book, old_field, new_field, strict=True)

        counts = self.get_constraints_count(
            Book._meta.db_table,
            Book._meta.get_field("author").column,
            (Author._meta.db_table, Author._meta.pk.column),
        )
        # The index remains.
        self.assertEqual(
            counts,
            {"fks": expected_fks, "uniques": 0, "indexes": expected_indexes},
        )

    def test_alter_field_o2o_to_fk(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithO2O)
        expected_fks = (
            1
            if connection.features.supports_foreign_keys
            and connection.features.can_introspect_foreign_keys
            else 0
        )

        # Check the unique constraint is right to begin with.
        counts = self.get_constraints_count(
            BookWithO2O._meta.db_table,
            BookWithO2O._meta.get_field("author").column,
            (Author._meta.db_table, Author._meta.pk.column),
        )
        self.assertEqual(counts, {"fks": expected_fks, "uniques": 1, "indexes": 0})

        old_field = BookWithO2O._meta.get_field("author")
        new_field = ForeignKey(Author, CASCADE)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithO2O, old_field, new_field)

        counts = self.get_constraints_count(
            BookWithO2O._meta.db_table,
            BookWithO2O._meta.get_field("author").column,
            (Author._meta.db_table, Author._meta.pk.column),
        )
        # The unique constraint on OneToOneField is replaced with an index for
        # ForeignKey.
        self.assertEqual(counts, {"fks": expected_fks, "uniques": 0, "indexes": 1})

    def test_alter_field_o2o_keeps_unique(self):
        """

        Tests that altering a one-to-one field keeps its unique constraint.

        This test case checks that when a one-to-one field is altered, its unique constraint is preserved.
        It creates a model with a one-to-one relationship, checks the initial state of the field's constraints,
        alters the field, and then verifies that the constraints remain unchanged.
        The test covers the cases where the database supports foreign keys and can introspect them, as well as cases where it does not.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithO2O)
        expected_fks = (
            1
            if connection.features.supports_foreign_keys
            and connection.features.can_introspect_foreign_keys
            else 0
        )

        # Check the unique constraint is right to begin with.
        counts = self.get_constraints_count(
            BookWithO2O._meta.db_table,
            BookWithO2O._meta.get_field("author").column,
            (Author._meta.db_table, Author._meta.pk.column),
        )
        self.assertEqual(counts, {"fks": expected_fks, "uniques": 1, "indexes": 0})

        old_field = BookWithO2O._meta.get_field("author")
        # on_delete changed from CASCADE.
        new_field = OneToOneField(Author, PROTECT)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithO2O, old_field, new_field, strict=True)

        counts = self.get_constraints_count(
            BookWithO2O._meta.db_table,
            BookWithO2O._meta.get_field("author").column,
            (Author._meta.db_table, Author._meta.pk.column),
        )
        # The unique constraint remains.
        self.assertEqual(counts, {"fks": expected_fks, "uniques": 1, "indexes": 0})

    @skipUnlessDBFeature("ignores_table_name_case")
    def test_alter_db_table_case(self):
        # Create the table
        """

        Tests the alteration of a database table's name to have a different case.

        This test case checks that the database table name can be changed to a different case
        (e.g. from lowercase to uppercase) and verifies that the operation is successful.

        The test creates a table for the Author model, alters its name to an uppercase version,
        and determines whether the alteration is properly handled by the database backend.

        Requires a database feature that supports ignoring table name case.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Alter the case of the table
        old_table_name = Author._meta.db_table
        with connection.schema_editor() as editor:
            editor.alter_db_table(Author, old_table_name, old_table_name.upper())

    def test_alter_implicit_id_to_explicit(self):
        """
        Should be able to convert an implicit "id" field to an explicit "id"
        primary key field.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)

        old_field = Author._meta.get_field("id")
        new_field = AutoField(primary_key=True)
        new_field.set_attributes_from_name("id")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        # This will fail if DROP DEFAULT is inadvertently executed on this
        # field which drops the id sequence, at least on PostgreSQL.
        Author.objects.create(name="Foo")
        Author.objects.create(name="Bar")

    def test_alter_autofield_pk_to_bigautofield_pk(self):
        """
        Tests altering an AutoField primary key to a BigAutoField primary key.

        This test case creates an Author model, alters its primary key from an AutoField to a BigAutoField,
        and then verifies that the model can still be used to create new instances.

        The test covers the following scenarios:

        * Creating the Author model with an initial AutoField primary key
        * Altering the primary key to a BigAutoField
        * Creating new instances of the Author model after the alteration
        * Verifying that the sequence is reset correctly to avoid conflicts with existing primary key values

        The test ensures that the migration is successful and that the model remains functional after the alteration.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        old_field = Author._meta.get_field("id")
        new_field = BigAutoField(primary_key=True)
        new_field.set_attributes_from_name("id")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)

        Author.objects.create(name="Foo", pk=1)
        with connection.cursor() as cursor:
            sequence_reset_sqls = connection.ops.sequence_reset_sql(
                no_style(), [Author]
            )
            if sequence_reset_sqls:
                cursor.execute(sequence_reset_sqls[0])
        self.assertIsNotNone(Author.objects.create(name="Bar"))

    def test_alter_autofield_pk_to_smallautofield_pk(self):
        """
        Tests altering the primary key field of a model from an AutoField to a SmallAutoField.

        This test case verifies that the primary key field can be successfully changed 
        from an AutoField to a SmallAutoField without losing data or causing 
        database inconsistencies. It covers the creation of a model, alteration of 
        the primary key field, and subsequent creation of objects using the new field.

        The test assumes a model named 'Author' with an 'id' field as the primary key 
        and checks that after alteration, new objects can be created with the new 
        primary key field type and without any errors related to database sequences.


        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        old_field = Author._meta.get_field("id")
        new_field = SmallAutoField(primary_key=True)
        new_field.set_attributes_from_name("id")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)

        Author.objects.create(name="Foo", pk=1)
        with connection.cursor() as cursor:
            sequence_reset_sqls = connection.ops.sequence_reset_sql(
                no_style(), [Author]
            )
            if sequence_reset_sqls:
                cursor.execute(sequence_reset_sqls[0])
        self.assertIsNotNone(Author.objects.create(name="Bar"))

    def test_alter_int_pk_to_autofield_pk(self):
        """
        Should be able to rename an IntegerField(primary_key=True) to
        AutoField(primary_key=True).
        """
        with connection.schema_editor() as editor:
            editor.create_model(IntegerPK)

        old_field = IntegerPK._meta.get_field("i")
        new_field = AutoField(primary_key=True)
        new_field.model = IntegerPK
        new_field.set_attributes_from_name("i")

        with connection.schema_editor() as editor:
            editor.alter_field(IntegerPK, old_field, new_field, strict=True)

        # A model representing the updated model.
        class IntegerPKToAutoField(Model):
            i = AutoField(primary_key=True)
            j = IntegerField(unique=True)

            class Meta:
                app_label = "schema"
                apps = new_apps
                db_table = IntegerPK._meta.db_table

        # An id (i) is generated by the database.
        obj = IntegerPKToAutoField.objects.create(j=1)
        self.assertIsNotNone(obj.i)

    def test_alter_int_pk_to_bigautofield_pk(self):
        """
        Should be able to rename an IntegerField(primary_key=True) to
        BigAutoField(primary_key=True).
        """
        with connection.schema_editor() as editor:
            editor.create_model(IntegerPK)

        old_field = IntegerPK._meta.get_field("i")
        new_field = BigAutoField(primary_key=True)
        new_field.model = IntegerPK
        new_field.set_attributes_from_name("i")

        with connection.schema_editor() as editor:
            editor.alter_field(IntegerPK, old_field, new_field, strict=True)

        # A model representing the updated model.
        class IntegerPKToBigAutoField(Model):
            i = BigAutoField(primary_key=True)
            j = IntegerField(unique=True)

            class Meta:
                app_label = "schema"
                apps = new_apps
                db_table = IntegerPK._meta.db_table

        # An id (i) is generated by the database.
        obj = IntegerPKToBigAutoField.objects.create(j=1)
        self.assertIsNotNone(obj.i)

    @isolate_apps("schema")
    def test_alter_smallint_pk_to_smallautofield_pk(self):
        """
        Should be able to rename an SmallIntegerField(primary_key=True) to
        SmallAutoField(primary_key=True).
        """

        class SmallIntegerPK(Model):
            i = SmallIntegerField(primary_key=True)

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(SmallIntegerPK)
        self.isolated_local_models = [SmallIntegerPK]
        old_field = SmallIntegerPK._meta.get_field("i")
        new_field = SmallAutoField(primary_key=True)
        new_field.model = SmallIntegerPK
        new_field.set_attributes_from_name("i")
        with connection.schema_editor() as editor:
            editor.alter_field(SmallIntegerPK, old_field, new_field, strict=True)

    @isolate_apps("schema")
    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_serial_auto_field_to_bigautofield(self):
        """
        Tests the alteration of a serial AutoField to a BigAutoField and then to an AutoField in a PostgreSQL database.

        This test creates a table with a SmallAutoField, alters it to a BigAutoField, and then alters it to an AutoField.
        It checks that the sequence data type is correctly updated after each alteration.

        The test is specific to PostgreSQL and requires a PostgreSQL database connection to run.

        It verifies that the sequence data type is changed to 'bigint' after altering to BigAutoField and to 'integer' after altering to AutoField. 

        Finally, it cleans up by dropping the created table. 

        :raises AssertionError: If the sequence data type is not as expected after alteration.

        """
        class SerialAutoField(Model):
            id = SmallAutoField(primary_key=True)

            class Meta:
                app_label = "schema"

        table = SerialAutoField._meta.db_table
        column = SerialAutoField._meta.get_field("id").column
        with connection.cursor() as cursor:
            cursor.execute(
                f'CREATE TABLE "{table}" '
                f'("{column}" smallserial NOT NULL PRIMARY KEY)'
            )
        try:
            old_field = SerialAutoField._meta.get_field("id")
            new_field = BigAutoField(primary_key=True)
            new_field.model = SerialAutoField
            new_field.set_attributes_from_name("id")
            with connection.schema_editor() as editor:
                editor.alter_field(SerialAutoField, old_field, new_field, strict=True)
            sequence_name = f"{table}_{column}_seq"
            with connection.cursor() as cursor:
                cursor.execute(
                    "SELECT data_type FROM pg_sequences WHERE sequencename = %s",
                    [sequence_name],
                )
                row = cursor.fetchone()
                sequence_data_type = row[0] if row and row[0] else None
                self.assertEqual(sequence_data_type, "bigint")
            # Rename the column.
            old_field = new_field
            new_field = AutoField(primary_key=True)
            new_field.model = SerialAutoField
            new_field.set_attributes_from_name("renamed_id")
            with connection.schema_editor() as editor:
                editor.alter_field(SerialAutoField, old_field, new_field, strict=True)
            with connection.cursor() as cursor:
                cursor.execute(
                    "SELECT data_type FROM pg_sequences WHERE sequencename = %s",
                    [sequence_name],
                )
                row = cursor.fetchone()
                sequence_data_type = row[0] if row and row[0] else None
                self.assertEqual(sequence_data_type, "integer")
        finally:
            with connection.cursor() as cursor:
                cursor.execute(f'DROP TABLE "{table}"')

    def test_alter_int_pk_to_int_unique(self):
        """
        Should be able to rename an IntegerField(primary_key=True) to
        IntegerField(unique=True).
        """
        with connection.schema_editor() as editor:
            editor.create_model(IntegerPK)
        # Delete the old PK
        old_field = IntegerPK._meta.get_field("i")
        new_field = IntegerField(unique=True)
        new_field.model = IntegerPK
        new_field.set_attributes_from_name("i")
        with connection.schema_editor() as editor:
            editor.alter_field(IntegerPK, old_field, new_field, strict=True)
        # The primary key constraint is gone. Result depends on database:
        # 'id' for SQLite, None for others (must not be 'i').
        self.assertIn(self.get_primary_key(IntegerPK._meta.db_table), ("id", None))

        # Set up a model class as it currently stands. The original IntegerPK
        # class is now out of date and some backends make use of the whole
        # model class when modifying a field (such as sqlite3 when remaking a
        # table) so an outdated model class leads to incorrect results.
        class Transitional(Model):
            i = IntegerField(unique=True)
            j = IntegerField(unique=True)

            class Meta:
                app_label = "schema"
                apps = new_apps
                db_table = "INTEGERPK"

        # model requires a new PK
        old_field = Transitional._meta.get_field("j")
        new_field = IntegerField(primary_key=True)
        new_field.model = Transitional
        new_field.set_attributes_from_name("j")

        with connection.schema_editor() as editor:
            editor.alter_field(Transitional, old_field, new_field, strict=True)

        # Create a model class representing the updated model.
        class IntegerUnique(Model):
            i = IntegerField(unique=True)
            j = IntegerField(primary_key=True)

            class Meta:
                app_label = "schema"
                apps = new_apps
                db_table = "INTEGERPK"

        # Ensure unique constraint works.
        IntegerUnique.objects.create(i=1, j=1)
        with self.assertRaises(IntegrityError):
            IntegerUnique.objects.create(i=1, j=2)

    def test_rename(self):
        """
        Tests simple altering of fields
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the field is right to begin with
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["name"][0],
            connection.features.introspected_field_types["CharField"],
        )
        self.assertNotIn("display_name", columns)
        # Alter the name field's name
        old_field = Author._meta.get_field("name")
        new_field = CharField(max_length=254)
        new_field.set_attributes_from_name("display_name")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["display_name"][0],
            connection.features.introspected_field_types["CharField"],
        )
        self.assertNotIn("name", columns)

    @isolate_apps("schema")
    def test_rename_referenced_field(self):
        class Author(Model):
            name = CharField(max_length=255, unique=True)

            class Meta:
                app_label = "schema"

        class Book(Model):
            author = ForeignKey(Author, CASCADE, to_field="name")

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        new_field = CharField(max_length=255, unique=True)
        new_field.set_attributes_from_name("renamed")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, Author._meta.get_field("name"), new_field)
        # Ensure the foreign key reference was updated.
        self.assertForeignKeyExists(Book, "author_id", "schema_author", "renamed")

    @skipIfDBFeature("interprets_empty_strings_as_nulls")
    def test_rename_keep_null_status(self):
        """
        Renaming a field shouldn't affect the not null status.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        with self.assertRaises(IntegrityError):
            Note.objects.create(info=None)
        old_field = Note._meta.get_field("info")
        new_field = TextField()
        new_field.set_attributes_from_name("detail_info")
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)
        columns = self.column_classes(Note)
        self.assertEqual(columns["detail_info"][0], "TextField")
        self.assertNotIn("info", columns)
        with self.assertRaises(IntegrityError):
            NoteRename.objects.create(detail_info=None)

    @isolate_apps("schema")
    def test_rename_keep_db_default(self):
        """Renaming a field shouldn't affect a database default."""

        class AuthorDbDefault(Model):
            birth_year = IntegerField(db_default=1985)

            class Meta:
                app_label = "schema"

        self.isolated_local_models = [AuthorDbDefault]
        with connection.schema_editor() as editor:
            editor.create_model(AuthorDbDefault)
        columns = self.column_classes(AuthorDbDefault)
        self.assertEqual(columns["birth_year"][1].default, "1985")

        old_field = AuthorDbDefault._meta.get_field("birth_year")
        new_field = IntegerField(db_default=1985)
        new_field.set_attributes_from_name("renamed_year")
        new_field.model = AuthorDbDefault
        with connection.schema_editor() as editor:
            editor.alter_field(AuthorDbDefault, old_field, new_field, strict=True)
        columns = self.column_classes(AuthorDbDefault)
        self.assertEqual(columns["renamed_year"][1].default, "1985")

    @isolate_apps("schema")
    def test_add_field_both_defaults_preserves_db_default(self):
        """

        Tests that adding a field with both default and db_default values to a model preserves the db_default value.

        This test case ensures that when a new field is added to a model with both a default value and a database default value,
        the database default value takes precedence and is preserved in the database schema.

        The test creates a new model, adds a field with default and db_default values, and then verifies that the resulting database column
        uses the db_default value as its default.

        """
        class Author(Model):
            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Author)

        field = IntegerField(default=1985, db_default=1988)
        field.set_attributes_from_name("birth_year")
        field.model = Author
        with connection.schema_editor() as editor:
            editor.add_field(Author, field)
        columns = self.column_classes(Author)
        self.assertEqual(columns["birth_year"][1].default, "1988")

    @isolate_apps("schema")
    def test_add_text_field_with_db_default(self):
        """

        Tests the addition of a text field with a database default value.

        This test case verifies that a TextField with a specified db_default value
        is correctly created in the database. It creates a model 'Author' with a
        TextField 'description' that has a db_default value of '(missing)', then
        checks if the default value is correctly set in the database column.

        """
        class Author(Model):
            description = TextField(db_default="(missing)")

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Author)
        columns = self.column_classes(Author)
        self.assertIn("(missing)", columns["description"][1].default)

    @isolate_apps("schema")
    def test_db_default_equivalent_sql_noop(self):
        """
        Tests if altering a model field to an equivalent default SQL value results in no operations being performed.

        This test ensures that when the default SQL value of a field is changed to a new value that is equivalent to the existing default,
        no unnecessary database operations are performed, resulting in a no-op (no operation).

        The test uses a model with a TextField to verify this behavior, ensuring that the database remains unchanged when the default SQL value is updated to an equivalent value.

        :raises: AssertionError if any database operations are performed during the test
        """
        class Author(Model):
            name = TextField(db_default=Value("foo"))

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Author)

        new_field = TextField(db_default="foo")
        new_field.set_attributes_from_name("name")
        new_field.model = Author
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            editor.alter_field(Author, Author._meta.get_field("name"), new_field)

    @isolate_apps("schema")
    def test_db_default_output_field_resolving(self):
        """

        Tests the default output of a database field.

        This test case checks that a JSONField's default value is correctly resolved and stored in the database.
        It verifies that the default value is a dictionary with a specific datetime, and that it is properly encoded
        and returned when the model instance is refreshed from the database.

        The test covers the creation of a model with a JSONField, setting its default value, and checking that the
        default value is correctly applied and retrieved.

        """
        class Author(Model):
            data = JSONField(
                encoder=DjangoJSONEncoder,
                db_default={
                    "epoch": datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)
                },
            )

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Author)

        author = Author.objects.create()
        author.refresh_from_db()
        self.assertEqual(author.data, {"epoch": "1970-01-01T00:00:00Z"})

    @skipUnlessDBFeature(
        "supports_column_check_constraints", "can_introspect_check_constraints"
    )
    @isolate_apps("schema")
    def test_rename_field_with_check_to_truncated_name(self):
        """

        Tests that renaming a field with a check constraint to a truncated name correctly preserves the constraint.

        The test creates a model with a field that has a very long name and a check constraint, then renames the field to a truncated name.
        It verifies that the check constraint is retained after the rename operation, ensuring that the constraint is updated to reference the new field name.

        This test is skipped if the database does not support column check constraints or cannot introspect check constraints.

        """
        class AuthorWithLongColumn(Model):
            field_with_very_looooooong_name = PositiveIntegerField(null=True)

            class Meta:
                app_label = "schema"

        self.isolated_local_models = [AuthorWithLongColumn]
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithLongColumn)
        old_field = AuthorWithLongColumn._meta.get_field(
            "field_with_very_looooooong_name"
        )
        new_field = PositiveIntegerField(null=True)
        new_field.set_attributes_from_name("renamed_field_with_very_long_name")
        with connection.schema_editor() as editor:
            editor.alter_field(AuthorWithLongColumn, old_field, new_field, strict=True)

        new_field_name = truncate_name(
            new_field.column, connection.ops.max_name_length()
        )
        constraints = self.get_constraints(AuthorWithLongColumn._meta.db_table)
        check_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == [new_field_name] and details["check"]
        ]
        self.assertEqual(len(check_constraints), 1)

    def _test_m2m_create(self, M2MFieldClass):
        """
        Tests M2M fields on models during creation
        """

        class LocalBookWithM2M(Model):
            author = ForeignKey(Author, CASCADE)
            title = CharField(max_length=100, db_index=True)
            pub_date = DateTimeField()
            tags = M2MFieldClass("TagM2MTest", related_name="books")

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [LocalBookWithM2M]
        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(TagM2MTest)
            editor.create_model(LocalBookWithM2M)
        # Ensure there is now an m2m table there
        columns = self.column_classes(
            LocalBookWithM2M._meta.get_field("tags").remote_field.through
        )
        self.assertEqual(
            columns["tagm2mtest_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )

    def test_m2m_create(self):
        self._test_m2m_create(ManyToManyField)

    def test_m2m_create_custom(self):
        self._test_m2m_create(CustomManyToManyField)

    def test_m2m_create_inherited(self):
        self._test_m2m_create(InheritedManyToManyField)

    def _test_m2m_create_through(self, M2MFieldClass):
        """
        Tests M2M fields on models during creation with through models
        """

        class LocalTagThrough(Model):
            book = ForeignKey("schema.LocalBookWithM2MThrough", CASCADE)
            tag = ForeignKey("schema.TagM2MTest", CASCADE)

            class Meta:
                app_label = "schema"
                apps = new_apps

        class LocalBookWithM2MThrough(Model):
            tags = M2MFieldClass(
                "TagM2MTest", related_name="books", through=LocalTagThrough
            )

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [LocalTagThrough, LocalBookWithM2MThrough]

        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(LocalTagThrough)
            editor.create_model(TagM2MTest)
            editor.create_model(LocalBookWithM2MThrough)
        # Ensure there is now an m2m table there
        columns = self.column_classes(LocalTagThrough)
        self.assertEqual(
            columns["book_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )
        self.assertEqual(
            columns["tag_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )

    def test_m2m_create_through(self):
        self._test_m2m_create_through(ManyToManyField)

    def test_m2m_create_through_custom(self):
        self._test_m2m_create_through(CustomManyToManyField)

    def test_m2m_create_through_inherited(self):
        self._test_m2m_create_through(InheritedManyToManyField)

    def test_m2m_through_remove(self):
        """

        Tests the removal of a Many-To-Many field with a custom through model.

        Verifies that attempting to alter a Many-To-Many field with a through model
        to a Many-To-Many field without a through model raises a ValueError.

        This test case checks the database schema editor's behavior when trying to
        modify a Many-To-Many relationship, ensuring that the relationship's through model
        cannot be removed or altered in a way that would change its type or through model.

        """
        class LocalAuthorNoteThrough(Model):
            book = ForeignKey("schema.Author", CASCADE)
            tag = ForeignKey("self", CASCADE)

            class Meta:
                app_label = "schema"
                apps = new_apps

        class LocalNoteWithM2MThrough(Model):
            authors = ManyToManyField("schema.Author", through=LocalAuthorNoteThrough)

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [LocalAuthorNoteThrough, LocalNoteWithM2MThrough]
        # Create the tables.
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(LocalAuthorNoteThrough)
            editor.create_model(LocalNoteWithM2MThrough)
        # Remove the through parameter.
        old_field = LocalNoteWithM2MThrough._meta.get_field("authors")
        new_field = ManyToManyField("Author")
        new_field.set_attributes_from_name("authors")
        msg = (
            f"Cannot alter field {old_field} into {new_field} - they are not "
            f"compatible types (you cannot alter to or from M2M fields, or add or "
            f"remove through= on M2M fields)"
        )
        with connection.schema_editor() as editor:
            with self.assertRaisesMessage(ValueError, msg):
                editor.alter_field(LocalNoteWithM2MThrough, old_field, new_field)

    def _test_m2m(self, M2MFieldClass):
        """
        Tests adding/removing M2M fields on models
        """

        class LocalAuthorWithM2M(Model):
            name = CharField(max_length=255)

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [LocalAuthorWithM2M]

        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(LocalAuthorWithM2M)
            editor.create_model(TagM2MTest)
        # Create an M2M field
        new_field = M2MFieldClass("schema.TagM2MTest", related_name="authors")
        new_field.contribute_to_class(LocalAuthorWithM2M, "tags")
        # Ensure there's no m2m table there
        with self.assertRaises(DatabaseError):
            self.column_classes(new_field.remote_field.through)
        # Add the field
        with (
            CaptureQueriesContext(connection) as ctx,
            connection.schema_editor() as editor,
        ):
            editor.add_field(LocalAuthorWithM2M, new_field)
        # Table is not rebuilt.
        self.assertEqual(
            len(
                [
                    query["sql"]
                    for query in ctx.captured_queries
                    if "CREATE TABLE" in query["sql"]
                ]
            ),
            1,
        )
        self.assertIs(
            any("DROP TABLE" in query["sql"] for query in ctx.captured_queries),
            False,
        )
        # Ensure there is now an m2m table there
        columns = self.column_classes(new_field.remote_field.through)
        self.assertEqual(
            columns["tagm2mtest_id"][0],
            connection.features.introspected_field_types["IntegerField"],
        )

        # "Alter" the field. This should not rename the DB table to itself.
        with connection.schema_editor() as editor:
            editor.alter_field(LocalAuthorWithM2M, new_field, new_field, strict=True)

        # Remove the M2M table again
        with connection.schema_editor() as editor:
            editor.remove_field(LocalAuthorWithM2M, new_field)
        # Ensure there's no m2m table there
        with self.assertRaises(DatabaseError):
            self.column_classes(new_field.remote_field.through)

        # Make sure the model state is coherent with the table one now that
        # we've removed the tags field.
        opts = LocalAuthorWithM2M._meta
        opts.local_many_to_many.remove(new_field)
        del new_apps.all_models["schema"][
            new_field.remote_field.through._meta.model_name
        ]
        opts._expire_cache()

    def test_m2m(self):
        self._test_m2m(ManyToManyField)

    def test_m2m_custom(self):
        self._test_m2m(CustomManyToManyField)

    def test_m2m_inherited(self):
        self._test_m2m(InheritedManyToManyField)

    def _test_m2m_through_alter(self, M2MFieldClass):
        """
        Tests altering M2Ms with explicit through models (should no-op)
        """

        class LocalAuthorTag(Model):
            author = ForeignKey("schema.LocalAuthorWithM2MThrough", CASCADE)
            tag = ForeignKey("schema.TagM2MTest", CASCADE)

            class Meta:
                app_label = "schema"
                apps = new_apps

        class LocalAuthorWithM2MThrough(Model):
            name = CharField(max_length=255)
            tags = M2MFieldClass(
                "schema.TagM2MTest", related_name="authors", through=LocalAuthorTag
            )

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [LocalAuthorTag, LocalAuthorWithM2MThrough]

        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(LocalAuthorTag)
            editor.create_model(LocalAuthorWithM2MThrough)
            editor.create_model(TagM2MTest)
        # Ensure the m2m table is there
        self.assertEqual(len(self.column_classes(LocalAuthorTag)), 3)
        # "Alter" the field's blankness. This should not actually do anything.
        old_field = LocalAuthorWithM2MThrough._meta.get_field("tags")
        new_field = M2MFieldClass(
            "schema.TagM2MTest", related_name="authors", through=LocalAuthorTag
        )
        new_field.contribute_to_class(LocalAuthorWithM2MThrough, "tags")
        with connection.schema_editor() as editor:
            editor.alter_field(
                LocalAuthorWithM2MThrough, old_field, new_field, strict=True
            )
        # Ensure the m2m table is still there
        self.assertEqual(len(self.column_classes(LocalAuthorTag)), 3)

    def test_m2m_through_alter(self):
        self._test_m2m_through_alter(ManyToManyField)

    def test_m2m_through_alter_custom(self):
        self._test_m2m_through_alter(CustomManyToManyField)

    def test_m2m_through_alter_inherited(self):
        self._test_m2m_through_alter(InheritedManyToManyField)

    def _test_m2m_repoint(self, M2MFieldClass):
        """
        Tests repointing M2M fields
        """

        class LocalBookWithM2M(Model):
            author = ForeignKey(Author, CASCADE)
            title = CharField(max_length=100, db_index=True)
            pub_date = DateTimeField()
            tags = M2MFieldClass("TagM2MTest", related_name="books")

            class Meta:
                app_label = "schema"
                apps = new_apps

        self.local_models = [LocalBookWithM2M]
        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(LocalBookWithM2M)
            editor.create_model(TagM2MTest)
            editor.create_model(UniqueTest)
        # Ensure the M2M exists and points to TagM2MTest
        if connection.features.supports_foreign_keys:
            self.assertForeignKeyExists(
                LocalBookWithM2M._meta.get_field("tags").remote_field.through,
                "tagm2mtest_id",
                "schema_tagm2mtest",
            )
        # Repoint the M2M
        old_field = LocalBookWithM2M._meta.get_field("tags")
        new_field = M2MFieldClass(UniqueTest)
        new_field.contribute_to_class(LocalBookWithM2M, "uniques")
        with connection.schema_editor() as editor:
            editor.alter_field(LocalBookWithM2M, old_field, new_field, strict=True)
        # Ensure old M2M is gone
        with self.assertRaises(DatabaseError):
            self.column_classes(
                LocalBookWithM2M._meta.get_field("tags").remote_field.through
            )

        # This model looks like the new model and is used for teardown.
        opts = LocalBookWithM2M._meta
        opts.local_many_to_many.remove(old_field)
        # Ensure the new M2M exists and points to UniqueTest
        if connection.features.supports_foreign_keys:
            self.assertForeignKeyExists(
                new_field.remote_field.through, "uniquetest_id", "schema_uniquetest"
            )

    def test_m2m_repoint(self):
        self._test_m2m_repoint(ManyToManyField)

    def test_m2m_repoint_custom(self):
        self._test_m2m_repoint(CustomManyToManyField)

    def test_m2m_repoint_inherited(self):
        self._test_m2m_repoint(InheritedManyToManyField)

    @isolate_apps("schema")
    def test_m2m_rename_field_in_target_model(self):
        class LocalTagM2MTest(Model):
            title = CharField(max_length=255)

            class Meta:
                app_label = "schema"

        class LocalM2M(Model):
            tags = ManyToManyField(LocalTagM2MTest)

            class Meta:
                app_label = "schema"

        # Create the tables.
        with connection.schema_editor() as editor:
            editor.create_model(LocalM2M)
            editor.create_model(LocalTagM2MTest)
        self.isolated_local_models = [LocalM2M, LocalTagM2MTest]
        # Ensure the m2m table is there.
        self.assertEqual(len(self.column_classes(LocalM2M)), 1)
        # Alter a field in LocalTagM2MTest.
        old_field = LocalTagM2MTest._meta.get_field("title")
        new_field = CharField(max_length=254)
        new_field.contribute_to_class(LocalTagM2MTest, "title1")
        # @isolate_apps() and inner models are needed to have the model
        # relations populated, otherwise this doesn't act as a regression test.
        self.assertEqual(len(new_field.model._meta.related_objects), 1)
        with connection.schema_editor() as editor:
            editor.alter_field(LocalTagM2MTest, old_field, new_field, strict=True)
        # Ensure the m2m table is still there.
        self.assertEqual(len(self.column_classes(LocalM2M)), 1)

    @skipUnlessDBFeature(
        "supports_column_check_constraints", "can_introspect_check_constraints"
    )
    def test_check_constraints(self):
        """
        Tests creating/deleting CHECK constraints
        """
        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the constraint exists
        constraints = self.get_constraints(Author._meta.db_table)
        if not any(
            details["columns"] == ["height"] and details["check"]
            for details in constraints.values()
        ):
            self.fail("No check constraint for height found")
        # Alter the column to remove it
        old_field = Author._meta.get_field("height")
        new_field = IntegerField(null=True, blank=True)
        new_field.set_attributes_from_name("height")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        constraints = self.get_constraints(Author._meta.db_table)
        for details in constraints.values():
            if details["columns"] == ["height"] and details["check"]:
                self.fail("Check constraint for height found")
        # Alter the column to re-add it
        new_field2 = Author._meta.get_field("height")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, new_field2, strict=True)
        constraints = self.get_constraints(Author._meta.db_table)
        if not any(
            details["columns"] == ["height"] and details["check"]
            for details in constraints.values()
        ):
            self.fail("No check constraint for height found")

    @skipUnlessDBFeature(
        "supports_column_check_constraints", "can_introspect_check_constraints"
    )
    @isolate_apps("schema")
    def test_check_constraint_timedelta_param(self):
        class DurationModel(Model):
            duration = DurationField()

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(DurationModel)
        self.isolated_local_models = [DurationModel]
        constraint_name = "duration_gte_5_minutes"
        constraint = CheckConstraint(
            condition=Q(duration__gt=datetime.timedelta(minutes=5)),
            name=constraint_name,
        )
        DurationModel._meta.constraints = [constraint]
        with connection.schema_editor() as editor:
            editor.add_constraint(DurationModel, constraint)
        constraints = self.get_constraints(DurationModel._meta.db_table)
        self.assertIn(constraint_name, constraints)
        with self.assertRaises(IntegrityError), atomic():
            DurationModel.objects.create(duration=datetime.timedelta(minutes=4))
        DurationModel.objects.create(duration=datetime.timedelta(minutes=10))

    @skipUnlessDBFeature(
        "supports_column_check_constraints",
        "can_introspect_check_constraints",
        "supports_json_field",
    )
    @isolate_apps("schema")
    def test_check_constraint_exact_jsonfield(self):
        """

        Tests the creation and enforcement of an exact JSON field check constraint.

        This test case exercises the addition of a check constraint to a model with a JSON field,
        verifying that the constraint is properly introspected and that invalid data insertion is
        prevented. The constraint checks if the 'version' key in the JSON field has the value 'stable'.

        """
        class JSONConstraintModel(Model):
            data = JSONField()

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(JSONConstraintModel)
        self.isolated_local_models = [JSONConstraintModel]
        constraint_name = "check_only_stable_version"
        constraint = CheckConstraint(
            condition=Q(data__version="stable"),
            name=constraint_name,
        )
        JSONConstraintModel._meta.constraints = [constraint]
        with connection.schema_editor() as editor:
            editor.add_constraint(JSONConstraintModel, constraint)
        constraints = self.get_constraints(JSONConstraintModel._meta.db_table)
        self.assertIn(constraint_name, constraints)
        with self.assertRaises(IntegrityError), atomic():
            JSONConstraintModel.objects.create(
                data={"release": "5.0.2dev", "version": "dev"}
            )
        JSONConstraintModel.objects.create(
            data={"release": "5.0.3", "version": "stable"}
        )

    @skipUnlessDBFeature(
        "supports_column_check_constraints", "can_introspect_check_constraints"
    )
    def test_remove_field_check_does_not_remove_meta_constraints(self):
        """

        Tests the removal of a field check constraint during schema migration.

        Specifically, this test case verifies that when a field's check constraint is removed,
        any meta-level constraints defined on that field are preserved and not inadvertently
        deleted. It also ensures that any new constraints created after the removal are
        correctly applied.

        This test covers the following scenarios:

        * Creation and addition of a custom check constraint to a model field
        * Altering the field to remove its check constraint
        * Verification that the custom check constraint remains intact after the field alteration
        * Subsequent removal of the custom check constraint

        The test validates that the constraints are correctly managed throughout these operations,
        ensuring data integrity and consistency in the database schema.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Add the custom check constraint
        constraint = CheckConstraint(
            condition=Q(height__gte=0), name="author_height_gte_0_check"
        )
        custom_constraint_name = constraint.name
        Author._meta.constraints = [constraint]
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, constraint)
        # Ensure the constraints exist
        constraints = self.get_constraints(Author._meta.db_table)
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["height"]
            and details["check"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 1)
        # Alter the column to remove field check
        old_field = Author._meta.get_field("height")
        new_field = IntegerField(null=True, blank=True)
        new_field.set_attributes_from_name("height")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        constraints = self.get_constraints(Author._meta.db_table)
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["height"]
            and details["check"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 0)
        # Alter the column to re-add field check
        new_field2 = Author._meta.get_field("height")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, new_field2, strict=True)
        constraints = self.get_constraints(Author._meta.db_table)
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["height"]
            and details["check"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 1)
        # Drop the check constraint
        with connection.schema_editor() as editor:
            Author._meta.constraints = []
            editor.remove_constraint(Author, constraint)

    def test_unique(self):
        """
        Tests removing and adding unique constraints to a single column.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
        # Ensure the field is unique to begin with
        Tag.objects.create(title="foo", slug="foo")
        with self.assertRaises(IntegrityError):
            Tag.objects.create(title="bar", slug="foo")
        Tag.objects.all().delete()
        # Alter the slug field to be non-unique
        old_field = Tag._meta.get_field("slug")
        new_field = SlugField(unique=False)
        new_field.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_field(Tag, old_field, new_field, strict=True)
        # Ensure the field is no longer unique
        Tag.objects.create(title="foo", slug="foo")
        Tag.objects.create(title="bar", slug="foo")
        Tag.objects.all().delete()
        # Alter the slug field to be unique
        new_field2 = SlugField(unique=True)
        new_field2.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_field(Tag, new_field, new_field2, strict=True)
        # Ensure the field is unique again
        Tag.objects.create(title="foo", slug="foo")
        with self.assertRaises(IntegrityError):
            Tag.objects.create(title="bar", slug="foo")
        Tag.objects.all().delete()
        # Rename the field
        new_field3 = SlugField(unique=True)
        new_field3.set_attributes_from_name("slug2")
        with connection.schema_editor() as editor:
            editor.alter_field(Tag, new_field2, new_field3, strict=True)
        # Ensure the field is still unique
        TagUniqueRename.objects.create(title="foo", slug2="foo")
        with self.assertRaises(IntegrityError):
            TagUniqueRename.objects.create(title="bar", slug2="foo")
        Tag.objects.all().delete()

    def test_unique_name_quoting(self):
        old_table_name = TagUniqueRename._meta.db_table
        try:
            with connection.schema_editor() as editor:
                editor.create_model(TagUniqueRename)
                editor.alter_db_table(TagUniqueRename, old_table_name, "unique-table")
                TagUniqueRename._meta.db_table = "unique-table"
                # This fails if the unique index name isn't quoted.
                editor.alter_unique_together(TagUniqueRename, [], (("title", "slug2"),))
        finally:
            with connection.schema_editor() as editor:
                editor.delete_model(TagUniqueRename)
            TagUniqueRename._meta.db_table = old_table_name

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_foreign_keys")
    def test_unique_no_unnecessary_fk_drops(self):
        """
        If AlterField isn't selective about dropping foreign key constraints
        when modifying a field with a unique constraint, the AlterField
        incorrectly drops and recreates the Book.author foreign key even though
        it doesn't restrict the field being changed (#29193).
        """

        class Author(Model):
            name = CharField(max_length=254, unique=True)

            class Meta:
                app_label = "schema"

        class Book(Model):
            author = ForeignKey(Author, CASCADE)

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        new_field = CharField(max_length=255, unique=True)
        new_field.model = Author
        new_field.set_attributes_from_name("name")
        with self.assertLogs("django.db.backends.schema", "DEBUG") as cm:
            with connection.schema_editor() as editor:
                editor.alter_field(Author, Author._meta.get_field("name"), new_field)
        # One SQL statement is executed to alter the field.
        self.assertEqual(len(cm.records), 1)

    @isolate_apps("schema")
    def test_unique_and_reverse_m2m(self):
        """
        AlterField can modify a unique field when there's a reverse M2M
        relation on the model.
        """

        class Tag(Model):
            title = CharField(max_length=255)
            slug = SlugField(unique=True)

            class Meta:
                app_label = "schema"

        class Book(Model):
            tags = ManyToManyField(Tag, related_name="books")

            class Meta:
                app_label = "schema"

        self.isolated_local_models = [Book._meta.get_field("tags").remote_field.through]
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
            editor.create_model(Book)
        new_field = SlugField(max_length=75, unique=True)
        new_field.model = Tag
        new_field.set_attributes_from_name("slug")
        with self.assertLogs("django.db.backends.schema", "DEBUG") as cm:
            with connection.schema_editor() as editor:
                editor.alter_field(Tag, Tag._meta.get_field("slug"), new_field)
        # One SQL statement is executed to alter the field.
        self.assertEqual(len(cm.records), 1)
        # Ensure that the field is still unique.
        Tag.objects.create(title="foo", slug="foo")
        with self.assertRaises(IntegrityError):
            Tag.objects.create(title="bar", slug="foo")

    def test_remove_ignored_unique_constraint_not_create_fk_index(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        constraint = UniqueConstraint(
            "author",
            condition=Q(title__in=["tHGttG", "tRatEotU"]),
            name="book_author_condition_uniq",
        )
        # Add unique constraint.
        with connection.schema_editor() as editor:
            editor.add_constraint(Book, constraint)
        old_constraints = self.get_constraints_for_column(
            Book,
            Book._meta.get_field("author").column,
        )
        # Remove unique constraint.
        with connection.schema_editor() as editor:
            editor.remove_constraint(Book, constraint)
        new_constraints = self.get_constraints_for_column(
            Book,
            Book._meta.get_field("author").column,
        )
        # Redundant foreign key index is not added.
        self.assertEqual(
            (
                len(old_constraints) - 1
                if connection.features.supports_partial_indexes
                else len(old_constraints)
            ),
            len(new_constraints),
        )

    @skipUnlessDBFeature("allows_multiple_constraints_on_same_fields")
    def test_remove_field_unique_does_not_remove_meta_constraints(self):
        """
        Tests that removing a unique constraint on a field does not remove other 
        meta constraints on the same field.

        Verifies that when a unique constraint is removed, the database still 
        contains other constraints that were defined on the same field before the 
        unique constraint was added. 

        Also checks that when a field is altered or recreated, its meta 
        constraints are preserved, including any custom unique constraints.

        """
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithUniqueName)
        self.local_models = [AuthorWithUniqueName]
        # Add the custom unique constraint
        constraint = UniqueConstraint(fields=["name"], name="author_name_uniq")
        custom_constraint_name = constraint.name
        AuthorWithUniqueName._meta.constraints = [constraint]
        with connection.schema_editor() as editor:
            editor.add_constraint(AuthorWithUniqueName, constraint)
        # Ensure the constraints exist
        constraints = self.get_constraints(AuthorWithUniqueName._meta.db_table)
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["name"]
            and details["unique"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 1)
        # Alter the column to remove field uniqueness
        old_field = AuthorWithUniqueName._meta.get_field("name")
        new_field = CharField(max_length=255)
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(AuthorWithUniqueName, old_field, new_field, strict=True)
        constraints = self.get_constraints(AuthorWithUniqueName._meta.db_table)
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["name"]
            and details["unique"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 0)
        # Alter the column to re-add field uniqueness
        new_field2 = AuthorWithUniqueName._meta.get_field("name")
        with connection.schema_editor() as editor:
            editor.alter_field(AuthorWithUniqueName, new_field, new_field2, strict=True)
        constraints = self.get_constraints(AuthorWithUniqueName._meta.db_table)
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["name"]
            and details["unique"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 1)
        # Drop the unique constraint
        with connection.schema_editor() as editor:
            AuthorWithUniqueName._meta.constraints = []
            editor.remove_constraint(AuthorWithUniqueName, constraint)

    def test_unique_together(self):
        """
        Tests removing and adding unique_together constraints on a model.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(UniqueTest)
        # Ensure the fields are unique to begin with
        UniqueTest.objects.create(year=2012, slug="foo")
        UniqueTest.objects.create(year=2011, slug="foo")
        UniqueTest.objects.create(year=2011, slug="bar")
        with self.assertRaises(IntegrityError):
            UniqueTest.objects.create(year=2012, slug="foo")
        UniqueTest.objects.all().delete()
        # Alter the model to its non-unique-together companion
        with connection.schema_editor() as editor:
            editor.alter_unique_together(
                UniqueTest, UniqueTest._meta.unique_together, []
            )
        # Ensure the fields are no longer unique
        UniqueTest.objects.create(year=2012, slug="foo")
        UniqueTest.objects.create(year=2012, slug="foo")
        UniqueTest.objects.all().delete()
        # Alter it back
        new_field2 = SlugField(unique=True)
        new_field2.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_unique_together(
                UniqueTest, [], UniqueTest._meta.unique_together
            )
        # Ensure the fields are unique again
        UniqueTest.objects.create(year=2012, slug="foo")
        with self.assertRaises(IntegrityError):
            UniqueTest.objects.create(year=2012, slug="foo")
        UniqueTest.objects.all().delete()

    def test_unique_together_with_fk(self):
        """
        Tests removing and adding unique_together constraints that include
        a foreign key.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        # Ensure the fields are unique to begin with
        self.assertEqual(Book._meta.unique_together, ())
        # Add the unique_together constraint
        with connection.schema_editor() as editor:
            editor.alter_unique_together(Book, [], [["author", "title"]])
        # Alter it back
        with connection.schema_editor() as editor:
            editor.alter_unique_together(Book, [["author", "title"]], [])

    def test_unique_together_with_fk_with_existing_index(self):
        """
        Tests removing and adding unique_together constraints that include
        a foreign key, where the foreign key is added after the model is
        created.
        """
        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithoutAuthor)
            new_field = ForeignKey(Author, CASCADE)
            new_field.set_attributes_from_name("author")
            editor.add_field(BookWithoutAuthor, new_field)
        # Ensure the fields aren't unique to begin with
        self.assertEqual(Book._meta.unique_together, ())
        # Add the unique_together constraint
        with connection.schema_editor() as editor:
            editor.alter_unique_together(Book, [], [["author", "title"]])
        # Alter it back
        with connection.schema_editor() as editor:
            editor.alter_unique_together(Book, [["author", "title"]], [])

    def _test_composed_index_with_fk(self, index):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        table = Book._meta.db_table
        self.assertEqual(Book._meta.indexes, [])
        Book._meta.indexes = [index]
        with connection.schema_editor() as editor:
            editor.add_index(Book, index)
        self.assertIn(index.name, self.get_constraints(table))
        Book._meta.indexes = []
        with connection.schema_editor() as editor:
            editor.remove_index(Book, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    def test_composed_index_with_fk(self):
        """
        Tests the creation of a composed index that includes a foreign key.

        This test case verifies the functionality of creating an index with multiple fields, 
        including one that references another table, and ensures it behaves as expected.

        Args:
            None

        Returns:
            None
        """
        index = Index(fields=["author", "title"], name="book_author_title_idx")
        self._test_composed_index_with_fk(index)

    def test_composed_desc_index_with_fk(self):
        """
        Tests a composed index with a foreign key, ensuring proper functionality.

        The composed index combines multiple fields, in this case 'author' in descending order and 'title', 
        creating an index named 'book_author_title_idx' to optimize query performance on these fields.

        This test case verifies the correctness of the composed index with a foreign key constraint, 
        covering various scenarios to ensure its reliability and effectiveness in different situations.
        """
        index = Index(fields=["-author", "title"], name="book_author_title_idx")
        self._test_composed_index_with_fk(index)

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_composed_func_index_with_fk(self):
        """
        Tests the creation of a composed function-based index with a foreign key, specifically testing the 'book_author_title_idx' index that combines the 'author' and 'title' functional expressions.
        """
        index = Index(F("author"), F("title"), name="book_author_title_idx")
        self._test_composed_index_with_fk(index)

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_composed_desc_func_index_with_fk(self):
        """
        Tests the creation and functionality of a composed descending index with a foreign key.

        This test case focuses on verifying that an index can be successfully created 
        with a combination of columns, including a foreign key, and that it functions 
        as expected in a descending order scenario. The test covers the case where 
        the index is composed of multiple columns, one of which is a foreign key.

        The test creates an index named 'book_author_title_idx' with the 'author' 
        column in descending order and the 'title' column, then verifies its 
        correctness using the '_test_composed_index_with_fk' method.

        Requires the database feature 'supports_expression_indexes' to be available.
        """
        index = Index(F("author").desc(), F("title"), name="book_author_title_idx")
        self._test_composed_index_with_fk(index)

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_composed_func_transform_index_with_fk(self):
        index = Index(F("title__lower"), name="book_title_lower_idx")
        with register_lookup(CharField, Lower):
            self._test_composed_index_with_fk(index)

    def _test_composed_constraint_with_fk(self, constraint):
        """

        Tests the creation and removal of a composed constraint that includes a foreign key.

        Checks that the constraint can be successfully added to and removed from a model's metadata,
        and that the constraint is properly applied to and removed from the database table.

        Verifies the initial state of the model's constraints, adds the given constraint, 
        and checks that the constraint is present in the table's constraints after addition.
        Then, it removes the constraint and checks that it is no longer present in the table's constraints.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        table = Book._meta.db_table
        self.assertEqual(Book._meta.constraints, [])
        Book._meta.constraints = [constraint]
        with connection.schema_editor() as editor:
            editor.add_constraint(Book, constraint)
        self.assertIn(constraint.name, self.get_constraints(table))
        Book._meta.constraints = []
        with connection.schema_editor() as editor:
            editor.remove_constraint(Book, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    def test_composed_constraint_with_fk(self):
        """
        Tests a composed constraint that includes a foreign key.

        This test ensures that a unique constraint can be applied to a combination of fields, 
        including those that reference other tables via foreign keys. The constraint is defined 
        with specific fields and a custom name, and then verified through a separate testing method.

        :raises: AssertionError if the constraint is not properly enforced
        :param constraint: the unique constraint to be tested
        """
        constraint = UniqueConstraint(
            fields=["author", "title"],
            name="book_author_title_uniq",
        )
        self._test_composed_constraint_with_fk(constraint)

    @skipUnlessDBFeature(
        "supports_column_check_constraints", "can_introspect_check_constraints"
    )
    def test_composed_check_constraint_with_fk(self):
        constraint = CheckConstraint(
            condition=Q(author__gt=0), name="book_author_check"
        )
        self._test_composed_constraint_with_fk(constraint)

    @skipUnlessDBFeature("allows_multiple_constraints_on_same_fields")
    def test_remove_unique_together_does_not_remove_meta_constraints(self):
        """
        Tests that removing unique_together constraints does not affect meta constraints.

            Tests the behavior of altering unique_together constraints on a model and 
            verifies that custom meta constraints are preserved during this process.

            Specifically, it checks that:
            - A custom unique constraint can be added to a model.
            - The unique_together constraint can be removed without affecting the 
              custom meta constraint.
            - The unique_together constraint can be re-added after removal, and the 
              custom meta constraint remains intact.
            - Removing the custom meta constraint does not interfere with the 
              re-established unique_together constraint.
        """
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithUniqueNameAndBirthday)
        self.local_models = [AuthorWithUniqueNameAndBirthday]
        # Add the custom unique constraint
        constraint = UniqueConstraint(
            fields=["name", "birthday"], name="author_name_birthday_uniq"
        )
        custom_constraint_name = constraint.name
        AuthorWithUniqueNameAndBirthday._meta.constraints = [constraint]
        with connection.schema_editor() as editor:
            editor.add_constraint(AuthorWithUniqueNameAndBirthday, constraint)
        # Ensure the constraints exist
        constraints = self.get_constraints(
            AuthorWithUniqueNameAndBirthday._meta.db_table
        )
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["name", "birthday"]
            and details["unique"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 1)
        # Remove unique together
        unique_together = AuthorWithUniqueNameAndBirthday._meta.unique_together
        with connection.schema_editor() as editor:
            editor.alter_unique_together(
                AuthorWithUniqueNameAndBirthday, unique_together, []
            )
        constraints = self.get_constraints(
            AuthorWithUniqueNameAndBirthday._meta.db_table
        )
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["name", "birthday"]
            and details["unique"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 0)
        # Re-add unique together
        with connection.schema_editor() as editor:
            editor.alter_unique_together(
                AuthorWithUniqueNameAndBirthday, [], unique_together
            )
        constraints = self.get_constraints(
            AuthorWithUniqueNameAndBirthday._meta.db_table
        )
        self.assertIn(custom_constraint_name, constraints)
        other_constraints = [
            name
            for name, details in constraints.items()
            if details["columns"] == ["name", "birthday"]
            and details["unique"]
            and name != custom_constraint_name
        ]
        self.assertEqual(len(other_constraints), 1)
        # Drop the unique constraint
        with connection.schema_editor() as editor:
            AuthorWithUniqueNameAndBirthday._meta.constraints = []
            editor.remove_constraint(AuthorWithUniqueNameAndBirthday, constraint)

    def test_unique_constraint(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(fields=["name"], name="name_uq")
        # Add constraint.
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, constraint)
            sql = constraint.create_sql(Author, editor)
        table = Author._meta.db_table
        self.assertIs(sql.references_table(table), True)
        self.assertIs(sql.references_column(table, "name"), True)
        # Remove constraint.
        with connection.schema_editor() as editor:
            editor.remove_constraint(Author, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_unique_constraint(self):
        """
        Tests the generation and enforcement of a function-based unique constraint on a database table.

        The test covers creating a model with a unique constraint defined on an uppercase version of a column, adding the constraint to the database, and ensuring it is correctly enforced. Additionally, it verifies the SQL generated for creating the constraint and checks that the constraint can be removed from the database.

        The test is skipped unless the database backend supports expression indexes. It also checks for specific database features, such as support for index column ordering, and tests the constraint's properties, including its name, uniqueness, and column references.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(Upper("name").desc(), name="func_upper_uq")
        # Add constraint.
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, constraint)
            sql = constraint.create_sql(Author, editor)
        table = Author._meta.db_table
        constraints = self.get_constraints(table)
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(table, constraint.name, ["DESC"])
        self.assertIn(constraint.name, constraints)
        self.assertIs(constraints[constraint.name]["unique"], True)
        # SQL contains a database function.
        self.assertIs(sql.references_column(table, "name"), True)
        self.assertIn("UPPER(%s)" % editor.quote_name("name"), str(sql))
        # Remove constraint.
        with connection.schema_editor() as editor:
            editor.remove_constraint(Author, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_composite_func_unique_constraint(self):
        """

        Tests the creation and removal of a unique constraint that involves composite functions 
        such as `UPPER` and `LOWER` on a model's fields. 

        This test case verifies that the constraint is properly applied to the model, 
        ensuring that the database enforces uniqueness based on the functions applied to 
        the fields. It also checks that the SQL generated for the constraint is correct, 
        referencing the correct columns and using the correct functions.

        The test then verifies that the constraint can be successfully removed from the model.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithSlug)
        constraint = UniqueConstraint(
            Upper("title"),
            Lower("slug"),
            name="func_upper_lower_unq",
        )
        # Add constraint.
        with connection.schema_editor() as editor:
            editor.add_constraint(BookWithSlug, constraint)
            sql = constraint.create_sql(BookWithSlug, editor)
        table = BookWithSlug._meta.db_table
        constraints = self.get_constraints(table)
        self.assertIn(constraint.name, constraints)
        self.assertIs(constraints[constraint.name]["unique"], True)
        # SQL contains database functions.
        self.assertIs(sql.references_column(table, "title"), True)
        self.assertIs(sql.references_column(table, "slug"), True)
        sql = str(sql)
        self.assertIn("UPPER(%s)" % editor.quote_name("title"), sql)
        self.assertIn("LOWER(%s)" % editor.quote_name("slug"), sql)
        self.assertLess(sql.index("UPPER"), sql.index("LOWER"))
        # Remove constraint.
        with connection.schema_editor() as editor:
            editor.remove_constraint(BookWithSlug, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_unique_constraint_field_and_expression(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(
            F("height").desc(),
            "uuid",
            Lower("name").asc(),
            name="func_f_lower_field_unq",
        )
        # Add constraint.
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, constraint)
            sql = constraint.create_sql(Author, editor)
        table = Author._meta.db_table
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(table, constraint.name, ["DESC", "ASC", "ASC"])
        constraints = self.get_constraints(table)
        self.assertIs(constraints[constraint.name]["unique"], True)
        self.assertEqual(len(constraints[constraint.name]["columns"]), 3)
        self.assertEqual(constraints[constraint.name]["columns"][1], "uuid")
        # SQL contains database functions and columns.
        self.assertIs(sql.references_column(table, "height"), True)
        self.assertIs(sql.references_column(table, "name"), True)
        self.assertIs(sql.references_column(table, "uuid"), True)
        self.assertIn("LOWER(%s)" % editor.quote_name("name"), str(sql))
        # Remove constraint.
        with connection.schema_editor() as editor:
            editor.remove_constraint(Author, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes", "supports_partial_indexes")
    def test_func_unique_constraint_partial(self):
        """

        Tests the creation and behavior of a unique constraint with a partial condition.

        This test case verifies that a unique constraint can be successfully added to a model,
        with a condition that applies a function to a column and only applies when another
        column is not null. The test checks that the constraint is correctly created, 
        applies the expected condition, and can be removed.

        The test case also ensures that the generated SQL for the constraint creation
        includes the correct function application and conditional clause.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(
            Upper("name"),
            name="func_upper_cond_weight_uq",
            condition=Q(weight__isnull=False),
        )
        # Add constraint.
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, constraint)
            sql = constraint.create_sql(Author, editor)
        table = Author._meta.db_table
        constraints = self.get_constraints(table)
        self.assertIn(constraint.name, constraints)
        self.assertIs(constraints[constraint.name]["unique"], True)
        self.assertIs(sql.references_column(table, "name"), True)
        self.assertIn("UPPER(%s)" % editor.quote_name("name"), str(sql))
        self.assertIn(
            "WHERE %s IS NOT NULL" % editor.quote_name("weight"),
            str(sql),
        )
        # Remove constraint.
        with connection.schema_editor() as editor:
            editor.remove_constraint(Author, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes", "supports_covering_indexes")
    def test_func_unique_constraint_covering(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(
            Upper("name"),
            name="func_upper_covering_uq",
            include=["weight", "height"],
        )
        # Add constraint.
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, constraint)
            sql = constraint.create_sql(Author, editor)
        table = Author._meta.db_table
        constraints = self.get_constraints(table)
        self.assertIn(constraint.name, constraints)
        self.assertIs(constraints[constraint.name]["unique"], True)
        self.assertEqual(
            constraints[constraint.name]["columns"],
            [None, "weight", "height"],
        )
        self.assertIs(sql.references_column(table, "name"), True)
        self.assertIs(sql.references_column(table, "weight"), True)
        self.assertIs(sql.references_column(table, "height"), True)
        self.assertIn("UPPER(%s)" % editor.quote_name("name"), str(sql))
        self.assertIn(
            "INCLUDE (%s, %s)"
            % (
                editor.quote_name("weight"),
                editor.quote_name("height"),
            ),
            str(sql),
        )
        # Remove constraint.
        with connection.schema_editor() as editor:
            editor.remove_constraint(Author, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_unique_constraint_lookups(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        with register_lookup(CharField, Lower), register_lookup(IntegerField, Abs):
            constraint = UniqueConstraint(
                F("name__lower"),
                F("weight__abs"),
                name="func_lower_abs_lookup_uq",
            )
            # Add constraint.
            with connection.schema_editor() as editor:
                editor.add_constraint(Author, constraint)
                sql = constraint.create_sql(Author, editor)
            table = Author._meta.db_table
            constraints = self.get_constraints(table)
            self.assertIn(constraint.name, constraints)
            self.assertIs(constraints[constraint.name]["unique"], True)
            # SQL contains columns.
            self.assertIs(sql.references_column(table, "name"), True)
            self.assertIs(sql.references_column(table, "weight"), True)
            # Remove constraint.
            with connection.schema_editor() as editor:
                editor.remove_constraint(Author, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_unique_constraint_collate(self):
        """

        Tests the creation and removal of a unique constraint with case-insensitive collation.

        This test case checks that a unique constraint can be applied to a model field
        with a non-default collation, and that the constraint is correctly added and
        removed from the database schema. The test also verifies that the constraint is
        functioning as expected, including the correct ordering of index columns and the
        presence of the collation in the SQL query.

        The test requires a database backend that supports expression indexes and
        case-insensitive collations. If the backend does not support these features,
        the test will be skipped.

        """
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("This backend does not support case-insensitive collations.")
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithSlug)
        constraint = UniqueConstraint(
            Collate(F("title"), collation=collation).desc(),
            Collate("slug", collation=collation),
            name="func_collate_uq",
        )
        # Add constraint.
        with connection.schema_editor() as editor:
            editor.add_constraint(BookWithSlug, constraint)
            sql = constraint.create_sql(BookWithSlug, editor)
        table = BookWithSlug._meta.db_table
        constraints = self.get_constraints(table)
        self.assertIn(constraint.name, constraints)
        self.assertIs(constraints[constraint.name]["unique"], True)
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(table, constraint.name, ["DESC", "ASC"])
        # SQL contains columns and a collation.
        self.assertIs(sql.references_column(table, "title"), True)
        self.assertIs(sql.references_column(table, "slug"), True)
        self.assertIn("COLLATE %s" % editor.quote_name(collation), str(sql))
        # Remove constraint.
        with connection.schema_editor() as editor:
            editor.remove_constraint(BookWithSlug, constraint)
        self.assertNotIn(constraint.name, self.get_constraints(table))

    @skipIfDBFeature("supports_expression_indexes")
    def test_func_unique_constraint_unsupported(self):
        # UniqueConstraint is ignored on databases that don't support indexes on
        # expressions.
        """

        Checks that adding and removing a unique constraint with a function-based index 
        is unsupported, as expected in certain database backends.

        The test validates that the database correctly handles the creation and removal 
        of a unique constraint on a model field, in this case, the 'name' field of the 
        Author model, where the constraint is defined using a function-based index.

        It verifies that the add and remove constraint operations return None, indicating 
        that the operations are not executed due to lack of support in the underlying 
        database.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(F("name"), name="func_name_uq")
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            self.assertIsNone(editor.add_constraint(Author, constraint))
            self.assertIsNone(editor.remove_constraint(Author, constraint))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_unique_constraint_nonexistent_field(self):
        constraint = UniqueConstraint(Lower("nonexistent"), name="func_nonexistent_uq")
        msg = (
            "Cannot resolve keyword 'nonexistent' into field. Choices are: "
            "height, id, name, uuid, weight"
        )
        with self.assertRaisesMessage(FieldError, msg):
            with connection.schema_editor() as editor:
                editor.add_constraint(Author, constraint)

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_unique_constraint_nondeterministic(self):
        """
        Tests that attempting to add a unique constraint with a non-deterministic function to a model raises a DatabaseError.

        This test checks the behavior of the database when trying to create a unique constraint
        that uses a non-deterministic function, such as one that generates random values.
        It verifies that the database correctly prevents the creation of such a constraint,
        as it would not be able to enforce the uniqueness requirement.

        The test is skipped if the database does not support expression indexes.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(Random(), name="func_random_uq")
        with connection.schema_editor() as editor:
            with self.assertRaises(DatabaseError):
                editor.add_constraint(Author, constraint)

    @skipUnlessDBFeature("supports_nulls_distinct_unique_constraints")
    def test_unique_constraint_index_nulls_distinct(self):
        """
        Tests that a model can enforce unique constraints with and without nulls being distinct.

        This test case checks the database's ability to handle unique constraints where null values are 
        either considered distinct or not. It creates a model with two fields (`height` and `weight`), 
        each with a unique constraint but with differing null distinctness. It then attempts to create 
        multiple instances of the model with varying values for these fields, checking for expected 
        IntegrityError when duplicate values are inserted under a constraint where nulls are not 
        distinct. Finally, it verifies that these constraints can be removed from the model.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        nulls_distinct = UniqueConstraint(
            F("height"), name="distinct_height", nulls_distinct=True
        )
        nulls_not_distinct = UniqueConstraint(
            F("weight"), name="not_distinct_weight", nulls_distinct=False
        )
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, nulls_distinct)
            editor.add_constraint(Author, nulls_not_distinct)
        Author.objects.create(name="", height=None, weight=None)
        Author.objects.create(name="", height=None, weight=1)
        with self.assertRaises(IntegrityError):
            Author.objects.create(name="", height=1, weight=None)
        with connection.schema_editor() as editor:
            editor.remove_constraint(Author, nulls_distinct)
            editor.remove_constraint(Author, nulls_not_distinct)
        constraints = self.get_constraints(Author._meta.db_table)
        self.assertNotIn(nulls_distinct.name, constraints)
        self.assertNotIn(nulls_not_distinct.name, constraints)

    @skipUnlessDBFeature("supports_nulls_distinct_unique_constraints")
    def test_unique_constraint_nulls_distinct(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(
            fields=["height", "weight"], name="constraint", nulls_distinct=False
        )
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, constraint)
        Author.objects.create(name="", height=None, weight=None)
        Author.objects.create(name="", height=1, weight=None)
        Author.objects.create(name="", height=None, weight=1)
        with self.assertRaises(IntegrityError):
            Author.objects.create(name="", height=None, weight=None)
        with self.assertRaises(IntegrityError):
            Author.objects.create(name="", height=1, weight=None)
        with self.assertRaises(IntegrityError):
            Author.objects.create(name="", height=None, weight=1)
        with connection.schema_editor() as editor:
            editor.remove_constraint(Author, constraint)
        constraints = self.get_constraints(Author._meta.db_table)
        self.assertNotIn(constraint.name, constraints)

    @skipUnlessDBFeature(
        "supports_nulls_distinct_unique_constraints",
        "supports_partial_indexes",
    )
    def test_unique_constraint_nulls_distinct_condition(self):
        """

        Tests the behavior of unique constraints with nulls distinct condition.

        This test case creates a model with a unique constraint that has a condition and
        nulls distinct set to False. It then attempts to create objects that violate this
        constraint and checks that an IntegrityError is raised. The test covers various
        scenarios, including objects with null values for the constrained fields, and
        ensures that the constraint is properly removed after the test is finished.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(
            fields=["height", "weight"],
            name="un_height_weight_start_A",
            condition=Q(name__startswith="A"),
            nulls_distinct=False,
        )
        with connection.schema_editor() as editor:
            editor.add_constraint(Author, constraint)
        Author.objects.create(name="Adam", height=None, weight=None)
        Author.objects.create(name="Avocado", height=1, weight=None)
        Author.objects.create(name="Adrian", height=None, weight=1)
        with self.assertRaises(IntegrityError):
            Author.objects.create(name="Alex", height=None, weight=None)
        Author.objects.create(name="Bob", height=None, weight=None)
        with self.assertRaises(IntegrityError):
            Author.objects.create(name="Alex", height=1, weight=None)
        Author.objects.create(name="Bill", height=None, weight=None)
        with self.assertRaises(IntegrityError):
            Author.objects.create(name="Alex", height=None, weight=1)
        Author.objects.create(name="Celine", height=None, weight=1)
        with connection.schema_editor() as editor:
            editor.remove_constraint(Author, constraint)
        constraints = self.get_constraints(Author._meta.db_table)
        self.assertNotIn(constraint.name, constraints)

    @skipIfDBFeature("supports_nulls_distinct_unique_constraints")
    def test_unique_constraint_nulls_distinct_unsupported(self):
        # UniqueConstraint is ignored on databases that don't support
        # NULLS [NOT] DISTINCT.
        """
        Tests the behavior of unique constraints with nulls_distinct=True in a database 
        that does not support this feature.

        This test case checks that attempting to add a unique constraint with 
        nulls_distinct=True to a model does not result in any database queries or 
        modifications, and that the constraint can be successfully removed without 
        any issues. The test ensures that the schema editor handles this unsupported 
        database feature correctly and prevents any potential errors or data corruption.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        constraint = UniqueConstraint(
            F("name"), name="func_name_uq", nulls_distinct=True
        )
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            self.assertIsNone(editor.add_constraint(Author, constraint))
            self.assertIsNone(editor.remove_constraint(Author, constraint))

    def test_index_together(self):
        """
        Tests removing and adding index_together constraints on a model.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
        # Ensure there's no index on the year/slug columns first
        self.assertIs(
            any(
                c["index"]
                for c in self.get_constraints("schema_tag").values()
                if c["columns"] == ["slug", "title"]
            ),
            False,
        )
        # Alter the model to add an index
        with connection.schema_editor() as editor:
            editor.alter_index_together(Tag, [], [("slug", "title")])
        # Ensure there is now an index
        self.assertIs(
            any(
                c["index"]
                for c in self.get_constraints("schema_tag").values()
                if c["columns"] == ["slug", "title"]
            ),
            True,
        )
        # Alter it back
        new_field2 = SlugField(unique=True)
        new_field2.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_index_together(Tag, [("slug", "title")], [])
        # Ensure there's no index
        self.assertIs(
            any(
                c["index"]
                for c in self.get_constraints("schema_tag").values()
                if c["columns"] == ["slug", "title"]
            ),
            False,
        )

    @isolate_apps("schema")
    def test_db_table(self):
        """
        Tests renaming of the table
        """

        class Author(Model):
            name = CharField(max_length=255)

            class Meta:
                app_label = "schema"

        class Book(Model):
            author = ForeignKey(Author, CASCADE)

            class Meta:
                app_label = "schema"

        # Create the table and one referring it.
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        # Ensure the table is there to begin with
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["name"][0],
            connection.features.introspected_field_types["CharField"],
        )
        # Alter the table
        with connection.schema_editor() as editor:
            editor.alter_db_table(Author, "schema_author", "schema_otherauthor")
        Author._meta.db_table = "schema_otherauthor"
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["name"][0],
            connection.features.introspected_field_types["CharField"],
        )
        # Ensure the foreign key reference was updated
        self.assertForeignKeyExists(Book, "author_id", "schema_otherauthor")
        # Alter the table again
        with connection.schema_editor() as editor:
            editor.alter_db_table(Author, "schema_otherauthor", "schema_author")
        # Ensure the table is still there
        Author._meta.db_table = "schema_author"
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["name"][0],
            connection.features.introspected_field_types["CharField"],
        )

    def test_add_remove_index(self):
        """
        Tests index addition and removal
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the table is there and has no index
        self.assertNotIn("title", self.get_indexes(Author._meta.db_table))
        # Add the index
        index = Index(fields=["name"], name="author_title_idx")
        with connection.schema_editor() as editor:
            editor.add_index(Author, index)
        self.assertIn("name", self.get_indexes(Author._meta.db_table))
        # Drop the index
        with connection.schema_editor() as editor:
            editor.remove_index(Author, index)
        self.assertNotIn("name", self.get_indexes(Author._meta.db_table))

    def test_remove_db_index_doesnt_remove_custom_indexes(self):
        """
        Changing db_index to False doesn't remove indexes from Meta.indexes.
        """
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithIndexedName)
        self.local_models = [AuthorWithIndexedName]
        # Ensure the table has its index
        self.assertIn("name", self.get_indexes(AuthorWithIndexedName._meta.db_table))

        # Add the custom index
        index = Index(fields=["-name"], name="author_name_idx")
        author_index_name = index.name
        with connection.schema_editor() as editor:
            db_index_name = editor._create_index_name(
                table_name=AuthorWithIndexedName._meta.db_table,
                column_names=("name",),
            )
        try:
            AuthorWithIndexedName._meta.indexes = [index]
            with connection.schema_editor() as editor:
                editor.add_index(AuthorWithIndexedName, index)
            old_constraints = self.get_constraints(AuthorWithIndexedName._meta.db_table)
            self.assertIn(author_index_name, old_constraints)
            self.assertIn(db_index_name, old_constraints)
            # Change name field to db_index=False
            old_field = AuthorWithIndexedName._meta.get_field("name")
            new_field = CharField(max_length=255)
            new_field.set_attributes_from_name("name")
            with connection.schema_editor() as editor:
                editor.alter_field(
                    AuthorWithIndexedName, old_field, new_field, strict=True
                )
            new_constraints = self.get_constraints(AuthorWithIndexedName._meta.db_table)
            self.assertNotIn(db_index_name, new_constraints)
            # The index from Meta.indexes is still in the database.
            self.assertIn(author_index_name, new_constraints)
            # Drop the index
            with connection.schema_editor() as editor:
                editor.remove_index(AuthorWithIndexedName, index)
        finally:
            AuthorWithIndexedName._meta.indexes = []

    def test_order_index(self):
        """
        Indexes defined with ordering (ASC/DESC) defined on column
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # The table doesn't have an index
        self.assertNotIn("title", self.get_indexes(Author._meta.db_table))
        index_name = "author_name_idx"
        # Add the index
        index = Index(fields=["name", "-weight"], name=index_name)
        with connection.schema_editor() as editor:
            editor.add_index(Author, index)
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(Author._meta.db_table, index_name, ["ASC", "DESC"])
        # Drop the index
        with connection.schema_editor() as editor:
            editor.remove_index(Author, index)

    def test_indexes(self):
        """
        Tests creation/altering of indexes
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        # Ensure the table is there and has the right index
        self.assertIn(
            "title",
            self.get_indexes(Book._meta.db_table),
        )
        # Alter to remove the index
        old_field = Book._meta.get_field("title")
        new_field = CharField(max_length=100, db_index=False)
        new_field.set_attributes_from_name("title")
        with connection.schema_editor() as editor:
            editor.alter_field(Book, old_field, new_field, strict=True)
        # Ensure the table is there and has no index
        self.assertNotIn(
            "title",
            self.get_indexes(Book._meta.db_table),
        )
        # Alter to re-add the index
        new_field2 = Book._meta.get_field("title")
        with connection.schema_editor() as editor:
            editor.alter_field(Book, new_field, new_field2, strict=True)
        # Ensure the table is there and has the index again
        self.assertIn(
            "title",
            self.get_indexes(Book._meta.db_table),
        )
        # Add a unique column, verify that creates an implicit index
        new_field3 = BookWithSlug._meta.get_field("slug")
        with connection.schema_editor() as editor:
            editor.add_field(Book, new_field3)
        self.assertIn(
            "slug",
            self.get_uniques(Book._meta.db_table),
        )
        # Remove the unique, check the index goes with it
        new_field4 = CharField(max_length=20, unique=False)
        new_field4.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithSlug, new_field3, new_field4, strict=True)
        self.assertNotIn(
            "slug",
            self.get_uniques(Book._meta.db_table),
        )

    def test_text_field_with_db_index(self):
        """
        Tests the creation of a database index on a text field.

            Verifies that the index is created or not, depending on the database backend's
            support for indexing text fields. If the database supports indexing text fields,
            the test checks that the index is present; otherwise, it checks that the index
            is not created.

            Note:
                The test case uses a model (AuthorTextFieldWithIndex) to create a table
                with a text field and an index, and then checks the database schema to
                confirm the expected behavior.

        """
        with connection.schema_editor() as editor:
            editor.create_model(AuthorTextFieldWithIndex)
        # The text_field index is present if the database supports it.
        assertion = (
            self.assertIn
            if connection.features.supports_index_on_text_field
            else self.assertNotIn
        )
        assertion(
            "text_field", self.get_indexes(AuthorTextFieldWithIndex._meta.db_table)
        )

    def _index_expressions_wrappers(self):
        """
        Retrieve a comma-separated string of qualified names for the wrapper classes used by index expressions.

        Returns:
            str: A string containing the qualified names of the wrapper classes, separated by commas.

        This method is used to obtain the list of wrapper classes that are utilized by index expressions, 
        typically in the context of database connections. The returned string can be used for logging, 
        debugging, or other purposes where the wrapper class names are required. 

        Note: This method is intended for internal use and should not be called directly from external code.
        """
        index_expression = IndexExpression()
        index_expression.set_wrapper_classes(connection)
        return ", ".join(
            [
                wrapper_cls.__qualname__
                for wrapper_cls in index_expression.wrapper_classes
            ]
        )

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_multiple_wrapper_references(self):
        """

        Tests the database's support for creating an index with multiple references to the same expression wrapper.

        Verifies that an attempt to create such an index raises a :class:`ValueError` with a descriptive error message.

        The test targets databases that support expression indexes, ensuring that the database correctly enforces this constraint.

        """
        index = Index(OrderBy(F("name").desc(), descending=True), name="name")
        msg = (
            "Multiple references to %s can't be used in an indexed expression."
            % self._index_expressions_wrappers()
        )
        with connection.schema_editor() as editor:
            with self.assertRaisesMessage(ValueError, msg):
                editor.add_index(Author, index)

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_invalid_topmost_expressions(self):
        index = Index(Upper(F("name").desc()), name="name")
        msg = (
            "%s must be topmost expressions in an indexed expression."
            % self._index_expressions_wrappers()
        )
        with connection.schema_editor() as editor:
            with self.assertRaisesMessage(ValueError, msg):
                editor.add_index(Author, index)

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index(self):
        """

        Tests the creation and removal of a functional index on a model.

        This test case verifies that a functional index can be successfully added to a model,
        and that its creation SQL correctly references the target column. It also checks that
        the index is removed as expected. The test covers index ordering support checks when
        available in the database.

        The test uses the Author model and creates a functional index on the 'name' column,
        using the LOWER function to create a case-insensitive index. The test then removes
        the index to ensure it can be deleted without errors.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        index = Index(Lower("name").desc(), name="func_lower_idx")
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(Author, index)
            sql = index.create_sql(Author, editor)
        table = Author._meta.db_table
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(table, index.name, ["DESC"])
        # SQL contains a database function.
        self.assertIs(sql.references_column(table, "name"), True)
        self.assertIn("LOWER(%s)" % editor.quote_name("name"), str(sql))
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Author, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_f(self):
        """
        Tests the creation, properties, and removal of a functional index.

        This test case covers the following scenarios:
        - Creating a model with an expression index using the schema editor.
        - Adding a functional index to the model and verifying its existence.
        - Validating the SQL query generated for creating the index.
        - Checking the column ordering of the index, if supported by the database.
        - Removing the index and verifying its successful deletion.

        The test function index ensures that the database backend correctly handles
        functional indexes with expressions, including the creation and removal of
        such indexes, and verifies the generated SQL references the correct columns.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
        index = Index("slug", F("title").desc(), name="func_f_idx")
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(Tag, index)
            sql = index.create_sql(Tag, editor)
        table = Tag._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(Tag._meta.db_table, index.name, ["ASC", "DESC"])
        # SQL contains columns.
        self.assertIs(sql.references_column(table, "slug"), True)
        self.assertIs(sql.references_column(table, "title"), True)
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Tag, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_lookups(self):
        """
        Tests the creation and removal of a function-based index on a model.

        This test case verifies that an index can be successfully created and dropped
        on a model using function-based lookups. It checks that the created index
        references the correct columns and that it is properly removed after deletion.

        The test uses the Author model and creates an index on the 'name' and 'weight'
        columns using the 'Lower' and 'Abs' lookups, respectively. It then checks
        that the index is created correctly, references the correct columns, and
        is removed after deletion.

        Requires a database that supports expression indexes.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        with register_lookup(CharField, Lower), register_lookup(IntegerField, Abs):
            index = Index(
                F("name__lower"),
                F("weight__abs"),
                name="func_lower_abs_lookup_idx",
            )
            # Add index.
            with connection.schema_editor() as editor:
                editor.add_index(Author, index)
                sql = index.create_sql(Author, editor)
        table = Author._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        # SQL contains columns.
        self.assertIs(sql.references_column(table, "name"), True)
        self.assertIs(sql.references_column(table, "weight"), True)
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Author, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_composite_func_index(self):
        """

        Tests the creation of a composite index using functional expressions.

        Verifies that an index can be successfully created, added to the database schema,
        and removed. The test checks that the index is correctly defined using the Lower
        and Upper database functions, and that the SQL generated for creating the index
        is valid and consistent with the expected output.

        The test covers the following scenarios:

        * Creation of the index using the Lower and Upper functions
        * Addition of the index to the database schema
        * Verification of the index existence and SQL generation
        * Removal of the index from the database schema

        Ensures that the database schema is updated correctly and that the index is
        properly defined and removed.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        index = Index(Lower("name"), Upper("name"), name="func_lower_upper_idx")
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(Author, index)
            sql = index.create_sql(Author, editor)
        table = Author._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        # SQL contains database functions.
        self.assertIs(sql.references_column(table, "name"), True)
        sql = str(sql)
        self.assertIn("LOWER(%s)" % editor.quote_name("name"), sql)
        self.assertIn("UPPER(%s)" % editor.quote_name("name"), sql)
        self.assertLess(sql.index("LOWER"), sql.index("UPPER"))
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Author, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_composite_func_index_field_and_expression(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        index = Index(
            F("author").desc(),
            Lower("title").asc(),
            "pub_date",
            name="func_f_lower_field_idx",
        )
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(Book, index)
            sql = index.create_sql(Book, editor)
        table = Book._meta.db_table
        constraints = self.get_constraints(table)
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(table, index.name, ["DESC", "ASC", "ASC"])
        self.assertEqual(len(constraints[index.name]["columns"]), 3)
        self.assertEqual(constraints[index.name]["columns"][2], "pub_date")
        # SQL contains database functions and columns.
        self.assertIs(sql.references_column(table, "author_id"), True)
        self.assertIs(sql.references_column(table, "title"), True)
        self.assertIs(sql.references_column(table, "pub_date"), True)
        self.assertIn("LOWER(%s)" % editor.quote_name("title"), str(sql))
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Book, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    @isolate_apps("schema")
    def test_func_index_f_decimalfield(self):
        class Node(Model):
            value = DecimalField(max_digits=5, decimal_places=2)

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Node)
        index = Index(F("value"), name="func_f_decimalfield_idx")
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(Node, index)
            sql = index.create_sql(Node, editor)
        table = Node._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        self.assertIs(sql.references_column(table, "value"), True)
        # SQL doesn't contain casting.
        self.assertNotIn("CAST", str(sql))
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Node, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_cast(self):
        """

        Tests the creation and removal of a database index with a functional cast.

        This test case ensures that a database index can be successfully created and removed
        when using a functional cast to a specific data type, in this case a FloatField cast
        for the 'weight' field of the Author model.

        The test covers the following scenarios:

        * Creating the Author model in the database
        * Adding an index with a functional cast to the Author model
        * Verifying that the index has been successfully created and references the expected column
        * Removing the index from the Author model
        * Verifying that the index has been successfully removed

        The test requires the 'supports_expression_indexes' database feature to be supported.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        index = Index(Cast("weight", FloatField()), name="func_cast_idx")
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(Author, index)
            sql = index.create_sql(Author, editor)
        table = Author._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        self.assertIs(sql.references_column(table, "weight"), True)
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Author, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_collate(self):
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("This backend does not support case-insensitive collations.")
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithSlug)
        index = Index(
            Collate(F("title"), collation=collation).desc(),
            Collate("slug", collation=collation),
            name="func_collate_idx",
        )
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(BookWithSlug, index)
            sql = index.create_sql(BookWithSlug, editor)
        table = Book._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(table, index.name, ["DESC", "ASC"])
        # SQL contains columns and a collation.
        self.assertIs(sql.references_column(table, "title"), True)
        self.assertIs(sql.references_column(table, "slug"), True)
        self.assertIn("COLLATE %s" % editor.quote_name(collation), str(sql))
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Book, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    @skipIfDBFeature("collate_as_index_expression")
    def test_func_index_collate_f_ordered(self):
        """

        Test that a func expression index with collation can be created and used.

        The test checks the following:

        *   A model (Author) can be created with a custom collation index on the 'name' field.
        *   The index with the specified collation can be successfully added and removed.
        *   The created index has the correct name and ordering (if supported by the database).
        *   The generated SQL includes the specified collation.

        The test requires the database backend to support expression indexes and non-default collations.

        """
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("This backend does not support case-insensitive collations.")
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        index = Index(
            Collate(F("name").desc(), collation=collation),
            name="func_collate_f_desc_idx",
        )
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(Author, index)
            sql = index.create_sql(Author, editor)
        table = Author._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        if connection.features.supports_index_column_ordering:
            self.assertIndexOrder(table, index.name, ["DESC"])
        # SQL contains columns and a collation.
        self.assertIs(sql.references_column(table, "name"), True)
        self.assertIn("COLLATE %s" % editor.quote_name(collation), str(sql))
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Author, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_calc(self):
        """

        Tests the creation and removal of a functional index on a model.

        The index is calculated based on an expression, specifically the division of two model fields, 
        with a constant value added to the divisor to prevent division by zero.

        Verifies that the index is correctly created, added to the model, and validated against the 
        database schema. Additionally, checks that the SQL query generated for the index creation 
        references the correct columns and follows the expected syntax.

        Ensures that the index is properly removed from the model and database schema when deleted.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        index = Index(F("height") / (F("weight") + Value(5)), name="func_calc_idx")
        # Add index.
        with connection.schema_editor() as editor:
            editor.add_index(Author, index)
            sql = index.create_sql(Author, editor)
        table = Author._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        # SQL contains columns and expressions.
        self.assertIs(sql.references_column(table, "height"), True)
        self.assertIs(sql.references_column(table, "weight"), True)
        sql = str(sql)
        self.assertIs(
            sql.index(editor.quote_name("height"))
            < sql.index("/")
            < sql.index(editor.quote_name("weight"))
            < sql.index("+")
            < sql.index("5"),
            True,
        )
        # Remove index.
        with connection.schema_editor() as editor:
            editor.remove_index(Author, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes", "supports_json_field")
    @isolate_apps("schema")
    def test_func_index_json_key_transform(self):
        class JSONModel(Model):
            field = JSONField()

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(JSONModel)
        self.isolated_local_models = [JSONModel]
        index = Index("field__some_key", name="func_json_key_idx")
        with connection.schema_editor() as editor:
            editor.add_index(JSONModel, index)
            sql = index.create_sql(JSONModel, editor)
        table = JSONModel._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        self.assertIs(sql.references_column(table, "field"), True)
        with connection.schema_editor() as editor:
            editor.remove_index(JSONModel, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipUnlessDBFeature("supports_expression_indexes", "supports_json_field")
    @isolate_apps("schema")
    def test_func_index_json_key_transform_cast(self):
        class JSONModel(Model):
            field = JSONField()

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(JSONModel)
        self.isolated_local_models = [JSONModel]
        index = Index(
            Cast(KeyTextTransform("some_key", "field"), IntegerField()),
            name="func_json_key_cast_idx",
        )
        with connection.schema_editor() as editor:
            editor.add_index(JSONModel, index)
            sql = index.create_sql(JSONModel, editor)
        table = JSONModel._meta.db_table
        self.assertIn(index.name, self.get_constraints(table))
        self.assertIs(sql.references_column(table, "field"), True)
        with connection.schema_editor() as editor:
            editor.remove_index(JSONModel, index)
        self.assertNotIn(index.name, self.get_constraints(table))

    @skipIfDBFeature("supports_expression_indexes")
    def test_func_index_unsupported(self):
        # Index is ignored on databases that don't support indexes on
        # expressions.
        """

        Tests the behavior of adding and removing a functional index when the database
        backend does not support expression indexes.

        This test case verifies that attempting to add or remove a functional index on a
        model when the underlying database does not support expression indexes results in
        no changes being made to the database schema.

        The test covers the following scenarios:

        * Creating a model with a functional index using the schema editor
        * Adding a functional index to the model
        * Removing a functional index from the model

        In both cases, the expected outcome is that no queries are executed and no changes
        are applied to the database schema, as the database backend does not support
        expression indexes.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        index = Index(F("name"), name="random_idx")
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            self.assertIsNone(editor.add_index(Author, index))
            self.assertIsNone(editor.remove_index(Author, index))

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_nonexistent_field(self):
        """

        Tests the addition of a functional index referencing a nonexistent field.

        Verifies that a `FieldError` is raised when attempting to create an index on a
        field that does not exist in the model. The test case checks that the error
        message correctly identifies the available fields and indicates that the
        specified field cannot be resolved.

        """
        index = Index(Lower("nonexistent"), name="func_nonexistent_idx")
        msg = (
            "Cannot resolve keyword 'nonexistent' into field. Choices are: "
            "height, id, name, uuid, weight"
        )
        with self.assertRaisesMessage(FieldError, msg):
            with connection.schema_editor() as editor:
                editor.add_index(Author, index)

    @skipUnlessDBFeature("supports_expression_indexes")
    def test_func_index_nondeterministic(self):
        """
        Test adding an index based on a non-deterministic function.

        Checks that attempting to create an index on a model using a non-deterministic
        function (in this case, the `Random()` function) raises a `DatabaseError`.
        This test ensures that the ORM correctly handles the creation of indexes with
        functions that do not always return the same output given the same inputs.

        The test creates a model instance, then attempts to add the index using a
        `Random()` function as the index expression. The expected outcome is that
        the database backend will reject this operation, resulting in a `DatabaseError`
        being raised. This behavior is tested using a schema editor, simulating the
        creation of the index on the model. The test requires a database backend that
        supports expression indexes to run successfully.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        index = Index(Random(), name="func_random_idx")
        with connection.schema_editor() as editor:
            with self.assertRaises(DatabaseError):
                editor.add_index(Author, index)

    def test_primary_key(self):
        """
        Tests altering of the primary key
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
        # Ensure the table is there and has the right PK
        self.assertEqual(self.get_primary_key(Tag._meta.db_table), "id")
        # Alter to change the PK
        id_field = Tag._meta.get_field("id")
        old_field = Tag._meta.get_field("slug")
        new_field = SlugField(primary_key=True)
        new_field.set_attributes_from_name("slug")
        new_field.model = Tag
        with connection.schema_editor() as editor:
            editor.remove_field(Tag, id_field)
            editor.alter_field(Tag, old_field, new_field)
        # Ensure the PK changed
        self.assertNotIn(
            "id",
            self.get_indexes(Tag._meta.db_table),
        )
        self.assertEqual(self.get_primary_key(Tag._meta.db_table), "slug")

    def test_alter_primary_key_the_same_name(self):
        """

        Tests the alteration of a primary key field to a new field with the same name.

        This test case creates a model `Thing`, then alters the primary key field `when` 
        to a character field with the same name, and verifies that the primary key remains 
        unchanged. It also reverses the alteration to ensure that the original primary key 
        is restored correctly.

        The test ensures that the database schema is updated correctly when altering a 
        primary key field to a new field with the same name, and that the primary key 
        constraint is preserved throughout the alteration process.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Thing)

        old_field = Thing._meta.get_field("when")
        new_field = CharField(max_length=2, primary_key=True)
        new_field.set_attributes_from_name("when")
        new_field.model = Thing
        with connection.schema_editor() as editor:
            editor.alter_field(Thing, old_field, new_field, strict=True)
        self.assertEqual(self.get_primary_key(Thing._meta.db_table), "when")
        with connection.schema_editor() as editor:
            editor.alter_field(Thing, new_field, old_field, strict=True)
        self.assertEqual(self.get_primary_key(Thing._meta.db_table), "when")

    def test_context_manager_exit(self):
        """
        Ensures transaction is correctly closed when an error occurs
        inside a SchemaEditor context.
        """

        class SomeError(Exception):
            pass

        try:
            with connection.schema_editor():
                raise SomeError
        except SomeError:
            self.assertFalse(connection.in_atomic_block)

    @skipIfDBFeature("can_rollback_ddl")
    def test_unsupported_transactional_ddl_disallowed(self):
        message = (
            "Executing DDL statements while in a transaction on databases "
            "that can't perform a rollback is prohibited."
        )
        with atomic(), connection.schema_editor() as editor:
            with self.assertRaisesMessage(TransactionManagementError, message):
                editor.execute(
                    editor.sql_create_table % {"table": "foo", "definition": ""}
                )

    @skipUnlessDBFeature("supports_foreign_keys", "indexes_foreign_keys")
    def test_foreign_key_index_long_names_regression(self):
        """
        Regression test for #21497.
        Only affects databases that supports foreign keys.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithEvenLongerName)
            editor.create_model(BookWithLongName)
        # Find the properly shortened column name
        column_name = connection.ops.quote_name(
            "author_foreign_key_with_really_long_field_name_id"
        )
        column_name = column_name[1:-1].lower()  # unquote, and, for Oracle, un-upcase
        # Ensure the table is there and has an index on the column
        self.assertIn(
            column_name,
            self.get_indexes(BookWithLongName._meta.db_table),
        )

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_add_foreign_key_long_names(self):
        """
        Regression test for #23009.
        Only affects databases that supports foreign keys.
        """
        # Create the initial tables
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithEvenLongerName)
            editor.create_model(BookWithLongName)
        # Add a second FK, this would fail due to long ref name before the fix
        new_field = ForeignKey(
            AuthorWithEvenLongerName, CASCADE, related_name="something"
        )
        new_field.set_attributes_from_name(
            "author_other_really_long_named_i_mean_so_long_fk"
        )
        with connection.schema_editor() as editor:
            editor.add_field(BookWithLongName, new_field)

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_foreign_keys")
    def test_add_foreign_key_quoted_db_table(self):
        """

        Tests the addition of a foreign key to a model when the database table name is quoted.

        This test case creates two models, Author and Book, where Book has a foreign key to Author.
        The Author model's database table name is explicitly set to a quoted name.
        The test then creates these models in the database and verifies that the foreign key constraint is correctly created.

        The test is skipped if the database does not support foreign keys, and it isolates the test to the 'schema' app to prevent interference with other tests.

        """
        class Author(Model):
            class Meta:
                db_table = '"table_author_double_quoted"'
                app_label = "schema"

        class Book(Model):
            author = ForeignKey(Author, CASCADE)

            class Meta:
                app_label = "schema"

        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        self.isolated_local_models = [Author]
        if connection.vendor == "mysql":
            self.assertForeignKeyExists(
                Book, "author_id", '"table_author_double_quoted"'
            )
        else:
            self.assertForeignKeyExists(Book, "author_id", "table_author_double_quoted")

    def test_add_foreign_object(self):
        with connection.schema_editor() as editor:
            editor.create_model(BookForeignObj)
        self.local_models = [BookForeignObj]

        new_field = ForeignObject(
            Author, on_delete=CASCADE, from_fields=["author_id"], to_fields=["id"]
        )
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.add_field(BookForeignObj, new_field)

    def test_creation_deletion_reserved_names(self):
        """
        Tries creating a model's table, and then deleting it when it has a
        SQL reserved name.
        """
        # Create the table
        with connection.schema_editor() as editor:
            try:
                editor.create_model(Thing)
            except OperationalError as e:
                self.fail(
                    "Errors when applying initial migration for a model "
                    "with a table named after an SQL reserved word: %s" % e
                )
        # The table is there
        list(Thing.objects.all())
        # Clean up that table
        with connection.schema_editor() as editor:
            editor.delete_model(Thing)
        # The table is gone
        with self.assertRaises(DatabaseError):
            list(Thing.objects.all())

    def test_remove_constraints_capital_letters(self):
        """
        #23065 - Constraint names must be quoted if they contain capital letters.
        """

        def get_field(*args, field_class=IntegerField, **kwargs):
            kwargs["db_column"] = "CamelCase"
            field = field_class(*args, **kwargs)
            field.set_attributes_from_name("CamelCase")
            return field

        model = Author
        field = get_field()
        table = model._meta.db_table
        column = field.column
        identifier_converter = connection.introspection.identifier_converter

        with connection.schema_editor() as editor:
            editor.create_model(model)
            editor.add_field(model, field)

            constraint_name = "CamelCaseIndex"
            expected_constraint_name = identifier_converter(constraint_name)
            editor.execute(
                editor.sql_create_index
                % {
                    "table": editor.quote_name(table),
                    "name": editor.quote_name(constraint_name),
                    "using": "",
                    "columns": editor.quote_name(column),
                    "extra": "",
                    "condition": "",
                    "include": "",
                }
            )
            self.assertIn(
                expected_constraint_name, self.get_constraints(model._meta.db_table)
            )
            editor.alter_field(model, get_field(db_index=True), field, strict=True)
            self.assertNotIn(
                expected_constraint_name, self.get_constraints(model._meta.db_table)
            )

            constraint_name = "CamelCaseUniqConstraint"
            expected_constraint_name = identifier_converter(constraint_name)
            editor.execute(editor._create_unique_sql(model, [field], constraint_name))
            self.assertIn(
                expected_constraint_name, self.get_constraints(model._meta.db_table)
            )
            editor.alter_field(model, get_field(unique=True), field, strict=True)
            self.assertNotIn(
                expected_constraint_name, self.get_constraints(model._meta.db_table)
            )

            if editor.sql_create_fk and connection.features.can_introspect_foreign_keys:
                constraint_name = "CamelCaseFKConstraint"
                expected_constraint_name = identifier_converter(constraint_name)
                editor.execute(
                    editor.sql_create_fk
                    % {
                        "table": editor.quote_name(table),
                        "name": editor.quote_name(constraint_name),
                        "column": editor.quote_name(column),
                        "to_table": editor.quote_name(table),
                        "to_column": editor.quote_name(model._meta.auto_field.column),
                        "deferrable": connection.ops.deferrable_sql(),
                    }
                )
                self.assertIn(
                    expected_constraint_name, self.get_constraints(model._meta.db_table)
                )
                editor.alter_field(
                    model,
                    get_field(Author, CASCADE, field_class=ForeignKey),
                    field,
                    strict=True,
                )
                self.assertNotIn(
                    expected_constraint_name, self.get_constraints(model._meta.db_table)
                )

    def test_add_field_use_effective_default(self):
        """
        #23987 - effective_default() should be used as the field default when
        adding a new field.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure there's no surname field
        columns = self.column_classes(Author)
        self.assertNotIn("surname", columns)
        # Create a row
        Author.objects.create(name="Anonymous1")
        # Add new CharField to ensure default will be used from effective_default
        new_field = CharField(max_length=15, blank=True)
        new_field.set_attributes_from_name("surname")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        # Ensure field was added with the right default
        with connection.cursor() as cursor:
            cursor.execute("SELECT surname FROM schema_author;")
            item = cursor.fetchall()[0]
            self.assertEqual(
                item[0],
                None if connection.features.interprets_empty_strings_as_nulls else "",
            )

    def test_add_field_default_dropped(self):
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure there's no surname field
        columns = self.column_classes(Author)
        self.assertNotIn("surname", columns)
        # Create a row
        Author.objects.create(name="Anonymous1")
        # Add new CharField with a default
        new_field = CharField(max_length=15, blank=True, default="surname default")
        new_field.set_attributes_from_name("surname")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        # Ensure field was added with the right default
        with connection.cursor() as cursor:
            cursor.execute("SELECT surname FROM schema_author;")
            item = cursor.fetchall()[0]
            self.assertEqual(item[0], "surname default")
            # And that the default is no longer set in the database.
            field = next(
                f
                for f in connection.introspection.get_table_description(
                    cursor, "schema_author"
                )
                if f.name == "surname"
            )
            if connection.features.can_introspect_default:
                self.assertIsNone(field.default)

    def test_add_field_default_nullable(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Add new nullable CharField with a default.
        new_field = CharField(max_length=15, blank=True, null=True, default="surname")
        new_field.set_attributes_from_name("surname")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        Author.objects.create(name="Anonymous1")
        with connection.cursor() as cursor:
            cursor.execute("SELECT surname FROM schema_author;")
            item = cursor.fetchall()[0]
            self.assertIsNone(item[0])
            field = next(
                f
                for f in connection.introspection.get_table_description(
                    cursor,
                    "schema_author",
                )
                if f.name == "surname"
            )
            # Field is still nullable.
            self.assertTrue(field.null_ok)
            # The database default is no longer set.
            if connection.features.can_introspect_default:
                self.assertIn(field.default, ["NULL", None])

    def test_add_textfield_default_nullable(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Add new nullable TextField with a default.
        new_field = TextField(blank=True, null=True, default="text")
        new_field.set_attributes_from_name("description")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        Author.objects.create(name="Anonymous1")
        with connection.cursor() as cursor:
            cursor.execute("SELECT description FROM schema_author;")
            item = cursor.fetchall()[0]
            self.assertIsNone(item[0])
            field = next(
                f
                for f in connection.introspection.get_table_description(
                    cursor,
                    "schema_author",
                )
                if f.name == "description"
            )
            # Field is still nullable.
            self.assertTrue(field.null_ok)
            # The database default is no longer set.
            if connection.features.can_introspect_default:
                self.assertIn(field.default, ["NULL", None])

    def test_alter_field_default_dropped(self):
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Create a row
        Author.objects.create(name="Anonymous1")
        self.assertIsNone(Author.objects.get().height)
        old_field = Author._meta.get_field("height")
        # The default from the new field is used in updating existing rows.
        new_field = IntegerField(blank=True, default=42)
        new_field.set_attributes_from_name("height")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(Author.objects.get().height, 42)
        # The database default should be removed.
        with connection.cursor() as cursor:
            field = next(
                f
                for f in connection.introspection.get_table_description(
                    cursor, "schema_author"
                )
                if f.name == "height"
            )
            if connection.features.can_introspect_default:
                self.assertIsNone(field.default)

    def test_alter_field_default_doesnt_perform_queries(self):
        """
        No queries are performed if a field default changes and the field's
        not changing from null to non-null.
        """
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithDefaultHeight)
        old_field = AuthorWithDefaultHeight._meta.get_field("height")
        new_default = old_field.default * 2
        new_field = PositiveIntegerField(null=True, blank=True, default=new_default)
        new_field.set_attributes_from_name("height")
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            editor.alter_field(
                AuthorWithDefaultHeight, old_field, new_field, strict=True
            )

    @skipUnlessDBFeature("supports_foreign_keys")
    def test_alter_field_fk_attributes_noop(self):
        """
        No queries are performed when changing field attributes that don't
        affect the schema.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        old_field = Book._meta.get_field("author")
        new_field = ForeignKey(
            Author,
            blank=True,
            editable=False,
            error_messages={"invalid": "error message"},
            help_text="help text",
            limit_choices_to={"limit": "choice"},
            on_delete=PROTECT,
            related_name="related_name",
            related_query_name="related_query_name",
            validators=[lambda x: x],
            verbose_name="verbose name",
        )
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            editor.alter_field(Book, old_field, new_field, strict=True)
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            editor.alter_field(Book, new_field, old_field, strict=True)

    def test_alter_field_choices_noop(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        old_field = Author._meta.get_field("name")
        new_field = CharField(
            choices=(("Jane", "Jane"), ("Joe", "Joe")),
            max_length=255,
        )
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            editor.alter_field(Author, old_field, new_field, strict=True)
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            editor.alter_field(Author, new_field, old_field, strict=True)

    def test_add_textfield_unhashable_default(self):
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Create a row
        Author.objects.create(name="Anonymous1")
        # Create a field that has an unhashable default
        new_field = TextField(default={})
        new_field.set_attributes_from_name("info")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_add_indexed_charfield(self):
        """
        Tests the creation of an indexed CharField in a PostgreSQL database.

        This test case verifies that a CharField with `db_index=True` is correctly created
        in the database, along with the associated index constraints.

        The test creates an Author model, adds an indexed CharField to it, and then checks
        that the expected index constraints are present in the database. The constraints
        checked include the primary index and the 'like' index created by the database
        for efficient querying.

        The test is skipped unless the database vendor is PostgreSQL, as the index
        constraints created may vary across different database systems.
        """
        field = CharField(max_length=255, db_index=True)
        field.set_attributes_from_name("nom_de_plume")
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.add_field(Author, field)
        # Should create two indexes; one for like operator.
        self.assertEqual(
            self.get_constraints_for_column(Author, "nom_de_plume"),
            [
                "schema_author_nom_de_plume_7570a851",
                "schema_author_nom_de_plume_7570a851_like",
            ],
        )

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_add_unique_charfield(self):
        """

        Tests the addition of a unique CharField to a model in PostgreSQL.

        This test case ensures that a CharField with the unique constraint can be successfully added to a model.
        It verifies that the constraints are correctly created after adding the field to the model.

        The test covers the following scenarios:
        - Creation of a CharField with a specified max length and unique constraint.
        - Adding the field to a model using the schema editor.
        - Verification of the resulting constraints on the column in the database.

        """
        field = CharField(max_length=255, unique=True)
        field.set_attributes_from_name("nom_de_plume")
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.add_field(Author, field)
        # Should create two indexes; one for like operator.
        self.assertEqual(
            self.get_constraints_for_column(Author, "nom_de_plume"),
            [
                "schema_author_nom_de_plume_7570a851_like",
                "schema_author_nom_de_plume_key",
            ],
        )

    @skipUnlessDBFeature("supports_comments")
    def test_add_db_comment_charfield(self):
        """
        Tests the ability to add a custom database comment to a CharField model field.

        This test case verifies that a comment specified using the `db_comment` parameter
        is correctly applied to the corresponding database column when the model is created.

        It covers the process of creating a model with a CharField, setting its attributes,
        and then checking the comment on the resulting database column to ensure it matches
        the expected custom comment.

        The test requires a database that supports comments to be successful.
        """
        comment = "Custom comment"
        field = CharField(max_length=255, db_comment=comment)
        field.set_attributes_from_name("name_with_comment")
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.add_field(Author, field)
        self.assertEqual(
            self.get_column_comment(Author._meta.db_table, "name_with_comment"),
            comment,
        )

    @skipUnlessDBFeature("supports_comments")
    def test_add_db_comment_and_default_charfield(self):
        """

        Tests the addition of a database comment and a default value to a CharField.

        This test case verifies that a comment added to a CharField is correctly stored in the database
        and that the default value is correctly applied when creating a new instance of the model.
        The test creates a new model, adds an instance to the database, then adds a new CharField to the model
        with a custom comment and default value, and checks that the comment is stored and the default value is used.

        """
        comment = "Custom comment with default"
        field = CharField(max_length=255, default="Joe Doe", db_comment=comment)
        field.set_attributes_from_name("name_with_comment_default")
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            Author.objects.create(name="Before adding a new field")
            editor.add_field(Author, field)

        self.assertEqual(
            self.get_column_comment(Author._meta.db_table, "name_with_comment_default"),
            comment,
        )
        with connection.cursor() as cursor:
            cursor.execute(
                f"SELECT name_with_comment_default FROM {Author._meta.db_table};"
            )
            for row in cursor.fetchall():
                self.assertEqual(row[0], "Joe Doe")

    @skipUnlessDBFeature("supports_comments")
    def test_alter_db_comment(self):
        """
        Tests the ability to alter database comments on a model field.

        This test creates a model, alters the comment on one of its fields, and verifies that the changes are correctly applied to the database.
        It checks for both setting a new comment and clearing an existing comment.

        The test covers the following scenarios:

        * Setting a custom comment on a field
        * Updating an existing comment on a field
        * Clearing a comment on a field

        It ensures that after each alteration, the database comment matches the expected value or is cleared as intended.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Add comment.
        old_field = Author._meta.get_field("name")
        new_field = CharField(max_length=255, db_comment="Custom comment")
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_column_comment(Author._meta.db_table, "name"),
            "Custom comment",
        )
        # Alter comment.
        old_field = new_field
        new_field = CharField(max_length=255, db_comment="New custom comment")
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_column_comment(Author._meta.db_table, "name"),
            "New custom comment",
        )
        # Remove comment.
        old_field = new_field
        new_field = CharField(max_length=255)
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertIn(
            self.get_column_comment(Author._meta.db_table, "name"),
            [None, ""],
        )

    @skipUnlessDBFeature("supports_comments", "supports_foreign_keys")
    def test_alter_db_comment_foreign_key(self):
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)

        comment = "FK custom comment"
        old_field = Book._meta.get_field("author")
        new_field = ForeignKey(Author, CASCADE, db_comment=comment)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(Book, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_column_comment(Book._meta.db_table, "author_id"),
            comment,
        )

    @skipUnlessDBFeature("supports_comments")
    def test_alter_field_type_preserve_comment(self):
        """
        Tests that the comment on a database field is preserved when its type is altered using the alter_field method of a schema editor.

        This test specifically checks that when altering a field from one type to another, the comment associated with the field remains unchanged, ensuring that the field's metadata is preserved through the alteration process.

        The test covers two alteration scenarios to verify that comments are preserved: altering a field from one character field type to another, and altering in the reverse direction, both while ensuring that the comment remains intact.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)

        comment = "This is the name."
        old_field = Author._meta.get_field("name")
        new_field = CharField(max_length=255, db_comment=comment)
        new_field.set_attributes_from_name("name")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_column_comment(Author._meta.db_table, "name"),
            comment,
        )
        # Changing a field type should preserve the comment.
        old_field = new_field
        new_field = CharField(max_length=511, db_comment=comment)
        new_field.set_attributes_from_name("name")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, old_field, strict=True)
        # Comment is preserved.
        self.assertEqual(
            self.get_column_comment(Author._meta.db_table, "name"),
            comment,
        )

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_comments")
    def test_db_comment_table(self):
        """

        Tests the database comment functionality for a table in the database.

        This test ensures that the database comment can be successfully set
        and altered for a table, and that the changes are reflected correctly.

        The test covers the following scenarios:
        - Creating a table with a custom comment.
        - Altering the comment on an existing table.
        - Removing the comment from an existing table.

        The test verifies that the table comment is correctly set after each operation
        by retrieving and comparing the comment with the expected value.

        """
        class ModelWithDbTableComment(Model):
            class Meta:
                app_label = "schema"
                db_table_comment = "Custom table comment"

        with connection.schema_editor() as editor:
            editor.create_model(ModelWithDbTableComment)
        self.isolated_local_models = [ModelWithDbTableComment]
        self.assertEqual(
            self.get_table_comment(ModelWithDbTableComment._meta.db_table),
            "Custom table comment",
        )
        # Alter table comment.
        old_db_table_comment = ModelWithDbTableComment._meta.db_table_comment
        with connection.schema_editor() as editor:
            editor.alter_db_table_comment(
                ModelWithDbTableComment, old_db_table_comment, "New table comment"
            )
        self.assertEqual(
            self.get_table_comment(ModelWithDbTableComment._meta.db_table),
            "New table comment",
        )
        # Remove table comment.
        old_db_table_comment = ModelWithDbTableComment._meta.db_table_comment
        with connection.schema_editor() as editor:
            editor.alter_db_table_comment(
                ModelWithDbTableComment, old_db_table_comment, None
            )
        self.assertIn(
            self.get_table_comment(ModelWithDbTableComment._meta.db_table),
            [None, ""],
        )

    @isolate_apps("schema")
    @skipIfDBFeature("supports_comments")
    def test_db_comment_table_unsupported(self):
        class ModelWithDbTableComment(Model):
            class Meta:
                app_label = "schema"
                db_table_comment = "Custom table comment"

        # Table comments are ignored on databases that don't support them.
        with connection.schema_editor() as editor, self.assertNumQueries(1):
            editor.create_model(ModelWithDbTableComment)
        self.isolated_local_models = [ModelWithDbTableComment]
        with connection.schema_editor() as editor, self.assertNumQueries(0):
            editor.alter_db_table_comment(
                ModelWithDbTableComment, "Custom table comment", "New table comment"
            )

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_comments", "supports_foreign_keys")
    def test_db_comments_from_abstract_model(self):
        """
        Tests that comments defined in an abstract model are correctly applied to the database.

        This test case verifies that both column and table comments are properly created 
        when an abstract model with comment definitions is used as a base for a concrete model.

        It checks that the comments are correctly applied to the database when the model is created,
        by comparing the expected comments with the actual comments retrieved from the database.
        """
        class AbstractModelWithDbComments(Model):
            name = CharField(
                max_length=255, db_comment="Custom comment", null=True, blank=True
            )

            class Meta:
                app_label = "schema"
                abstract = True
                db_table_comment = "Custom table comment"

        class ModelWithDbComments(AbstractModelWithDbComments):
            pass

        with connection.schema_editor() as editor:
            editor.create_model(ModelWithDbComments)
        self.isolated_local_models = [ModelWithDbComments]

        self.assertEqual(
            self.get_column_comment(ModelWithDbComments._meta.db_table, "name"),
            "Custom comment",
        )
        self.assertEqual(
            self.get_table_comment(ModelWithDbComments._meta.db_table),
            "Custom table comment",
        )

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_field_add_index_to_charfield(self):
        # Create the table and verify no initial indexes.
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        self.assertEqual(self.get_constraints_for_column(Author, "name"), [])
        # Alter to add db_index=True and create 2 indexes.
        old_field = Author._meta.get_field("name")
        new_field = CharField(max_length=255, db_index=True)
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(Author, "name"),
            ["schema_author_name_1fbc5617", "schema_author_name_1fbc5617_like"],
        )
        # Remove db_index=True to drop both indexes.
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, old_field, strict=True)
        self.assertEqual(self.get_constraints_for_column(Author, "name"), [])

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_field_add_unique_to_charfield(self):
        # Create the table and verify no initial indexes.
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        self.assertEqual(self.get_constraints_for_column(Author, "name"), [])
        # Alter to add unique=True and create 2 indexes.
        old_field = Author._meta.get_field("name")
        new_field = CharField(max_length=255, unique=True)
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(Author, "name"),
            ["schema_author_name_1fbc5617_like", "schema_author_name_1fbc5617_uniq"],
        )
        # Remove unique=True to drop both indexes.
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, old_field, strict=True)
        self.assertEqual(self.get_constraints_for_column(Author, "name"), [])

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_field_add_index_to_textfield(self):
        # Create the table and verify no initial indexes.
        with connection.schema_editor() as editor:
            editor.create_model(Note)
        self.assertEqual(self.get_constraints_for_column(Note, "info"), [])
        # Alter to add db_index=True and create 2 indexes.
        old_field = Note._meta.get_field("info")
        new_field = TextField(db_index=True)
        new_field.set_attributes_from_name("info")
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(Note, "info"),
            ["schema_note_info_4b0ea695", "schema_note_info_4b0ea695_like"],
        )
        # Remove db_index=True to drop both indexes.
        with connection.schema_editor() as editor:
            editor.alter_field(Note, new_field, old_field, strict=True)
        self.assertEqual(self.get_constraints_for_column(Note, "info"), [])

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_field_add_unique_to_charfield_with_db_index(self):
        # Create the table and verify initial indexes.
        """
        Tests the behavior of altering a CharField to add a unique constraint with a database index in PostgreSQL.

        This test first creates a model (BookWithoutAuthor) and verifies its initial constraints.
        It then alters the 'title' field to add a unique constraint with a database index,
        verifying that the expected constraints are applied to the column.
        Finally, it re-alters the field to remove the unique constraint,
        checking that the constraints are correctly updated.

        This test is specific to PostgreSQL and is skipped for other databases.
        """
        with connection.schema_editor() as editor:
            editor.create_model(BookWithoutAuthor)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"),
            ["schema_book_title_2dfb2dff", "schema_book_title_2dfb2dff_like"],
        )
        # Alter to add unique=True (should replace the index)
        old_field = BookWithoutAuthor._meta.get_field("title")
        new_field = CharField(max_length=100, db_index=True, unique=True)
        new_field.set_attributes_from_name("title")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithoutAuthor, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"),
            ["schema_book_title_2dfb2dff_like", "schema_book_title_2dfb2dff_uniq"],
        )
        # Alter to remove unique=True (should drop unique index)
        new_field2 = CharField(max_length=100, db_index=True)
        new_field2.set_attributes_from_name("title")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithoutAuthor, new_field, new_field2, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"),
            ["schema_book_title_2dfb2dff", "schema_book_title_2dfb2dff_like"],
        )

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_field_remove_unique_and_db_index_from_charfield(self):
        # Create the table and verify initial indexes.
        """
        Tests that altering a CharField removes the unique constraint and database index when they are no longer specified.

        This test creates a model with a CharField that has a unique constraint and database index, 
        then alters the field to remove these constraints and verifies the database state afterwards.

        It tests the PostgreSQL backend specifically, due to its unique handling of constraints and indexes.
        The test scenario involves two alterations: the first adds a unique constraint and database index,
        and the second removes them, ensuring that the resulting database state is correct in both cases.

        """
        with connection.schema_editor() as editor:
            editor.create_model(BookWithoutAuthor)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"),
            ["schema_book_title_2dfb2dff", "schema_book_title_2dfb2dff_like"],
        )
        # Alter to add unique=True (should replace the index)
        old_field = BookWithoutAuthor._meta.get_field("title")
        new_field = CharField(max_length=100, db_index=True, unique=True)
        new_field.set_attributes_from_name("title")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithoutAuthor, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"),
            ["schema_book_title_2dfb2dff_like", "schema_book_title_2dfb2dff_uniq"],
        )
        # Alter to remove both unique=True and db_index=True (should drop all indexes)
        new_field2 = CharField(max_length=100)
        new_field2.set_attributes_from_name("title")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithoutAuthor, new_field, new_field2, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"), []
        )

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_field_swap_unique_and_db_index_with_charfield(self):
        # Create the table and verify initial indexes.
        """
        Tests the alteration of a field in a model by swapping between unique constraints and database indexes with a CharField.

        This test case covers two scenarios: 
        1. Replacing an existing field with a CharField that has a unique constraint, 
           verifying that the original database index is removed and a new unique constraint is added.
        2. Replacing the unique CharField with another CharField that has a database index, 
           verifying that the unique constraint is removed and the original database index is restored.

        The test is specific to PostgreSQL and requires a database connection to execute.

        The test uses the `BookWithoutAuthor` model and alters the 'title' field to test the field alteration scenarios.

        """
        with connection.schema_editor() as editor:
            editor.create_model(BookWithoutAuthor)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"),
            ["schema_book_title_2dfb2dff", "schema_book_title_2dfb2dff_like"],
        )
        # Alter to set unique=True and remove db_index=True (should replace the index)
        old_field = BookWithoutAuthor._meta.get_field("title")
        new_field = CharField(max_length=100, unique=True)
        new_field.set_attributes_from_name("title")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithoutAuthor, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"),
            ["schema_book_title_2dfb2dff_like", "schema_book_title_2dfb2dff_uniq"],
        )
        # Alter to set db_index=True and remove unique=True (should restore index)
        new_field2 = CharField(max_length=100, db_index=True)
        new_field2.set_attributes_from_name("title")
        with connection.schema_editor() as editor:
            editor.alter_field(BookWithoutAuthor, new_field, new_field2, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(BookWithoutAuthor, "title"),
            ["schema_book_title_2dfb2dff", "schema_book_title_2dfb2dff_like"],
        )

    @unittest.skipUnless(connection.vendor == "postgresql", "PostgreSQL specific")
    def test_alter_field_add_db_index_to_charfield_with_unique(self):
        # Create the table and verify initial indexes.
        """

        Tests the behavior of adding a database index to a CharField with a unique constraint.

        Verifies that when a CharField is altered to include a db_index and unique constraints,
        the resulting database constraints are correctly created and updated.
        The test case covers two scenarios: 
        1. Adding db_index to an existing unique CharField.
        2. Removing db_index from a CharField with both db_index and unique constraints.

        This test is specific to PostgreSQL databases and is skipped for other vendors.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
        self.assertEqual(
            self.get_constraints_for_column(Tag, "slug"),
            ["schema_tag_slug_2c418ba3_like", "schema_tag_slug_key"],
        )
        # Alter to add db_index=True
        old_field = Tag._meta.get_field("slug")
        new_field = SlugField(db_index=True, unique=True)
        new_field.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_field(Tag, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(Tag, "slug"),
            ["schema_tag_slug_2c418ba3_like", "schema_tag_slug_key"],
        )
        # Alter to remove db_index=True
        new_field2 = SlugField(unique=True)
        new_field2.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_field(Tag, new_field, new_field2, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(Tag, "slug"),
            ["schema_tag_slug_2c418ba3_like", "schema_tag_slug_key"],
        )

    def test_alter_field_add_index_to_integerfield(self):
        # Create the table and verify no initial indexes.
        """

        Tests the alteration of a field to add an index to an IntegerField.

        Verifies that adding an index to an existing IntegerField using the
        alter_field method creates the expected index constraint, and that
        reverting the change removes the index constraint.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        self.assertEqual(self.get_constraints_for_column(Author, "weight"), [])

        # Alter to add db_index=True and create index.
        old_field = Author._meta.get_field("weight")
        new_field = IntegerField(null=True, db_index=True)
        new_field.set_attributes_from_name("weight")
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_constraints_for_column(Author, "weight"),
            ["schema_author_weight_587740f9"],
        )

        # Remove db_index=True to drop index.
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, old_field, strict=True)
        self.assertEqual(self.get_constraints_for_column(Author, "weight"), [])

    def test_alter_pk_with_self_referential_field(self):
        """
        Changing the primary key field name of a model with a self-referential
        foreign key (#26384).
        """
        with connection.schema_editor() as editor:
            editor.create_model(Node)
        old_field = Node._meta.get_field("node_id")
        new_field = AutoField(primary_key=True)
        new_field.set_attributes_from_name("id")
        with connection.schema_editor() as editor:
            editor.alter_field(Node, old_field, new_field, strict=True)
        self.assertForeignKeyExists(Node, "parent_id", Node._meta.db_table)

    @mock.patch("django.db.backends.base.schema.datetime")
    @mock.patch("django.db.backends.base.schema.timezone")
    def test_add_datefield_and_datetimefield_use_effective_default(
        self, mocked_datetime, mocked_tz
    ):
        """
        effective_default() should be used for DateField, DateTimeField, and
        TimeField if auto_now or auto_now_add is set (#25005).
        """
        now = datetime.datetime(month=1, day=1, year=2000, hour=1, minute=1)
        now_tz = datetime.datetime(
            month=1, day=1, year=2000, hour=1, minute=1, tzinfo=datetime.timezone.utc
        )
        mocked_datetime.now = mock.MagicMock(return_value=now)
        mocked_tz.now = mock.MagicMock(return_value=now_tz)
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Check auto_now/auto_now_add attributes are not defined
        columns = self.column_classes(Author)
        self.assertNotIn("dob_auto_now", columns)
        self.assertNotIn("dob_auto_now_add", columns)
        self.assertNotIn("dtob_auto_now", columns)
        self.assertNotIn("dtob_auto_now_add", columns)
        self.assertNotIn("tob_auto_now", columns)
        self.assertNotIn("tob_auto_now_add", columns)
        # Create a row
        Author.objects.create(name="Anonymous1")
        # Ensure fields were added with the correct defaults
        dob_auto_now = DateField(auto_now=True)
        dob_auto_now.set_attributes_from_name("dob_auto_now")
        self.check_added_field_default(
            editor,
            Author,
            dob_auto_now,
            "dob_auto_now",
            now.date(),
            cast_function=lambda x: x.date(),
        )
        dob_auto_now_add = DateField(auto_now_add=True)
        dob_auto_now_add.set_attributes_from_name("dob_auto_now_add")
        self.check_added_field_default(
            editor,
            Author,
            dob_auto_now_add,
            "dob_auto_now_add",
            now.date(),
            cast_function=lambda x: x.date(),
        )
        dtob_auto_now = DateTimeField(auto_now=True)
        dtob_auto_now.set_attributes_from_name("dtob_auto_now")
        self.check_added_field_default(
            editor,
            Author,
            dtob_auto_now,
            "dtob_auto_now",
            now,
        )
        dt_tm_of_birth_auto_now_add = DateTimeField(auto_now_add=True)
        dt_tm_of_birth_auto_now_add.set_attributes_from_name("dtob_auto_now_add")
        self.check_added_field_default(
            editor,
            Author,
            dt_tm_of_birth_auto_now_add,
            "dtob_auto_now_add",
            now,
        )
        tob_auto_now = TimeField(auto_now=True)
        tob_auto_now.set_attributes_from_name("tob_auto_now")
        self.check_added_field_default(
            editor,
            Author,
            tob_auto_now,
            "tob_auto_now",
            now.time(),
            cast_function=lambda x: x.time(),
        )
        tob_auto_now_add = TimeField(auto_now_add=True)
        tob_auto_now_add.set_attributes_from_name("tob_auto_now_add")
        self.check_added_field_default(
            editor,
            Author,
            tob_auto_now_add,
            "tob_auto_now_add",
            now.time(),
            cast_function=lambda x: x.time(),
        )

    def test_namespaced_db_table_create_index_name(self):
        """
        Table names are stripped of their namespace/schema before being used to
        generate index names.
        """
        with connection.schema_editor() as editor:
            max_name_length = connection.ops.max_name_length() or 200
            namespace = "n" * max_name_length
            table_name = "t" * max_name_length
            namespaced_table_name = '"%s"."%s"' % (namespace, table_name)
            self.assertEqual(
                editor._create_index_name(table_name, []),
                editor._create_index_name(namespaced_table_name, []),
            )

    @unittest.skipUnless(
        connection.vendor == "oracle", "Oracle specific db_table syntax"
    )
    def test_creation_with_db_table_double_quotes(self):
        """

        Tests the creation of models using a database table with double quotes, specifically for Oracle databases.

        This test case checks that models can be created and used correctly when their database tables are defined with double quotes,
        which is a specific requirement for Oracle databases. It verifies that the database table names are correctly generated and
        that relationships between models (e.g., many-to-many) are established as expected. The test case also ensures that data can
        be successfully inserted into these models and retrieved correctly.

        """
        oracle_user = connection.creation._test_database_user()

        class Student(Model):
            name = CharField(max_length=30)

            class Meta:
                app_label = "schema"
                apps = new_apps
                db_table = '"%s"."DJANGO_STUDENT_TABLE"' % oracle_user

        class Document(Model):
            name = CharField(max_length=30)
            students = ManyToManyField(Student)

            class Meta:
                app_label = "schema"
                apps = new_apps
                db_table = '"%s"."DJANGO_DOCUMENT_TABLE"' % oracle_user

        self.isolated_local_models = [Student, Document]

        with connection.schema_editor() as editor:
            editor.create_model(Student)
            editor.create_model(Document)

        doc = Document.objects.create(name="Test Name")
        student = Student.objects.create(name="Some man")
        doc.students.add(student)

    @isolate_apps("schema")
    @unittest.skipUnless(
        connection.vendor == "postgresql", "PostgreSQL specific db_table syntax."
    )
    def test_namespaced_db_table_foreign_key_reference(self):
        """

        Tests the creation of a namespaced db_table foreign key reference in PostgreSQL.

        This test case ensures that Django's ORM can correctly create a foreign key
        reference to a model in a different schema, using the PostgreSQL-specific
        db_table syntax.

        It creates a schema, defines two models (Author and Book) in that schema,
        and then creates a foreign key relationship between them. The test covers
        the scenario where the db_table name is fully qualified with the schema name.

        The test is skipped if the database vendor is not PostgreSQL, as the
        db_table syntax used is specific to PostgreSQL.

        """
        with connection.cursor() as cursor:
            cursor.execute("CREATE SCHEMA django_schema_tests")

        def delete_schema():
            with connection.cursor() as cursor:
                cursor.execute("DROP SCHEMA django_schema_tests CASCADE")

        self.addCleanup(delete_schema)

        class Author(Model):
            class Meta:
                app_label = "schema"

        class Book(Model):
            class Meta:
                app_label = "schema"
                db_table = '"django_schema_tests"."schema_book"'

        author = ForeignKey(Author, CASCADE)
        author.set_attributes_from_name("author")

        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
            editor.add_field(Book, author)

    def test_rename_table_renames_deferred_sql_references(self):
        """
        Tests that renaming a table also updates any deferred SQL references to the original table name.

        This test case creates models (Author and Book), renames their associated database tables, 
        and then verifies that any deferred SQL statements are updated to reference the new table names.
        It ensures that the rename operation correctly handles dependent SQL statements, preventing any potential naming conflicts or errors.

        The test validates the correct functionality of the database schema editor when performing table rename operations,
        specifically checking that the deferred SQL statements no longer reference the original table names after the rename operation.

        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
            editor.alter_db_table(Author, "schema_author", "schema_renamed_author")
            editor.alter_db_table(Author, "schema_book", "schema_renamed_book")
            try:
                self.assertGreater(len(editor.deferred_sql), 0)
                for statement in editor.deferred_sql:
                    self.assertIs(statement.references_table("schema_author"), False)
                    self.assertIs(statement.references_table("schema_book"), False)
            finally:
                editor.alter_db_table(Author, "schema_renamed_author", "schema_author")
                editor.alter_db_table(Author, "schema_renamed_book", "schema_book")

    def test_rename_column_renames_deferred_sql_references(self):
        """
        Tests whether renaming a column also renames its references in deferred SQL statements.

        This test case ensures that when a column is renamed, all associated SQL statements 
        that reference the original column name are updated to use the new column name.
        It checks for the presence of deferred SQL statements and verifies that they no 
        longer reference the original column names after the rename operation.

        The test covers renaming of both regular columns and foreign key fields, 
        ensuring that the renaming process correctly updates all related SQL statements.
        """
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
            old_title = Book._meta.get_field("title")
            new_title = CharField(max_length=100, db_index=True)
            new_title.set_attributes_from_name("renamed_title")
            editor.alter_field(Book, old_title, new_title)
            old_author = Book._meta.get_field("author")
            new_author = ForeignKey(Author, CASCADE)
            new_author.set_attributes_from_name("renamed_author")
            editor.alter_field(Book, old_author, new_author)
            self.assertGreater(len(editor.deferred_sql), 0)
            for statement in editor.deferred_sql:
                self.assertIs(statement.references_column("book", "title"), False)
                self.assertIs(statement.references_column("book", "author_id"), False)

    @isolate_apps("schema")
    def test_referenced_field_without_constraint_rename_inside_atomic_block(self):
        """
        Foreign keys without database level constraint don't prevent the field
        they reference from being renamed in an atomic block.
        """

        class Foo(Model):
            field = CharField(max_length=255, unique=True)

            class Meta:
                app_label = "schema"

        class Bar(Model):
            foo = ForeignKey(Foo, CASCADE, to_field="field", db_constraint=False)

            class Meta:
                app_label = "schema"

        self.isolated_local_models = [Foo, Bar]
        with connection.schema_editor() as editor:
            editor.create_model(Foo)
            editor.create_model(Bar)

        new_field = CharField(max_length=255, unique=True)
        new_field.set_attributes_from_name("renamed")
        with connection.schema_editor(atomic=True) as editor:
            editor.alter_field(Foo, Foo._meta.get_field("field"), new_field)

    @isolate_apps("schema")
    def test_referenced_table_without_constraint_rename_inside_atomic_block(self):
        """
        Foreign keys without database level constraint don't prevent the table
        they reference from being renamed in an atomic block.
        """

        class Foo(Model):
            field = CharField(max_length=255, unique=True)

            class Meta:
                app_label = "schema"

        class Bar(Model):
            foo = ForeignKey(Foo, CASCADE, to_field="field", db_constraint=False)

            class Meta:
                app_label = "schema"

        self.isolated_local_models = [Foo, Bar]
        with connection.schema_editor() as editor:
            editor.create_model(Foo)
            editor.create_model(Bar)

        new_field = CharField(max_length=255, unique=True)
        new_field.set_attributes_from_name("renamed")
        with connection.schema_editor(atomic=True) as editor:
            editor.alter_db_table(Foo, Foo._meta.db_table, "renamed_table")
        Foo._meta.db_table = "renamed_table"

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_collation_on_charfield")
    def test_db_collation_charfield(self):
        """

        Tests creation of a CharField model with a non-default database collation.

        Verifies that the specified collation is correctly applied to the CharField
        when the model is created in the database.

        The test checks for support of language collations on CharField and skips if
        this feature is not available. It creates a test model with a CharField that
        uses a non-default collation and then checks that the correct collation is
        applied to the column in the database.

        """
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("Language collations are not supported.")

        class Foo(Model):
            field = CharField(max_length=255, db_collation=collation)

            class Meta:
                app_label = "schema"

        self.isolated_local_models = [Foo]
        with connection.schema_editor() as editor:
            editor.create_model(Foo)

        self.assertEqual(
            self.get_column_collation(Foo._meta.db_table, "field"),
            collation,
        )

    @isolate_apps("schema")
    @skipUnlessDBFeature("supports_collation_on_textfield")
    def test_db_collation_textfield(self):
        """
        Tests that a TextField with a non-default collation is correctly created in the database.

            This test checks the support of collation on text fields in the database
            by creating a model with a TextField that uses a non-default collation.
            It then verifies that the column collation in the database matches the
            specified collation.

            The test skips if the database does not support language collations.

        """
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("Language collations are not supported.")

        class Foo(Model):
            field = TextField(db_collation=collation)

            class Meta:
                app_label = "schema"

        self.isolated_local_models = [Foo]
        with connection.schema_editor() as editor:
            editor.create_model(Foo)

        self.assertEqual(
            self.get_column_collation(Foo._meta.db_table, "field"),
            collation,
        )

    @skipUnlessDBFeature("supports_collation_on_charfield")
    def test_add_field_db_collation(self):
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("Language collations are not supported.")

        with connection.schema_editor() as editor:
            editor.create_model(Author)

        new_field = CharField(max_length=255, db_collation=collation)
        new_field.set_attributes_from_name("alias")
        with connection.schema_editor() as editor:
            editor.add_field(Author, new_field)
        columns = self.column_classes(Author)
        self.assertEqual(
            columns["alias"][0],
            connection.features.introspected_field_types["CharField"],
        )
        self.assertEqual(columns["alias"][1][8], collation)

    @skipUnlessDBFeature("supports_collation_on_charfield")
    def test_alter_field_db_collation(self):
        """

        Test the alteration of a model field's database collation in a CharField.

        This test ensures that changing the collation of a CharField via the alter_field
        method in a schema editor successfully updates the database schema, and that
        the change can be reverted.

        The test creates an Author model with a 'name' field, alters the field's
        collation to a non-default collation, and then verifies that the collation
        has been updated in the database. The test then reverts the collation change,
        ensuring that the field returns to its original state.

        """
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("Language collations are not supported.")

        with connection.schema_editor() as editor:
            editor.create_model(Author)

        old_field = Author._meta.get_field("name")
        new_field = CharField(max_length=255, db_collation=collation)
        new_field.set_attributes_from_name("name")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_column_collation(Author._meta.db_table, "name"),
            collation,
        )
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, old_field, strict=True)
        self.assertIsNone(self.get_column_collation(Author._meta.db_table, "name"))

    @skipUnlessDBFeature("supports_collation_on_charfield")
    def test_alter_field_type_preserve_db_collation(self):
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("Language collations are not supported.")

        with connection.schema_editor() as editor:
            editor.create_model(Author)

        old_field = Author._meta.get_field("name")
        new_field = CharField(max_length=255, db_collation=collation)
        new_field.set_attributes_from_name("name")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, old_field, new_field, strict=True)
        self.assertEqual(
            self.get_column_collation(Author._meta.db_table, "name"),
            collation,
        )
        # Changing a field type should preserve the collation.
        old_field = new_field
        new_field = CharField(max_length=511, db_collation=collation)
        new_field.set_attributes_from_name("name")
        new_field.model = Author
        with connection.schema_editor() as editor:
            editor.alter_field(Author, new_field, old_field, strict=True)
        # Collation is preserved.
        self.assertEqual(
            self.get_column_collation(Author._meta.db_table, "name"),
            collation,
        )

    @skipUnlessDBFeature("supports_collation_on_charfield")
    def test_alter_primary_key_db_collation(self):
        """

        Tests altering the primary key of a model to use a non-default database collation.

        This test ensures that the primary key can be changed to use a different collation, 
        and that the change is persisted in the database schema. It also verifies that 
        reverting the change successfully restores the original collation.

        The test uses a sample model `Thing` and modifies its primary key field `when` 
        to use a non-default collation. It checks that the primary key is updated 
        correctly and that the collation is applied as expected. Finally, it reverts 
        the change to ensure that the original state is restored.

        """
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("Language collations are not supported.")

        with connection.schema_editor() as editor:
            editor.create_model(Thing)

        old_field = Thing._meta.get_field("when")
        new_field = CharField(max_length=1, db_collation=collation, primary_key=True)
        new_field.set_attributes_from_name("when")
        new_field.model = Thing
        with connection.schema_editor() as editor:
            editor.alter_field(Thing, old_field, new_field, strict=True)
        self.assertEqual(self.get_primary_key(Thing._meta.db_table), "when")
        self.assertEqual(
            self.get_column_collation(Thing._meta.db_table, "when"),
            collation,
        )
        with connection.schema_editor() as editor:
            editor.alter_field(Thing, new_field, old_field, strict=True)
        self.assertEqual(self.get_primary_key(Thing._meta.db_table), "when")
        self.assertIsNone(self.get_column_collation(Thing._meta.db_table, "when"))

    @skipUnlessDBFeature(
        "supports_collation_on_charfield", "supports_collation_on_textfield"
    )
    def test_alter_field_type_and_db_collation(self):
        collation = connection.features.test_collations.get("non_default")
        if not collation:
            self.skipTest("Language collations are not supported.")

        with connection.schema_editor() as editor:
            editor.create_model(Note)

        old_field = Note._meta.get_field("info")
        new_field = CharField(max_length=255, db_collation=collation)
        new_field.set_attributes_from_name("info")
        new_field.model = Note
        with connection.schema_editor() as editor:
            editor.alter_field(Note, old_field, new_field, strict=True)
        columns = self.column_classes(Note)
        self.assertEqual(
            columns["info"][0],
            connection.features.introspected_field_types["CharField"],
        )
        self.assertEqual(columns["info"][1][8], collation)
        with connection.schema_editor() as editor:
            editor.alter_field(Note, new_field, old_field, strict=True)
        columns = self.column_classes(Note)
        self.assertEqual(columns["info"][0], "TextField")
        self.assertIsNone(columns["info"][1][8])

    @skipUnlessDBFeature(
        "supports_collation_on_charfield",
        "supports_non_deterministic_collations",
    )
    def test_ci_cs_db_collation(self):
        """
        Tests case-insensitive and case-sensitive database collations on character fields.

        This test checks the functionality of case-insensitive and case-sensitive database collations 
        on character fields in different databases, such as MySQL and PostgreSQL. It creates a model,
        alters the field to use different collations, and verifies that the query results match the 
        expected case sensitivity. The test ensures that the database correctly handles case-insensitive 
        and case-sensitive queries, and that the conversion between collations works as expected.
        """
        cs_collation = connection.features.test_collations.get("cs")
        ci_collation = connection.features.test_collations.get("ci")
        try:
            if connection.vendor == "mysql":
                cs_collation = "latin1_general_cs"
            elif connection.vendor == "postgresql":
                cs_collation = "en-x-icu"
                with connection.cursor() as cursor:
                    cursor.execute(
                        "CREATE COLLATION IF NOT EXISTS case_insensitive "
                        "(provider = icu, locale = 'und-u-ks-level2', "
                        "deterministic = false)"
                    )
                    ci_collation = "case_insensitive"
            # Create the table.
            with connection.schema_editor() as editor:
                editor.create_model(Author)
            # Case-insensitive collation.
            old_field = Author._meta.get_field("name")
            new_field_ci = CharField(max_length=255, db_collation=ci_collation)
            new_field_ci.set_attributes_from_name("name")
            new_field_ci.model = Author
            with connection.schema_editor() as editor:
                editor.alter_field(Author, old_field, new_field_ci, strict=True)
            Author.objects.create(name="ANDREW")
            self.assertIs(Author.objects.filter(name="Andrew").exists(), True)
            # Case-sensitive collation.
            new_field_cs = CharField(max_length=255, db_collation=cs_collation)
            new_field_cs.set_attributes_from_name("name")
            new_field_cs.model = Author
            with connection.schema_editor() as editor:
                editor.alter_field(Author, new_field_ci, new_field_cs, strict=True)
            self.assertIs(Author.objects.filter(name="Andrew").exists(), False)
        finally:
            if connection.vendor == "postgresql":
                with connection.cursor() as cursor:
                    cursor.execute("DROP COLLATION IF EXISTS case_insensitive")
